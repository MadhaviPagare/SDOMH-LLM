{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Now import your GPU-related libraries, such as PyTorch\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set up CUDA\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "import random\n",
    "\n",
    "random_seed = 777  # You can change this value to any seed you prefer\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "\n",
    "# Load and preprocess your data for H1, H2, and H3\n",
    "model1_data = pd.read_csv(\"model1_2636.csv\")\n",
    "texts_h1 = model1_data['text'].tolist()\n",
    "labels_h1 = model1_data.iloc[:, 1].values.tolist()\n",
    "\n",
    "model2_data = pd.read_csv(\"model2_2636.csv\")\n",
    "texts_h2 = model2_data['text'].tolist()\n",
    "labels_h2 = model2_data.iloc[:, 1].values.tolist()\n",
    "\n",
    "model3_data = pd.read_csv(\"model3_2636.csv\")\n",
    "texts_h3 = model3_data['text'].tolist()\n",
    "labels_h3 = model3_data.iloc[:, 1:].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 21:37:59.294814: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/data2/users/mpagare/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 231/231 [03:06<00:00,  1.24it/s]\n",
      "Training: 100%|██████████| 231/231 [03:04<00:00,  1.25it/s]\n",
      "Training: 100%|██████████| 231/231 [03:03<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "H1: Train Loss: 1.7604, Val Loss: 1.4489, Accuracy: 0.9278\n",
      "Precision H1: 0.9278, Recall H1: 0.9278, F1 H1: 0.9278\n",
      "H2: Train Loss: 1.5636, Val Loss: 1.4847, Accuracy: 0.6692\n",
      "Precision H2: 0.6692, Recall H2: 0.6692, F1 H2: 0.6692\n",
      "H3: Train Loss: 1.5059, Val Loss: 1.4030, Custom Accuracy: 0.6663\n",
      "Precision H3: 0.6584510229947493,Recall H3:0.5230416604941319,F1 Score H3: 0.5829867949825093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/33\n",
      "H1: Train Loss: 1.4822, Val Loss: 1.3191, Accuracy: 0.9430\n",
      "Precision H1: 0.9430, Recall H1: 0.9430, F1 H1: 0.9430\n",
      "H2: Train Loss: 1.4396, Val Loss: 1.3551, Accuracy: 0.7110\n",
      "Precision H2: 0.7110, Recall H2: 0.7110, F1 H2: 0.7110\n",
      "H3: Train Loss: 1.3876, Val Loss: 1.3909, Custom Accuracy: 0.6718\n",
      "Precision H3: 0.6720532319391636,Recall H3:0.513523749170137,F1 Score H3: 0.5821896018669244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/33\n",
      "H1: Train Loss: 1.3622, Val Loss: 1.2094, Accuracy: 0.9506\n",
      "Precision H1: 0.9506, Recall H1: 0.9506, F1 H1: 0.9506\n",
      "H2: Train Loss: 1.3039, Val Loss: 1.1716, Accuracy: 0.7529\n",
      "Precision H2: 0.7529, Recall H2: 0.7529, F1 H2: 0.7529\n",
      "H3: Train Loss: 1.2449, Val Loss: 1.2467, Custom Accuracy: 0.6797\n",
      "Precision H3: 0.6709940249864205,Recall H3:0.5368903593238195,F1 Score H3: 0.5964978566799095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/33\n",
      "H1: Train Loss: 1.1832, Val Loss: 1.0706, Accuracy: 0.9544\n",
      "Precision H1: 0.9544, Recall H1: 0.9544, F1 H1: 0.9544\n",
      "H2: Train Loss: 1.1196, Val Loss: 1.0973, Accuracy: 0.7985\n",
      "Precision H2: 0.7985, Recall H2: 0.7985, F1 H2: 0.7985\n",
      "H3: Train Loss: 1.0585, Val Loss: 1.1730, Custom Accuracy: 0.6961\n",
      "Precision H3: 0.7112076769871446,Recall H3:0.5335373013129666,F1 Score H3: 0.6096924772028242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/33\n",
      "H1: Train Loss: 0.9937, Val Loss: 0.9923, Accuracy: 0.9658\n",
      "Precision H1: 0.9658, Recall H1: 0.9658, F1 H1: 0.9658\n",
      "H2: Train Loss: 0.9277, Val Loss: 1.0255, Accuracy: 0.8669\n",
      "Precision H2: 0.8669, Recall H2: 0.8669, F1 H2: 0.8669\n",
      "H3: Train Loss: 0.8823, Val Loss: 1.1186, Custom Accuracy: 0.6996\n",
      "Precision H3: 0.6990449031323556,Recall H3:0.5498864253617105,F1 Score H3: 0.6155587487972931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:03<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/33\n",
      "H1: Train Loss: 0.8507, Val Loss: 0.9113, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.8296, Val Loss: 0.8681, Accuracy: 0.9278\n",
      "Precision H2: 0.9278, Recall H2: 0.9278, F1 H2: 0.9278\n",
      "H3: Train Loss: 0.7857, Val Loss: 0.9029, Custom Accuracy: 0.7058\n",
      "Precision H3: 0.6978634799927577,Recall H3:0.5722353902962268,F1 Score H3: 0.6288363688667431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/33\n",
      "H1: Train Loss: 0.7729, Val Loss: 0.9131, Accuracy: 0.9696\n",
      "Precision H1: 0.9696, Recall H1: 0.9696, F1 H1: 0.9696\n",
      "H2: Train Loss: 0.7294, Val Loss: 0.8313, Accuracy: 0.9316\n",
      "Precision H2: 0.9316, Recall H2: 0.9316, F1 H2: 0.9316\n",
      "H3: Train Loss: 0.7005, Val Loss: 0.8964, Custom Accuracy: 0.7055\n",
      "Precision H3: 0.6944052145573059,Recall H3:0.5841460504008031,F1 Score H3: 0.6345213908566472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/33\n",
      "H1: Train Loss: 0.7116, Val Loss: 0.9434, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.6874, Val Loss: 0.8562, Accuracy: 0.9316\n",
      "Precision H2: 0.9316, Recall H2: 0.9316, F1 H2: 0.9316\n",
      "H3: Train Loss: 0.7039, Val Loss: 0.8156, Custom Accuracy: 0.7066\n",
      "Precision H3: 0.6974425131269237,Recall H3:0.5677135285500304,F1 Score H3: 0.6259268217432872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/33\n",
      "H1: Train Loss: 0.6503, Val Loss: 0.9025, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.6476, Val Loss: 0.8236, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.6382, Val Loss: 0.8191, Custom Accuracy: 0.7104\n",
      "Precision H3: 0.6926866437322711,Recall H3:0.587985778480075,F1 Score H3: 0.6360563222780755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/33\n",
      "H1: Train Loss: 0.6387, Val Loss: 0.9497, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.6114, Val Loss: 0.8392, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.5985, Val Loss: 0.8183, Custom Accuracy: 0.7104\n",
      "Precision H3: 0.7016144607399359,Recall H3:0.5681672784334381,F1 Score H3: 0.6278785816020066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/33\n",
      "H1: Train Loss: 0.6042, Val Loss: 0.8680, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.5860, Val Loss: 0.8708, Accuracy: 0.9354\n",
      "Precision H2: 0.9354, Recall H2: 0.9354, F1 H2: 0.9354\n",
      "H3: Train Loss: 0.6030, Val Loss: 0.7918, Custom Accuracy: 0.7169\n",
      "Precision H3: 0.7004662321202245,Recall H3:0.5992450304237376,F1 Score H3: 0.6459140898049838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/33\n",
      "H1: Train Loss: 0.6004, Val Loss: 0.9218, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.5644, Val Loss: 0.8967, Accuracy: 0.9430\n",
      "Precision H2: 0.9430, Recall H2: 0.9430, F1 H2: 0.9430\n",
      "H3: Train Loss: 0.5823, Val Loss: 0.8672, Custom Accuracy: 0.7163\n",
      "Precision H3: 0.6852326908410559,Recall H3:0.6363964193812103,F1 Score H3: 0.6599122666431912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/33\n",
      "H1: Train Loss: 0.5749, Val Loss: 0.8969, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.5660, Val Loss: 0.8690, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.5510, Val Loss: 0.8803, Custom Accuracy: 0.7251\n",
      "Precision H3: 0.6968861620002303,Recall H3:0.636939602433899,F1 Score H3: 0.66556578348061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:03<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/33\n",
      "H1: Train Loss: 0.5612, Val Loss: 0.8971, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.5502, Val Loss: 0.8210, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.5383, Val Loss: 0.8328, Custom Accuracy: 0.7289\n",
      "Precision H3: 0.7155429910182761,Recall H3:0.6048011346490434,F1 Score H3: 0.6555279104063879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.27it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/33\n",
      "H1: Train Loss: 0.5591, Val Loss: 0.8966, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.5323, Val Loss: 0.8327, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.5445, Val Loss: 0.7530, Custom Accuracy: 0.7324\n",
      "Precision H3: 0.7097151580991884,Recall H3:0.6164108493956404,F1 Score H3: 0.6597806256123635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:03<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/33\n",
      "H1: Train Loss: 0.5180, Val Loss: 0.8305, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.5095, Val Loss: 0.7903, Accuracy: 0.9354\n",
      "Precision H2: 0.9354, Recall H2: 0.9354, F1 H2: 0.9354\n",
      "H3: Train Loss: 0.5122, Val Loss: 0.7658, Custom Accuracy: 0.7458\n",
      "Precision H3: 0.7356402152980099,Recall H3:0.633334979342584,F1 Score H3: 0.680664897922649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/33\n",
      "H1: Train Loss: 0.5144, Val Loss: 0.8340, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.4915, Val Loss: 0.7823, Accuracy: 0.9620\n",
      "Precision H2: 0.9620, Recall H2: 0.9620, F1 H2: 0.9620\n",
      "H3: Train Loss: 0.4792, Val Loss: 0.8020, Custom Accuracy: 0.7514\n",
      "Precision H3: 0.7327837034110798,Recall H3:0.6494192330694232,F1 Score H3: 0.6885874977038262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:03<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/33\n",
      "H1: Train Loss: 0.4911, Val Loss: 0.7899, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.4910, Val Loss: 0.7767, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.4844, Val Loss: 0.7886, Custom Accuracy: 0.7599\n",
      "Precision H3: 0.7233959639853176,Recall H3:0.689868950230167,F1 Score H3: 0.706234774889769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:03<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/33\n",
      "H1: Train Loss: 0.4735, Val Loss: 0.7461, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.4794, Val Loss: 0.7206, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.4496, Val Loss: 0.7537, Custom Accuracy: 0.7727\n",
      "Precision H3: 0.7541188638146813,Recall H3:0.6774596864901047,F1 Score H3: 0.7137367753203615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/33\n",
      "H1: Train Loss: 0.4416, Val Loss: 0.7739, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.4501, Val Loss: 0.7118, Accuracy: 0.9620\n",
      "Precision H2: 0.9620, Recall H2: 0.9620, F1 H2: 0.9620\n",
      "H3: Train Loss: 0.4381, Val Loss: 0.7380, Custom Accuracy: 0.7841\n",
      "Precision H3: 0.7662027663928804,Recall H3:0.700537970690062,F1 Score H3: 0.7319004886623357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/33\n",
      "H1: Train Loss: 0.4201, Val Loss: 0.7337, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.4374, Val Loss: 0.6920, Accuracy: 0.9620\n",
      "Precision H2: 0.9620, Recall H2: 0.9620, F1 H2: 0.9620\n",
      "H3: Train Loss: 0.4084, Val Loss: 0.6782, Custom Accuracy: 0.7929\n",
      "Precision H3: 0.7754972319611103,Recall H3:0.7095949994238968,F1 Score H3: 0.7410838818454722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:03<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/33\n",
      "H1: Train Loss: 0.3879, Val Loss: 0.7270, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.3783, Val Loss: 0.6661, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.3837, Val Loss: 0.6459, Custom Accuracy: 0.7961\n",
      "Precision H3: 0.7619575713682177,Recall H3:0.7343863677513868,F1 Score H3: 0.7479179600206156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/33\n",
      "H1: Train Loss: 0.3579, Val Loss: 0.6863, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.3460, Val Loss: 0.6738, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.3399, Val Loss: 0.6626, Custom Accuracy: 0.8283\n",
      "Precision H3: 0.8091671741861857,Recall H3:0.7702634712140416,F1 Score H3: 0.7892361949494421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/33\n",
      "H1: Train Loss: 0.3432, Val Loss: 0.7185, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.3300, Val Loss: 0.6499, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.3306, Val Loss: 0.6408, Custom Accuracy: 0.8283\n",
      "Precision H3: 0.802628813940601,Recall H3:0.7840894002490961,F1 Score H3: 0.7932507986828852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/33\n",
      "H1: Train Loss: 0.3276, Val Loss: 0.6371, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.3021, Val Loss: 0.6300, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.2884, Val Loss: 0.6218, Custom Accuracy: 0.8546\n",
      "Precision H3: 0.8407370829424061,Recall H3:0.8000796942812151,F1 Score H3: 0.8199046689778781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/33\n",
      "H1: Train Loss: 0.2776, Val Loss: 0.6228, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.2684, Val Loss: 0.5884, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.2472, Val Loss: 0.5779, Custom Accuracy: 0.8734\n",
      "Precision H3: 0.8626438200582688,Recall H3:0.8227367372804636,F1 Score H3: 0.8422178111162963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:03<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/33\n",
      "H1: Train Loss: 0.2388, Val Loss: 0.5549, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.2282, Val Loss: 0.5369, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.2146, Val Loss: 0.5259, Custom Accuracy: 0.8903\n",
      "Precision H3: 0.8869734827909732,Recall H3:0.8270009985789454,F1 Score H3: 0.8559380130267719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/33\n",
      "H1: Train Loss: 0.2132, Val Loss: 0.5791, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.2074, Val Loss: 0.5995, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.2043, Val Loss: 0.5651, Custom Accuracy: 0.8982\n",
      "Precision H3: 0.8931058274214168,Recall H3:0.8559512836128805,F1 Score H3: 0.8741339257143504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.09it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/33\n",
      "H1: Train Loss: 0.2131, Val Loss: 0.5542, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.1883, Val Loss: 0.5940, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.2052, Val Loss: 0.5721, Custom Accuracy: 0.9035\n",
      "Precision H3: 0.8931584997174351,Recall H3:0.8756885805364892,F1 Score H3: 0.8843372697874862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/33\n",
      "H1: Train Loss: 0.1820, Val Loss: 0.5238, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.1607, Val Loss: 0.5683, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.1614, Val Loss: 0.5466, Custom Accuracy: 0.9251\n",
      "Precision H3: 0.914985405384645,Recall H3:0.9030260508397391,F1 Score H3: 0.9089663922321455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:03<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/33\n",
      "H1: Train Loss: 0.1450, Val Loss: 0.5083, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.1344, Val Loss: 0.5180, Accuracy: 0.9620\n",
      "Precision H2: 0.9620, Recall H2: 0.9620, F1 H2: 0.9620\n",
      "H3: Train Loss: 0.1273, Val Loss: 0.5529, Custom Accuracy: 0.9354\n",
      "Precision H3: 0.9339577195090503,Recall H3:0.9096376584969741,F1 Score H3: 0.9216372781626816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/33\n",
      "H1: Train Loss: 0.1228, Val Loss: 0.4788, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.1156, Val Loss: 0.5532, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.1215, Val Loss: 0.4990, Custom Accuracy: 0.9380\n",
      "Precision H3: 0.9407475076676597,Recall H3:0.90881959189944,F1 Score H3: 0.9245079740000215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:02<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:03<00:00,  1.26it/s]\n",
      "Training: 100%|██████████| 231/231 [03:03<00:00,  1.26it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:10<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/33\n",
      "H1: Train Loss: 0.1189, Val Loss: 0.5005, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.1930, Val Loss: 0.5258, Accuracy: 0.9430\n",
      "Precision H2: 0.9430, Recall H2: 0.9430, F1 H2: 0.9430\n",
      "H3: Train Loss: 0.1237, Val Loss: 0.5319, Custom Accuracy: 0.9415\n",
      "Precision H3: 0.9407174679988367,Recall H3:0.9122554990425712,F1 Score H3: 0.9262678932629732\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and set up CUDA\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "import random\n",
    "\n",
    "random_seed = 777  # You can change this value to any seed you prefer\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "\n",
    "# Load and preprocess your data for H1, H2, and H3\n",
    "model1_data = pd.read_csv(\"model1_2636.csv\")\n",
    "texts_h1 = model1_data['text'].tolist()\n",
    "labels_h1 = model1_data.iloc[:, 1].values.tolist()\n",
    "\n",
    "model2_data = pd.read_csv(\"model2_2636.csv\")\n",
    "texts_h2 = model2_data['text'].tolist()\n",
    "labels_h2 = model2_data.iloc[:, 1].values.tolist()\n",
    "\n",
    "model3_data = pd.read_csv(\"model3_2636.csv\")\n",
    "texts_h3 = model3_data['text'].tolist()\n",
    "labels_h3 = model3_data.iloc[:, 1:].values.tolist()\n",
    "\n",
    "#print(\"Total Records in H1:\", len(texts_h1),\"texts_h1\", \"with\", len(labels_h1), \"labels\")\n",
    "#print(\"Total Records in H2:\", len(texts_h2),\"texts_h2\",\"with\", len(labels_h2), \"labels\")\n",
    "#print(\"Total Records in H3:\", len(texts_h3),\"texts_h3\", \"with\", len(labels_h3), \"labels\")\n",
    "\n",
    "# Split the data for each hierarchy\n",
    "def split_data(texts, labels, train_ratio, val_ratio, test_ratio):\n",
    "    total_samples = len(texts)\n",
    "    train_size = int(total_samples * train_ratio)\n",
    "    val_size = int(total_samples * val_ratio)\n",
    "    test_size = total_samples - train_size - val_size  # Remaining samples for test\n",
    "\n",
    "    train_texts = texts[:train_size]\n",
    "    val_texts = texts[train_size:train_size + val_size]\n",
    "    test_texts = texts[train_size + val_size:]\n",
    "\n",
    "    train_labels = labels[:train_size]\n",
    "    val_labels = labels[train_size:train_size + val_size]\n",
    "    test_labels = labels[train_size + val_size:]\n",
    "\n",
    "    return train_texts, val_texts, test_texts, train_labels, val_labels, test_labels\n",
    "\n",
    "# Split the data for each hierarchy\n",
    "train_texts_h1, val_texts_h1, test_texts_h1, train_labels_h1, val_labels_h1, test_labels_h1 = split_data(texts_h1, labels_h1, 0.7, 0.1, 0.2)\n",
    "train_texts_h2, val_texts_h2, test_texts_h2, train_labels_h2, val_labels_h2, test_labels_h2 = split_data(texts_h2, labels_h2, 0.7, 0.1, 0.2)\n",
    "train_texts_h3, val_texts_h3, test_texts_h3, train_labels_h3, val_labels_h3, test_labels_h3 = split_data(texts_h3, labels_h3, 0.7, 0.1, 0.2)\n",
    "\n",
    "#print(\"Train Val Test Splitting:\")\n",
    "#print(\"H1:\", len(train_texts_h1), len(val_texts_h1), len(test_texts_h1))\n",
    "#print(\"H2:\", len(train_texts_h2), len(val_texts_h2), len(test_texts_h2))\n",
    "#print(\"H3:\", len(train_texts_h3), len(val_texts_h3), len(test_texts_h3))\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Define the TextDataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Now expecting a list of binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    # Rest of the code remains unchanged\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Create datasets and dataloaders for H1, H2, and H3\n",
    "dataset_h1 = TextDataset(train_texts_h1 + val_texts_h1 + test_texts_h1, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "dataset_h2 = TextDataset(train_texts_h2 + val_texts_h2 + test_texts_h2, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "dataset_h3 = TextDataset(train_texts_h3 + val_texts_h3 + test_texts_h3, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "\n",
    "# Split the datasets into train, val, and test for H1, H2, and H3\n",
    "train_size_h1 = len(train_texts_h1)\n",
    "val_size_h1 = len(val_texts_h1)\n",
    "train_size_h2 = len(train_texts_h2)\n",
    "val_size_h2 = len(val_texts_h2)\n",
    "train_size_h3 = len(train_texts_h3)\n",
    "val_size_h3 = len(val_texts_h3)\n",
    "\n",
    "train_dataset_h1, val_dataset_h1, test_dataset_h1 = random_split(dataset_h1, [train_size_h1, val_size_h1, len(test_texts_h1)])\n",
    "train_dataset_h2, val_dataset_h2, test_dataset_h2 = random_split(dataset_h2, [train_size_h2, val_size_h2, len(test_texts_h2)])\n",
    "train_dataset_h3, val_dataset_h3, test_dataset_h3 = random_split(dataset_h3, [train_size_h3, val_size_h3, len(test_texts_h3)])\n",
    "\n",
    "# Create dataloaders for H1, H2, and H3\n",
    "train_dataloader_h1 = DataLoader(train_dataset_h1, batch_size=8, shuffle=True)\n",
    "val_dataloader_h1 = DataLoader(val_dataset_h1,batch_size=8, shuffle=False)  # You can set shuffle to True if you want to shuffle the validation data.\n",
    "train_dataloader_h2 = DataLoader(train_dataset_h2, batch_size=8, shuffle=True)\n",
    "val_dataloader_h2 = DataLoader(val_dataset_h2, batch_size=8, shuffle=False)\n",
    "\n",
    "train_dataloader_h3 = DataLoader(train_dataset_h3, batch_size=8, shuffle=True)\n",
    "val_dataloader_h3 = DataLoader(val_dataset_h3, batch_size=8, shuffle=False)\n",
    "\n",
    "# Define the model architecture for H1, H2, and H3\n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc_h1 = nn.Linear(self.roberta.config.hidden_size, 1)  # Binary output for H1\n",
    "        self.fc_h2 = nn.Linear(self.roberta.config.hidden_size, 1)  # Binary output for H2\n",
    "        self.fc_h3 = nn.Linear(self.roberta.config.hidden_size, num_labels_h3)  # Multi-label output for H3\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(input_ids, attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "model = HierarchicalClassifier(num_labels_h3=len(train_labels_h3[0]))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)  # You can adjust the learning rate as needed\n",
    "\n",
    "# Training loop for H1, H2, and H3\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader), desc=\"Training\"):\n",
    "        input_ids = batch['ids'].to(device)\n",
    "        attention_mask = batch['mask'].to(device)\n",
    "        labels_h1 = batch['labels_h1'].to(device)\n",
    "        labels_h2 = batch['labels_h2'].to(device)\n",
    "        labels_h3 = batch['labels_h3'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "        loss_h1 = criterion(logits_h1, labels_h1)\n",
    "        loss_h2 = criterion(logits_h2, labels_h2)\n",
    "        loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "        loss = loss_h1 + loss_h2 + loss_h3\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Validation loop for H1, H2, and H3\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Validation\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels_h1 = batch['labels_h1'].to(device)\n",
    "            labels_h2 = batch['labels_h2'].to(device)\n",
    "            labels_h3 = batch['labels_h3'].to(device)\n",
    "\n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "# Training and evaluation for H1, H2, and H3\n",
    "# Custom accuracy function\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_labels = np.sum(np.equal(y_true, y_pred), axis=1)\n",
    "    total_labels = y_true.shape[1]\n",
    "    sample_accuracy = np.mean(correct_labels / total_labels)\n",
    "    return sample_accuracy\n",
    "\n",
    "def custom_precision_recall_f1(y_true, y_pred):\n",
    "    # Calculate precision and recall for each sample\n",
    "    sample_precisions = []\n",
    "    sample_recalls = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_positive = np.sum((true == 1) & (pred == 1))\n",
    "        false_positive = np.sum((true == 0) & (pred == 1))\n",
    "        false_negative = np.sum((true == 1) & (pred == 0))\n",
    "        \n",
    "        sample_precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "        sample_recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "        \n",
    "        sample_precisions.append(sample_precision)\n",
    "        sample_recalls.append(sample_recall)\n",
    "    \n",
    "    # Calculate average precision and recall across all samples\n",
    "    avg_precision = np.mean(sample_precisions)\n",
    "    avg_recall = np.mean(sample_recalls)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    if avg_precision + avg_recall > 0:\n",
    "        avg_f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
    "    else:\n",
    "        avg_f1 = 0\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "\n",
    "# Training and evaluation for H1, H2, and H3\n",
    "num_epochs = 33 # You can adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training for H1\n",
    "    train_loss_h1 = train(model, train_dataloader_h1, optimizer, criterion, device)\n",
    "    # Training for H2\n",
    "    train_loss_h2 = train(model, train_dataloader_h2, optimizer, criterion, device)\n",
    "    # Training for H3\n",
    "    train_loss_h3 = train(model, train_dataloader_h3, optimizer, criterion, device)\n",
    "\n",
    "    # Validation for H1\n",
    "    val_loss_h1, val_preds_h1, _, _, val_labels_h1, _, _ = evaluate(model, val_dataloader_h1, criterion, device)\n",
    "    # Validation for H2\n",
    "    val_loss_h2, _, val_preds_h2, _, _, val_labels_h2, _ = evaluate(model, val_dataloader_h2, criterion, device)\n",
    "    # Validation for H3\n",
    "    val_loss_h3, _, _, val_preds_h3, _, _, val_labels_h3 = evaluate(model, val_dataloader_h3, criterion, device)\n",
    "\n",
    "    # Metrics calculation for H1\n",
    "    threshold_h1 = 0.5\n",
    "    val_preds_h1_binary = (np.array(val_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "    acc_h1 = accuracy_score(val_labels_h1, val_preds_h1_binary)\n",
    "    precision_h1 = precision_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    recall_h1 = recall_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    f1_h1 = f1_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "\n",
    "\n",
    "    # Metrics calculation for H2\n",
    "    threshold_h2 = 0.5\n",
    "    val_preds_h2_binary = (np.array(val_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "    acc_h2 = accuracy_score(val_labels_h2, val_preds_h2_binary)\n",
    "    precision_h2 = precision_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    recall_h2 = recall_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    f1_h2 = f1_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "\n",
    "# Convert predictions and labels to binary using the threshold\n",
    "\n",
    "    # Metrics calculation for H3\n",
    "    threshold_h3 = 0.5\n",
    "    val_preds_h3_binary = (np.array(val_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "\n",
    "    # Custom accuracy calculation for H3\n",
    "    acc_h3_custom = custom_accuracy(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "    # Calculate custom precision, recall, and F1 score for H3\n",
    "    precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"H1: Train Loss: {train_loss_h1:.4f}, Val Loss: {val_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "    print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "    print(f\"H2: Train Loss: {train_loss_h2:.4f}, Val Loss: {val_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "    print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "    print(f\"H3: Train Loss: {train_loss_h3:.4f}, Val Loss: {val_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "    print(f\"Precision H3: {precision_h3},Recall H3:{recall_h3},F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "# Saving the model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Loading the model\n",
    "#loaded_model = YourModelClass(*args, **kwargs)  # Instantiate your model\n",
    "#loaded_model.load_state_dict(torch.load('model.pth'))\n",
    "#loaded_model.eval()  # Set the model to evaluation mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   2%|▏         | 1/66 [00:00<00:23,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   3%|▎         | 2/66 [00:00<00:20,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   5%|▍         | 3/66 [00:00<00:20,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   6%|▌         | 4/66 [00:01<00:19,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   8%|▊         | 5/66 [00:01<00:19,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   9%|▉         | 6/66 [00:01<00:19,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  11%|█         | 7/66 [00:02<00:19,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  12%|█▏        | 8/66 [00:02<00:18,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  14%|█▎        | 9/66 [00:02<00:18,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  15%|█▌        | 10/66 [00:03<00:17,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  17%|█▋        | 11/66 [00:03<00:17,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  18%|█▊        | 12/66 [00:03<00:17,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  20%|█▉        | 13/66 [00:04<00:16,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  21%|██        | 14/66 [00:04<00:16,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  23%|██▎       | 15/66 [00:04<00:16,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  24%|██▍       | 16/66 [00:05<00:15,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  26%|██▌       | 17/66 [00:05<00:15,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  27%|██▋       | 18/66 [00:05<00:15,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  29%|██▉       | 19/66 [00:06<00:14,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  30%|███       | 20/66 [00:06<00:14,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  32%|███▏      | 21/66 [00:06<00:14,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  33%|███▎      | 22/66 [00:07<00:14,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  35%|███▍      | 23/66 [00:07<00:13,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  36%|███▋      | 24/66 [00:07<00:13,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  38%|███▊      | 25/66 [00:07<00:13,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  39%|███▉      | 26/66 [00:08<00:12,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  41%|████      | 27/66 [00:08<00:12,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  42%|████▏     | 28/66 [00:08<00:12,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  44%|████▍     | 29/66 [00:09<00:12,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  45%|████▌     | 30/66 [00:09<00:11,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  47%|████▋     | 31/66 [00:09<00:11,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  48%|████▊     | 32/66 [00:10<00:11,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  50%|█████     | 33/66 [00:10<00:10,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  52%|█████▏    | 34/66 [00:10<00:10,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  53%|█████▎    | 35/66 [00:11<00:10,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  55%|█████▍    | 36/66 [00:11<00:09,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  56%|█████▌    | 37/66 [00:11<00:09,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  58%|█████▊    | 38/66 [00:12<00:09,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  59%|█████▉    | 39/66 [00:12<00:08,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  61%|██████    | 40/66 [00:12<00:08,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  62%|██████▏   | 41/66 [00:13<00:08,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  64%|██████▎   | 42/66 [00:13<00:07,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  65%|██████▌   | 43/66 [00:13<00:07,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  67%|██████▋   | 44/66 [00:14<00:06,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  68%|██████▊   | 45/66 [00:14<00:06,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  70%|██████▉   | 46/66 [00:14<00:06,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  71%|███████   | 47/66 [00:15<00:06,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  73%|███████▎  | 48/66 [00:15<00:05,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  74%|███████▍  | 49/66 [00:15<00:05,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  76%|███████▌  | 50/66 [00:16<00:05,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  77%|███████▋  | 51/66 [00:16<00:04,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  79%|███████▉  | 52/66 [00:16<00:04,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  80%|████████  | 53/66 [00:17<00:04,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  82%|████████▏ | 54/66 [00:17<00:03,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  83%|████████▎ | 55/66 [00:17<00:03,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  85%|████████▍ | 56/66 [00:17<00:03,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  86%|████████▋ | 57/66 [00:18<00:02,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  88%|████████▊ | 58/66 [00:18<00:02,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  89%|████████▉ | 59/66 [00:18<00:02,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  91%|█████████ | 60/66 [00:19<00:01,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  92%|█████████▏| 61/66 [00:19<00:01,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  94%|█████████▍| 62/66 [00:19<00:01,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  95%|█████████▌| 63/66 [00:20<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  97%|█████████▋| 64/66 [00:20<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  98%|█████████▊| 65/66 [00:20<00:00,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 66/66 [00:21<00:00,  3.12it/s]\n",
      "Testing:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   2%|▏         | 1/66 [00:00<00:20,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   3%|▎         | 2/66 [00:00<00:20,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   5%|▍         | 3/66 [00:00<00:19,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   6%|▌         | 4/66 [00:01<00:19,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   8%|▊         | 5/66 [00:01<00:19,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   9%|▉         | 6/66 [00:01<00:19,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  11%|█         | 7/66 [00:02<00:19,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  12%|█▏        | 8/66 [00:02<00:18,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  14%|█▎        | 9/66 [00:02<00:18,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  15%|█▌        | 10/66 [00:03<00:17,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  17%|█▋        | 11/66 [00:03<00:17,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  18%|█▊        | 12/66 [00:03<00:17,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  20%|█▉        | 13/66 [00:04<00:16,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  21%|██        | 14/66 [00:04<00:16,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  23%|██▎       | 15/66 [00:04<00:16,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  24%|██▍       | 16/66 [00:05<00:15,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  26%|██▌       | 17/66 [00:05<00:15,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  27%|██▋       | 18/66 [00:05<00:15,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  29%|██▉       | 19/66 [00:06<00:14,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  30%|███       | 20/66 [00:06<00:14,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  32%|███▏      | 21/66 [00:06<00:14,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  33%|███▎      | 22/66 [00:07<00:14,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  35%|███▍      | 23/66 [00:07<00:13,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  36%|███▋      | 24/66 [00:07<00:13,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  38%|███▊      | 25/66 [00:07<00:13,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  39%|███▉      | 26/66 [00:08<00:12,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  41%|████      | 27/66 [00:08<00:12,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  42%|████▏     | 28/66 [00:08<00:12,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  44%|████▍     | 29/66 [00:09<00:12,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  45%|████▌     | 30/66 [00:09<00:11,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  47%|████▋     | 31/66 [00:09<00:11,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  48%|████▊     | 32/66 [00:10<00:11,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  50%|█████     | 33/66 [00:10<00:10,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  52%|█████▏    | 34/66 [00:10<00:10,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  53%|█████▎    | 35/66 [00:11<00:10,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  55%|█████▍    | 36/66 [00:11<00:09,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  56%|█████▌    | 37/66 [00:11<00:09,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  58%|█████▊    | 38/66 [00:12<00:09,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  59%|█████▉    | 39/66 [00:12<00:08,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  61%|██████    | 40/66 [00:12<00:08,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  62%|██████▏   | 41/66 [00:13<00:08,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  64%|██████▎   | 42/66 [00:13<00:07,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  65%|██████▌   | 43/66 [00:13<00:07,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  67%|██████▋   | 44/66 [00:14<00:06,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  68%|██████▊   | 45/66 [00:14<00:06,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  70%|██████▉   | 46/66 [00:14<00:06,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  71%|███████   | 47/66 [00:15<00:06,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  73%|███████▎  | 48/66 [00:15<00:05,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  74%|███████▍  | 49/66 [00:15<00:05,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  76%|███████▌  | 50/66 [00:16<00:05,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  77%|███████▋  | 51/66 [00:16<00:05,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  79%|███████▉  | 52/66 [00:16<00:04,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  80%|████████  | 53/66 [00:17<00:04,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  82%|████████▏ | 54/66 [00:17<00:03,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  83%|████████▎ | 55/66 [00:17<00:03,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  85%|████████▍ | 56/66 [00:18<00:03,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  86%|████████▋ | 57/66 [00:18<00:02,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  88%|████████▊ | 58/66 [00:18<00:02,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  89%|████████▉ | 59/66 [00:18<00:02,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  91%|█████████ | 60/66 [00:19<00:01,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  92%|█████████▏| 61/66 [00:19<00:01,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  94%|█████████▍| 62/66 [00:19<00:01,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  95%|█████████▌| 63/66 [00:20<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  97%|█████████▋| 64/66 [00:20<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  98%|█████████▊| 65/66 [00:20<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 66/66 [00:21<00:00,  3.11it/s]\n",
      "Testing:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   2%|▏         | 1/66 [00:00<00:20,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   3%|▎         | 2/66 [00:00<00:20,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   5%|▍         | 3/66 [00:00<00:20,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   6%|▌         | 4/66 [00:01<00:19,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   8%|▊         | 5/66 [00:01<00:19,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   9%|▉         | 6/66 [00:01<00:19,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  11%|█         | 7/66 [00:02<00:19,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  12%|█▏        | 8/66 [00:02<00:18,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  14%|█▎        | 9/66 [00:02<00:18,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  15%|█▌        | 10/66 [00:03<00:17,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  17%|█▋        | 11/66 [00:03<00:17,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  18%|█▊        | 12/66 [00:03<00:17,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  20%|█▉        | 13/66 [00:04<00:17,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  21%|██        | 14/66 [00:04<00:16,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  23%|██▎       | 15/66 [00:04<00:16,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  24%|██▍       | 16/66 [00:05<00:16,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  26%|██▌       | 17/66 [00:05<00:15,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  27%|██▋       | 18/66 [00:05<00:15,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  29%|██▉       | 19/66 [00:06<00:15,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  30%|███       | 20/66 [00:06<00:15,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  32%|███▏      | 21/66 [00:06<00:15,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  33%|███▎      | 22/66 [00:07<00:15,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  35%|███▍      | 23/66 [00:07<00:14,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  36%|███▋      | 24/66 [00:07<00:14,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  38%|███▊      | 25/66 [00:08<00:13,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  39%|███▉      | 26/66 [00:08<00:13,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  41%|████      | 27/66 [00:08<00:13,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  42%|████▏     | 28/66 [00:09<00:12,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  44%|████▍     | 29/66 [00:09<00:12,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  45%|████▌     | 30/66 [00:09<00:12,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  47%|████▋     | 31/66 [00:10<00:11,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  48%|████▊     | 32/66 [00:10<00:11,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  50%|█████     | 33/66 [00:10<00:11,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  52%|█████▏    | 34/66 [00:11<00:10,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  53%|█████▎    | 35/66 [00:11<00:10,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  55%|█████▍    | 36/66 [00:11<00:09,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  56%|█████▌    | 37/66 [00:12<00:09,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  58%|█████▊    | 38/66 [00:12<00:09,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  59%|█████▉    | 39/66 [00:12<00:08,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  61%|██████    | 40/66 [00:13<00:08,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  62%|██████▏   | 41/66 [00:13<00:08,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  64%|██████▎   | 42/66 [00:13<00:07,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  65%|██████▌   | 43/66 [00:14<00:07,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  67%|██████▋   | 44/66 [00:14<00:06,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  68%|██████▊   | 45/66 [00:14<00:06,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  70%|██████▉   | 46/66 [00:15<00:06,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  71%|███████   | 47/66 [00:15<00:06,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  73%|███████▎  | 48/66 [00:15<00:05,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  74%|███████▍  | 49/66 [00:16<00:05,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  76%|███████▌  | 50/66 [00:16<00:05,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  77%|███████▋  | 51/66 [00:16<00:05,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  79%|███████▉  | 52/66 [00:17<00:04,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  80%|████████  | 53/66 [00:17<00:04,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  82%|████████▏ | 54/66 [00:17<00:03,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  83%|████████▎ | 55/66 [00:18<00:03,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  85%|████████▍ | 56/66 [00:18<00:03,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  86%|████████▋ | 57/66 [00:18<00:02,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  88%|████████▊ | 58/66 [00:19<00:02,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  89%|████████▉ | 59/66 [00:19<00:02,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  91%|█████████ | 60/66 [00:19<00:01,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  92%|█████████▏| 61/66 [00:20<00:01,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  94%|█████████▍| 62/66 [00:20<00:01,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  95%|█████████▌| 63/66 [00:20<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  97%|█████████▋| 64/66 [00:21<00:00,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  98%|█████████▊| 65/66 [00:21<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 66/66 [00:21<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Results:\n",
      "H1: Test Loss: 0.1025, Accuracy: 0.9981\n",
      "Precision H1: 0.9981, Recall H1: 0.9981, F1 H1: 0.9981\n",
      "H2: Test Loss: 0.1025, Accuracy: 0.9924\n",
      "Precision H2: 0.9924, Recall H2: 0.9924, F1 H2: 0.9924\n",
      "H3: Test Loss: 0.1025, Custom Accuracy: 0.9862\n",
      "Precision H3: 0.9906166644803007, Recall H3:0.9820489117364117, F1 Score H3: 0.9863141822209809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create test datasets for H1, H2, and H3\n",
    "test_dataset_h1 = TextDataset(test_texts_h1, test_labels_h1, test_labels_h2, test_labels_h3, tokenizer)\n",
    "test_dataset_h2 = TextDataset(test_texts_h2, test_labels_h1, test_labels_h2, test_labels_h3, tokenizer)\n",
    "test_dataset_h3 = TextDataset(test_texts_h3, test_labels_h1, test_labels_h2, test_labels_h3, tokenizer)\n",
    "\n",
    "# Create test dataloaders for H1, H2, and H3\n",
    "test_dataloader_h1 = DataLoader(test_dataset_h1, batch_size=8, shuffle=False)\n",
    "test_dataloader_h2 = DataLoader(test_dataset_h2, batch_size=8, shuffle=False)\n",
    "test_dataloader_h3 = DataLoader(test_dataset_h3, batch_size=8, shuffle=False)\n",
    "# Testing loop for H1, H2, and H3\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Testing\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels_h1 = batch['labels_h1'].to(device)  # No need to reshape labels_h1\n",
    "            labels_h2 = batch['labels_h2'].to(device)  # No need to reshape labels_h2\n",
    "\n",
    "            #labels_h1 = batch['labels_h1'].unsqueeze(1).to(device)  # Reshape labels_h1\n",
    "            #labels_h2 = batch['labels_h2'].unsqueeze(1).to(device)  # Reshape labels_h2\n",
    "            #labels_h3 = batch['labels_h3'].unsqueeze(1).to(device)  # Reshape labels_h3\n",
    "            labels_h3 = batch['labels_h3'].to(device)  # No need to reshape labels_h3\n",
    "            print(\"Labels H1 shape:\", labels_h1.shape)\n",
    "            print(\"Labels H2 shape:\", labels_h2.shape)\n",
    "            print(\"Labels H3 shape:\", labels_h3.shape)\n",
    "\n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            \n",
    "            print(\"Logits H1 shape:\", logits_h1.shape)\n",
    "            print(\"Logits H2 shape:\", logits_h2.shape)\n",
    "            print(\"Logits H3 shape:\", logits_h3.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "# Testing for H1\n",
    "test_loss_h1, test_preds_h1, _, _, test_labels_h1, _, _ = test(model, test_dataloader_h1, criterion, device)\n",
    "# Testing for H2\n",
    "test_loss_h2, _, test_preds_h2, _, _, test_labels_h2, _ = test(model, test_dataloader_h2, criterion, device)\n",
    "# Testing for H3\n",
    "test_loss_h3, _, _, test_preds_h3, _, _, test_labels_h3 = test(model, test_dataloader_h3, criterion, device)\n",
    "\n",
    "# Metrics calculation for H1\n",
    "threshold_h1 = 0.5\n",
    "test_preds_h1_binary = (np.array(test_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "acc_h1 = accuracy_score(test_labels_h1, test_preds_h1_binary)\n",
    "precision_h1 = precision_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "recall_h1 = recall_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "f1_h1 = f1_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H2\n",
    "threshold_h2 = 0.5\n",
    "test_preds_h2_binary = (np.array(test_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "acc_h2 = accuracy_score(test_labels_h2, test_preds_h2_binary)\n",
    "precision_h2 = precision_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "recall_h2 = recall_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "f1_h2 = f1_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H3\n",
    "threshold_h3 = 0.5\n",
    "test_preds_h3_binary = (np.array(test_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "# Custom accuracy calculation for H3\n",
    "acc_h3_custom = custom_accuracy(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "# Calculate custom precision, recall, and F1 score for H3\n",
    "precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "\n",
    "print(\"Testing Results:\")\n",
    "print(f\"H1: Test Loss: {test_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "print(f\"H2: Test Loss: {test_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "print(f\"H3: Test Loss: {test_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "print(f\"Precision H3: {precision_h3}, Recall H3:{recall_h3}, F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW UNSEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Testing: 100%|██████████| 26/26 [00:08<00:00,  3.10it/s]\n",
      "Testing: 100%|██████████| 26/26 [00:07<00:00,  3.33it/s]\n",
      "Testing: 100%|██████████| 26/26 [00:07<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Results:\n",
      "H1: Test Loss: 0.4606, Accuracy: 0.9904\n",
      "Precision H1: 0.9904, Recall H1: 0.9904, F1 H1: 0.9904\n",
      "H2: Test Loss: 0.4606, Accuracy: 0.9904\n",
      "Precision H2: 0.9904, Recall H2: 0.9904, F1 H2: 0.9904\n",
      "H3: Test Loss: 0.4606, Custom Accuracy: 0.8924\n",
      "Precision H3: 0.7959153672914849, Recall H3:0.8958478993148093, F1 Score H3: 0.8429301187466134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming the new unseen datasets are similar to 'model1_2636.csv', 'model2_2636.csv', 'model3_2636.csv'\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Loading and preprocessing new_data_h1\n",
    "new_data_h1 = pd.read_csv(\"112_H_100_O_NEWMODEL1.CSV\")\n",
    "new_data_h1['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h1 = new_data_h1['text'].tolist()\n",
    "new_labels_h1 = new_data_h1.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h2\n",
    "new_data_h2 = pd.read_csv(\"112_H_100_O_NEWMODEL2.CSV\")\n",
    "new_data_h2['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h2 = new_data_h2['text'].tolist()\n",
    "new_labels_h2 = new_data_h2.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h3 for multi-label classification\n",
    "new_data_h3 = pd.read_csv(\"112_H_100_O_NEWMODEL3.CSV\")\n",
    "new_data_h3['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "\n",
    "# Replace NaN values in label columns with 0 for new_data_h3\n",
    "# Assuming all label columns are binary, fill NaN values with 0\n",
    "for label_col in new_data_h3.columns[1:]:  # Skip the text column, only fill NaN in label columns\n",
    "    new_data_h3[label_col].fillna(0, inplace=True)\n",
    "\n",
    "new_texts_h3 = new_data_h3['text'].tolist()\n",
    "new_labels_h3 = new_data_h3.iloc[:, 1:].values.tolist()  # Extract labels after filling NaN values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Now expecting a list of binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    # Rest of the code remains unchanged\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "        \n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc_h1 = nn.Linear(self.roberta.config.hidden_size, 1)  # Binary output for H1\n",
    "        self.fc_h2 = nn.Linear(self.roberta.config.hidden_size, 1)  # Binary output for H2\n",
    "        self.fc_h3 = nn.Linear(self.roberta.config.hidden_size, num_labels_h3)  # Multi-label output for H3\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(input_ids, attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "#model = HierarchicalClassifier(num_labels_h3=len(train_labels_h3[0]))\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Preprocess the texts and labels in the same way as the original datasets\n",
    "# Assuming the preprocessing steps are included in the TextDataset class\n",
    "# Create TextDataset instances for the new data\n",
    "new_dataset_h1 = TextDataset(new_texts_h1, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "new_dataset_h2 = TextDataset(new_texts_h2, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "new_dataset_h3 = TextDataset(new_texts_h3, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "\n",
    "# Create DataLoader instances for the new datasets\n",
    "#new_dataloader_h1 = DataLoader(new_dataset_h1, batch_size=8, shuffle=False)\n",
    "#new_dataloader_h2 = DataLoader(new_dataset_h2, batch_size=8, shuffle=False)\n",
    "#new_dataloader_h3 = DataLoader(new_dataset_h3, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "new_dataloader_h1 = DataLoader(new_dataset_h1, batch_size=8, shuffle=False, drop_last=True)\n",
    "new_dataloader_h2 = DataLoader(new_dataset_h2, batch_size=8, shuffle=False, drop_last=True)\n",
    "new_dataloader_h3 = DataLoader(new_dataset_h3, batch_size=8, shuffle=False, drop_last=True)\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'model.pth'  # Path to your saved model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = HierarchicalClassifier(num_labels_h3=len(new_labels_h3[0]))  # Make sure to provide the correct number of labels for H3\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Testing\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            \n",
    "            # Ensuring labels are correctly shaped and moved to the device\n",
    "            labels_h1 = batch['labels_h1'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h2 = batch['labels_h2'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h3 = batch['labels_h3'].to(device)  # Shape: [batch_size, num_labels_h3]\n",
    "            \n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Compute loss for each hierarchy\n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert logits to probabilities for binary classification/multi-label classification\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            # Store predictions and labels for metric calculation\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Testing the model on the new unseen data\n",
    "test_loss_h1, test_preds_h1, _, _, test_labels_h1, _, _ = test(model, new_dataloader_h1, criterion, device)\n",
    "test_loss_h2, _, test_preds_h2, _, _, test_labels_h2, _ = test(model, new_dataloader_h2, criterion, device)\n",
    "test_loss_h3, _, _, test_preds_h3, _, _, test_labels_h3 = test(model, new_dataloader_h3, criterion, device)\n",
    "\n",
    "# Calculate and print the metrics for H1, H2, and H3 using the same approach as before\n",
    "# Use the appropriate threshold and custom functions for metrics calculation\n",
    "\n",
    "# Metrics calculation for H1\n",
    "threshold_h1 = 0.5\n",
    "test_preds_h1_binary = (np.array(test_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "acc_h1 = accuracy_score(test_labels_h1, test_preds_h1_binary)\n",
    "precision_h1 = precision_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "recall_h1 = recall_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "f1_h1 = f1_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H2\n",
    "threshold_h2 = 0.5\n",
    "test_preds_h2_binary = (np.array(test_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "acc_h2 = accuracy_score(test_labels_h2, test_preds_h2_binary)\n",
    "precision_h2 = precision_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "recall_h2 = recall_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "f1_h2 = f1_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H3\n",
    "threshold_h3 = 0.5\n",
    "test_preds_h3_binary = (np.array(test_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_predictions = np.equal(y_true, y_pred)\n",
    "    sample_accuracy = np.sum(correct_predictions, axis=1) / y_true.shape[1]\n",
    "    return np.mean(sample_accuracy)\n",
    "\n",
    "def custom_precision_recall_f1(y_true, y_pred):\n",
    "    true_positives = np.sum((y_true == 1) & (y_pred == 1), axis=1)\n",
    "    false_positives = np.sum((y_true == 0) & (y_pred == 1), axis=1)\n",
    "    false_negatives = np.sum((y_true == 1) & (y_pred == 0), axis=1)\n",
    "\n",
    "    precision = np.mean(true_positives / (true_positives + false_positives + 1e-8))\n",
    "    recall = np.mean(true_positives / (true_positives + false_negatives + 1e-8))\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom accuracy calculation for H3\n",
    "acc_h3_custom = custom_accuracy(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "# Calculate custom precision, recall, and F1 score for H3\n",
    "precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "\n",
    "print(\"Testing Results:\")\n",
    "print(f\"H1: Test Loss: {test_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "print(f\"H2: Test Loss: {test_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "print(f\"H3: Test Loss: {test_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "print(f\"Precision H3: {precision_h3}, Recall H3:{recall_h3}, F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
