{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/mpagare/.local/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 231/231 [07:09<00:00,  1.86s/it]\n",
      "Training: 100%|██████████| 231/231 [07:08<00:00,  1.85s/it]\n",
      "Training: 100%|██████████| 231/231 [07:05<00:00,  1.84s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:17<00:00,  1.85it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:17<00:00,  1.86it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n",
      "H1: Train Loss: 1.7711, Val Loss: 1.4620, Accuracy: 0.9202\n",
      "Precision H1: 0.9202, Recall H1: 0.9202, F1 H1: 0.9202\n",
      "H2: Train Loss: 1.5321, Val Loss: 1.3765, Accuracy: 0.6540\n",
      "Precision H2: 0.6540, Recall H2: 0.6540, F1 H2: 0.6540\n",
      "H3: Train Loss: 1.4727, Val Loss: 1.4766, Custom Accuracy: 0.6797\n",
      "Precision H3: 0.7114340032590982, Recall H3: 0.4941068753806397, F1 Score H3: 0.5831812734322747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:09<00:00,  1.86s/it]\n",
      "Training: 100%|██████████| 231/231 [07:08<00:00,  1.85s/it]\n",
      "Training: 100%|██████████| 231/231 [07:07<00:00,  1.85s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.77it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.77it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/27\n",
      "H1: Train Loss: 1.4069, Val Loss: 1.1975, Accuracy: 0.9620\n",
      "Precision H1: 0.9620, Recall H1: 0.9620, F1 H1: 0.9620\n",
      "H2: Train Loss: 1.3433, Val Loss: 1.1927, Accuracy: 0.7414\n",
      "Precision H2: 0.7414, Recall H2: 0.7414, F1 H2: 0.7414\n",
      "H3: Train Loss: 1.2949, Val Loss: 1.2646, Custom Accuracy: 0.6926\n",
      "Precision H3: 0.7199121854064819, Recall H3: 0.5216841143647227, F1 Score H3: 0.6049740176148402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:08<00:00,  1.85s/it]\n",
      "Training: 100%|██████████| 231/231 [07:10<00:00,  1.86s/it]\n",
      "Training: 100%|██████████| 231/231 [07:07<00:00,  1.85s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.78it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.81it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/27\n",
      "H1: Train Loss: 1.2119, Val Loss: 0.9769, Accuracy: 0.9696\n",
      "Precision H1: 0.9696, Recall H1: 0.9696, F1 H1: 0.9696\n",
      "H2: Train Loss: 1.1469, Val Loss: 1.0676, Accuracy: 0.7985\n",
      "Precision H2: 0.7985, Recall H2: 0.7985, F1 H2: 0.7985\n",
      "H3: Train Loss: 1.0800, Val Loss: 1.1240, Custom Accuracy: 0.6999\n",
      "Precision H3: 0.710927032409922, Recall H3: 0.5520874140646003, F1 Score H3: 0.621519204324844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [06:55<00:00,  1.80s/it]\n",
      "Training: 100%|██████████| 231/231 [06:33<00:00,  1.70s/it]\n",
      "Training: 100%|██████████| 231/231 [06:54<00:00,  1.79s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.75it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.79it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:17<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/27\n",
      "H1: Train Loss: 0.9761, Val Loss: 0.8447, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.9039, Val Loss: 0.9245, Accuracy: 0.8859\n",
      "Precision H2: 0.8859, Recall H2: 0.8859, F1 H2: 0.8859\n",
      "H3: Train Loss: 0.8669, Val Loss: 0.9322, Custom Accuracy: 0.7031\n",
      "Precision H3: 0.6971392359225059, Recall H3: 0.581086393538865, F1 Score H3: 0.6338444716796243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:05<00:00,  1.84s/it]\n",
      "Training: 100%|██████████| 231/231 [07:04<00:00,  1.84s/it]\n",
      "Training: 100%|██████████| 231/231 [07:04<00:00,  1.84s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:17<00:00,  1.85it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.82it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/27\n",
      "H1: Train Loss: 0.8515, Val Loss: 0.7637, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.7394, Val Loss: 0.8869, Accuracy: 0.8973\n",
      "Precision H2: 0.8973, Recall H2: 0.8973, F1 H2: 0.8973\n",
      "H3: Train Loss: 0.7190, Val Loss: 0.8227, Custom Accuracy: 0.7087\n",
      "Precision H3: 0.706880318667391, Recall H3: 0.580160924837731, F1 Score H3: 0.6372823582728202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:13<00:00,  1.87s/it]\n",
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.68it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.72it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/27\n",
      "H1: Train Loss: 0.6903, Val Loss: 0.7573, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.6523, Val Loss: 0.8837, Accuracy: 0.9392\n",
      "Precision H2: 0.9392, Recall H2: 0.9392, F1 H2: 0.9392\n",
      "H3: Train Loss: 0.6495, Val Loss: 0.7521, Custom Accuracy: 0.7069\n",
      "Precision H3: 0.7239362665218179, Recall H3: 0.5392698028629588, F1 Score H3: 0.6181049587937832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:20<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:20<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:20<00:00,  1.91s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.71it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/27\n",
      "H1: Train Loss: 0.6259, Val Loss: 0.7708, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.6471, Val Loss: 0.8796, Accuracy: 0.9240\n",
      "Precision H2: 0.9240, Recall H2: 0.9240, F1 H2: 0.9240\n",
      "H3: Train Loss: 0.6227, Val Loss: 0.7294, Custom Accuracy: 0.7154\n",
      "Precision H3: 0.713279316796427, Recall H3: 0.5944761301225179, F1 Score H3: 0.6484813792128747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:19<00:00,  1.90s/it]\n",
      "Training: 100%|██████████| 231/231 [07:19<00:00,  1.90s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.67it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.68it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/27\n",
      "H1: Train Loss: 0.5978, Val Loss: 0.6817, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.5781, Val Loss: 0.7870, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.5846, Val Loss: 0.6923, Custom Accuracy: 0.7216\n",
      "Precision H3: 0.7129277566539924, Recall H3: 0.616568317613945, F1 Score H3: 0.6612560593568906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:13<00:00,  1.88s/it]\n",
      "Training: 100%|██████████| 231/231 [07:20<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:18<00:00,  1.90s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/27\n",
      "H1: Train Loss: 0.5778, Val Loss: 0.6742, Accuracy: 0.9962\n",
      "Precision H1: 0.9962, Recall H1: 0.9962, F1 H1: 0.9962\n",
      "H2: Train Loss: 0.5633, Val Loss: 0.7834, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.5749, Val Loss: 0.6985, Custom Accuracy: 0.7306\n",
      "Precision H3: 0.740543951190339, Recall H3: 0.6007570270878255, F1 Score H3: 0.6633663730210406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:19<00:00,  1.90s/it]\n",
      "Training: 100%|██████████| 231/231 [07:19<00:00,  1.90s/it]\n",
      "Training: 100%|██████████| 231/231 [07:20<00:00,  1.91s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.71it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.70it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/27\n",
      "H1: Train Loss: 0.5503, Val Loss: 0.7053, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.5271, Val Loss: 0.7954, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.5288, Val Loss: 0.6928, Custom Accuracy: 0.7341\n",
      "Precision H3: 0.7322695998551513, Recall H3: 0.6210676839003836, F1 Score H3: 0.6720999854680011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:19<00:00,  1.90s/it]\n",
      "Training: 100%|██████████| 231/231 [07:15<00:00,  1.89s/it]\n",
      "Training: 100%|██████████| 231/231 [07:17<00:00,  1.90s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.70it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.73it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/27\n",
      "H1: Train Loss: 0.5329, Val Loss: 0.7054, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.5187, Val Loss: 0.8312, Accuracy: 0.9316\n",
      "Precision H2: 0.9316, Recall H2: 0.9316, F1 H2: 0.9316\n",
      "H3: Train Loss: 0.5426, Val Loss: 0.6946, Custom Accuracy: 0.7417\n",
      "Precision H3: 0.7282379745307502, Recall H3: 0.6491628671286466, F1 Score H3: 0.6864306122084399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:20<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:22<00:00,  1.91s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.68it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.67it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/27\n",
      "H1: Train Loss: 0.5269, Val Loss: 0.7181, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.4991, Val Loss: 0.8316, Accuracy: 0.9430\n",
      "Precision H2: 0.9430, Recall H2: 0.9430, F1 H2: 0.9430\n",
      "H3: Train Loss: 0.5003, Val Loss: 0.6688, Custom Accuracy: 0.7464\n",
      "Precision H3: 0.7440959019856357, Recall H3: 0.6369424829500875, F1 Score H3: 0.6863622279199348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:20<00:00,  1.91s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.75it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/27\n",
      "H1: Train Loss: 0.4870, Val Loss: 0.6697, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.4815, Val Loss: 0.7918, Accuracy: 0.9430\n",
      "Precision H2: 0.9430, Recall H2: 0.9430, F1 H2: 0.9430\n",
      "H3: Train Loss: 0.4881, Val Loss: 0.6104, Custom Accuracy: 0.7587\n",
      "Precision H3: 0.7574956517922297, Recall H3: 0.6622699016235138, F1 Score H3: 0.7066893116060532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:20<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.73it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/27\n",
      "H1: Train Loss: 0.4840, Val Loss: 0.6878, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.5030, Val Loss: 0.7893, Accuracy: 0.9430\n",
      "Precision H2: 0.9430, Recall H2: 0.9430, F1 H2: 0.9430\n",
      "H3: Train Loss: 0.4798, Val Loss: 0.6033, Custom Accuracy: 0.7654\n",
      "Precision H3: 0.7563449119532769, Recall H3: 0.6782414037166888, F1 Score H3: 0.7151670543261766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:13<00:00,  1.88s/it]\n",
      "Training: 100%|██████████| 231/231 [07:19<00:00,  1.90s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.73it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/27\n",
      "H1: Train Loss: 0.4700, Val Loss: 0.6391, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.4505, Val Loss: 0.7553, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.4486, Val Loss: 0.5917, Custom Accuracy: 0.7827\n",
      "Precision H3: 0.7783785289488712, Recall H3: 0.7036941934280337, F1 Score H3: 0.7391546215518023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:19<00:00,  1.90s/it]\n",
      "Training: 100%|██████████| 231/231 [07:20<00:00,  1.91s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:18<00:00,  1.76it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/27\n",
      "H1: Train Loss: 0.4306, Val Loss: 0.5964, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.4156, Val Loss: 0.7023, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.4156, Val Loss: 0.5455, Custom Accuracy: 0.7985\n",
      "Precision H3: 0.7902998881135762, Recall H3: 0.7293204999478764, F1 Score H3: 0.7585867023579781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:19<00:00,  1.90s/it]\n",
      "Training: 100%|██████████| 231/231 [07:19<00:00,  1.90s/it]\n",
      "Training: 100%|██████████| 231/231 [07:13<00:00,  1.88s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.73it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.73it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/27\n",
      "H1: Train Loss: 0.4007, Val Loss: 0.5873, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.3745, Val Loss: 0.6879, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.3728, Val Loss: 0.5107, Custom Accuracy: 0.8204\n",
      "Precision H3: 0.820219989136339, Recall H3: 0.7520384452893958, F1 Score H3: 0.784650858814666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:18<00:00,  1.90s/it]\n",
      "Training: 100%|██████████| 231/231 [07:19<00:00,  1.90s/it]\n",
      "Training: 100%|██████████| 231/231 [07:19<00:00,  1.90s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.71it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/27\n",
      "H1: Train Loss: 0.3721, Val Loss: 0.5099, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.3467, Val Loss: 0.6442, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.3523, Val Loss: 0.4978, Custom Accuracy: 0.8347\n",
      "Precision H3: 0.8459489918615394, Recall H3: 0.7548687581957543, F1 Score H3: 0.7978178214985627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:01<00:00,  1.83s/it]\n",
      "Training: 100%|██████████| 231/231 [06:20<00:00,  1.65s/it]\n",
      "Training: 100%|██████████| 231/231 [06:19<00:00,  1.64s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.32it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.31it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/27\n",
      "H1: Train Loss: 0.3474, Val Loss: 0.5134, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.3408, Val Loss: 0.6373, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.3334, Val Loss: 0.4590, Custom Accuracy: 0.8391\n",
      "Precision H3: 0.8289590637499383, Recall H3: 0.7879100620545487, F1 Score H3: 0.8079134877845063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [06:19<00:00,  1.64s/it]\n",
      "Training: 100%|██████████| 231/231 [06:19<00:00,  1.64s/it]\n",
      "Training: 100%|██████████| 231/231 [06:19<00:00,  1.64s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.32it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.31it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/27\n",
      "H1: Train Loss: 0.3161, Val Loss: 0.4289, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.2914, Val Loss: 0.5731, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.2852, Val Loss: 0.4295, Custom Accuracy: 0.8739\n",
      "Precision H3: 0.8860249699603312, Recall H3: 0.8066294394241161, F1 Score H3: 0.8444651440630195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [06:19<00:00,  1.64s/it]\n",
      "Training: 100%|██████████| 231/231 [06:19<00:00,  1.64s/it]\n",
      "Training: 100%|██████████| 231/231 [06:20<00:00,  1.65s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.33it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.31it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/27\n",
      "H1: Train Loss: 0.2796, Val Loss: 0.4305, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.2596, Val Loss: 0.5902, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.2537, Val Loss: 0.3821, Custom Accuracy: 0.8906\n",
      "Precision H3: 0.8800078459774276, Recall H3: 0.8673317915713352, F1 Score H3: 0.8736238396321891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [06:19<00:00,  1.64s/it]\n",
      "Training: 100%|██████████| 231/231 [06:19<00:00,  1.64s/it]\n",
      "Training: 100%|██████████| 231/231 [06:19<00:00,  1.64s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.33it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.31it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:14<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/27\n",
      "H1: Train Loss: 0.2411, Val Loss: 0.4150, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.2350, Val Loss: 0.5889, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.2876, Val Loss: 0.4215, Custom Accuracy: 0.8886\n",
      "Precision H3: 0.9124539803247028, Recall H3: 0.8217975518355747, F1 Score H3: 0.8647562747249352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [06:20<00:00,  1.65s/it]\n",
      "Training: 100%|██████████| 231/231 [07:14<00:00,  1.88s/it]\n",
      "Training: 100%|██████████| 231/231 [08:52<00:00,  2.30s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:20<00:00,  1.63it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:20<00:00,  1.64it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:20<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/27\n",
      "H1: Train Loss: 0.2320, Val Loss: 0.3759, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.2061, Val Loss: 0.5336, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.1972, Val Loss: 0.3354, Custom Accuracy: 0.9172\n",
      "Precision H3: 0.927110869696421, Recall H3: 0.8772252673393358, F1 Score H3: 0.9014784593947642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [08:01<00:00,  2.09s/it]\n",
      "Training: 100%|██████████| 231/231 [06:30<00:00,  1.69s/it]\n",
      "Training: 100%|██████████| 231/231 [07:22<00:00,  1.92s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.71it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.72it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/27\n",
      "H1: Train Loss: 0.1876, Val Loss: 0.3562, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.1713, Val Loss: 0.5203, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.1695, Val Loss: 0.3065, Custom Accuracy: 0.9292\n",
      "Precision H3: 0.9293273583197538, Recall H3: 0.9040587844770355, F1 Score H3: 0.9165189398259069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:22<00:00,  1.92s/it]\n",
      "Training: 100%|██████████| 231/231 [07:23<00:00,  1.92s/it]\n",
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.67it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.71it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/27\n",
      "H1: Train Loss: 0.1652, Val Loss: 0.3181, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.1514, Val Loss: 0.4644, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.1473, Val Loss: 0.2783, Custom Accuracy: 0.9430\n",
      "Precision H3: 0.9440114068441064, Recall H3: 0.9148983040618021, F1 Score H3: 0.9292268796807475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:23<00:00,  1.92s/it]\n",
      "Training: 100%|██████████| 231/231 [07:22<00:00,  1.92s/it]\n",
      "Training: 100%|██████████| 231/231 [07:22<00:00,  1.91s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.68it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.70it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/27\n",
      "H1: Train Loss: 0.1400, Val Loss: 0.3181, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.1265, Val Loss: 0.4555, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.1277, Val Loss: 0.2521, Custom Accuracy: 0.9517\n",
      "Precision H3: 0.9502836622608485, Recall H3: 0.9341994085340092, F1 Score H3: 0.9421728950307524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:20<00:00,  1.91s/it]\n",
      "Training: 100%|██████████| 231/231 [07:21<00:00,  1.91s/it]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.72it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:19<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/27\n",
      "H1: Train Loss: 0.1222, Val Loss: 0.3216, Accuracy: 0.9924\n",
      "Precision H1: 0.9924, Recall H1: 0.9924, F1 H1: 0.9924\n",
      "H2: Train Loss: 0.1078, Val Loss: 0.4787, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.1074, Val Loss: 0.2564, Custom Accuracy: 0.9629\n",
      "Precision H3: 0.9603129337920212, Recall H3: 0.9481018769992154, F1 Score H3: 0.9541683389654182\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Now import your GPU-related libraries, such as PyTorch\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "# Import libraries and set up CUDA\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_seed = 777  # You can change this value to any seed you prefer\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "\n",
    "# Load and preprocess your data for H1, H2, and H3\n",
    "model1_data = pd.read_csv(\"model1_2636.csv\")\n",
    "texts_h1 = model1_data['text'].tolist()\n",
    "labels_h1 = model1_data.iloc[:, 1].values.tolist()\n",
    "\n",
    "model2_data = pd.read_csv(\"model2_2636.csv\")\n",
    "texts_h2 = model2_data['text'].tolist()\n",
    "labels_h2 = model2_data.iloc[:, 1].values.tolist()\n",
    "\n",
    "model3_data = pd.read_csv(\"model3_2636.csv\")\n",
    "texts_h3 = model3_data['text'].tolist()\n",
    "labels_h3 = model3_data.iloc[:, 1:].values.tolist()\n",
    "\n",
    "#print(\"Total Records in H1:\", len(texts_h1),\"texts_h1\", \"with\", len(labels_h1), \"labels\")\n",
    "#print(\"Total Records in H2:\", len(texts_h2),\"texts_h2\",\"with\", len(labels_h2), \"labels\")\n",
    "#print(\"Total Records in H3:\", len(texts_h3),\"texts_h3\", \"with\", len(labels_h3), \"labels\")\n",
    "\n",
    "# Split the data for each hierarchy\n",
    "def split_data(texts, labels, train_ratio, val_ratio, test_ratio):\n",
    "    total_samples = len(texts)\n",
    "    train_size = int(total_samples * train_ratio)\n",
    "    val_size = int(total_samples * val_ratio)\n",
    "    test_size = total_samples - train_size - val_size  # Remaining samples for test\n",
    "\n",
    "    train_texts = texts[:train_size]\n",
    "    val_texts = texts[train_size:train_size + val_size]\n",
    "    test_texts = texts[train_size + val_size:]\n",
    "\n",
    "    train_labels = labels[:train_size]\n",
    "    val_labels = labels[train_size:train_size + val_size]\n",
    "    test_labels = labels[train_size + val_size:]\n",
    "\n",
    "    return train_texts, val_texts, test_texts, train_labels, val_labels, test_labels\n",
    "\n",
    "# Split the data for each hierarchy\n",
    "train_texts_h1, val_texts_h1, test_texts_h1, train_labels_h1, val_labels_h1, test_labels_h1 = split_data(texts_h1, labels_h1, 0.7, 0.1, 0.2)\n",
    "train_texts_h2, val_texts_h2, test_texts_h2, train_labels_h2, val_labels_h2, test_labels_h2 = split_data(texts_h2, labels_h2, 0.7, 0.1, 0.2)\n",
    "train_texts_h3, val_texts_h3, test_texts_h3, train_labels_h3, val_labels_h3, test_labels_h3 = split_data(texts_h3, labels_h3, 0.7, 0.1, 0.2)\n",
    "\n",
    "#print(\"Train Val Test Splitting:\")\n",
    "#print(\"H1:\", len(train_texts_h1), len(val_texts_h1), len(test_texts_h1))\n",
    "#print(\"H2:\", len(train_texts_h2), len(val_texts_h2), len(test_texts_h2))\n",
    "#print(\"H3:\", len(train_texts_h3), len(val_texts_h3), len(test_texts_h3))\n",
    "\n",
    "# Tokenizer\n",
    "\n",
    "# Initialize the Clinical-Longformer tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\")\n",
    "clinical_longformer_model = AutoModel.from_pretrained(\"yikuan8/Clinical-Longformer\")\n",
    "\n",
    "\n",
    "# Define the TextDataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Now expecting a list of binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    # Rest of the code remains unchanged\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Create datasets and dataloaders for H1, H2, and H3\n",
    "dataset_h1 = TextDataset(train_texts_h1 + val_texts_h1 + test_texts_h1, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "dataset_h2 = TextDataset(train_texts_h2 + val_texts_h2 + test_texts_h2, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "dataset_h3 = TextDataset(train_texts_h3 + val_texts_h3 + test_texts_h3, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "\n",
    "# Split the datasets into train, val, and test for H1, H2, and H3\n",
    "train_size_h1 = len(train_texts_h1)\n",
    "val_size_h1 = len(val_texts_h1)\n",
    "train_size_h2 = len(train_texts_h2)\n",
    "val_size_h2 = len(val_texts_h2)\n",
    "train_size_h3 = len(train_texts_h3)\n",
    "val_size_h3 = len(val_texts_h3)\n",
    "\n",
    "train_dataset_h1, val_dataset_h1, test_dataset_h1 = random_split(dataset_h1, [train_size_h1, val_size_h1, len(test_texts_h1)])\n",
    "train_dataset_h2, val_dataset_h2, test_dataset_h2 = random_split(dataset_h2, [train_size_h2, val_size_h2, len(test_texts_h2)])\n",
    "train_dataset_h3, val_dataset_h3, test_dataset_h3 = random_split(dataset_h3, [train_size_h3, val_size_h3, len(test_texts_h3)])\n",
    "\n",
    "# Create dataloaders for H1, H2, and H3\n",
    "train_dataloader_h1 = DataLoader(train_dataset_h1, batch_size=8, shuffle=True)\n",
    "val_dataloader_h1 = DataLoader(val_dataset_h1,batch_size=8, shuffle=False)  # You can set shuffle to True if you want to shuffle the validation data.\n",
    "train_dataloader_h2 = DataLoader(train_dataset_h2, batch_size=8, shuffle=True)\n",
    "val_dataloader_h2 = DataLoader(val_dataset_h2, batch_size=8, shuffle=False)\n",
    "\n",
    "train_dataloader_h3 = DataLoader(train_dataset_h3, batch_size=8, shuffle=True)\n",
    "val_dataloader_h3 = DataLoader(val_dataset_h3, batch_size=8, shuffle=False)\n",
    "\n",
    "# Define the model architecture for H1, H2, and H3\n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.longformer = clinical_longformer_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc_h1 = nn.Linear(self.longformer.config.hidden_size, 1)\n",
    "        self.fc_h2 = nn.Linear(self.longformer.config.hidden_size, 1)\n",
    "        self.fc_h3 = nn.Linear(self.longformer.config.hidden_size, num_labels_h3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.longformer(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Assuming using the [CLS] token's representation\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "model = HierarchicalClassifier(num_labels_h3=len(train_labels_h3[0]))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)  # You can adjust the learning rate as needed\n",
    "\n",
    "# Training loop for H1, H2, and H3\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader), desc=\"Training\"):\n",
    "        input_ids = batch['ids'].to(device)\n",
    "        attention_mask = batch['mask'].to(device)\n",
    "        labels_h1 = batch['labels_h1'].to(device)\n",
    "        labels_h2 = batch['labels_h2'].to(device)\n",
    "        labels_h3 = batch['labels_h3'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "        loss_h1 = criterion(logits_h1, labels_h1)\n",
    "        loss_h2 = criterion(logits_h2, labels_h2)\n",
    "        loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "        loss = loss_h1 + loss_h2 + loss_h3\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Validation loop for H1, H2, and H3\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Validation\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels_h1 = batch['labels_h1'].to(device)\n",
    "            labels_h2 = batch['labels_h2'].to(device)\n",
    "            labels_h3 = batch['labels_h3'].to(device)\n",
    "\n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "# Training and evaluation for H1, H2, and H3\n",
    "# Custom accuracy function\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_labels = np.sum(np.equal(y_true, y_pred), axis=1)\n",
    "    total_labels = y_true.shape[1]\n",
    "    sample_accuracy = np.mean(correct_labels / total_labels)\n",
    "    return sample_accuracy\n",
    "\n",
    "def custom_precision_recall_f1(y_true, y_pred):\n",
    "    # Calculate precision and recall for each sample\n",
    "    sample_precisions = []\n",
    "    sample_recalls = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_positive = np.sum((true == 1) & (pred == 1))\n",
    "        false_positive = np.sum((true == 0) & (pred == 1))\n",
    "        false_negative = np.sum((true == 1) & (pred == 0))\n",
    "        \n",
    "        sample_precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "        sample_recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "        \n",
    "        sample_precisions.append(sample_precision)\n",
    "        sample_recalls.append(sample_recall)\n",
    "    \n",
    "    # Calculate average precision and recall across all samples\n",
    "    avg_precision = np.mean(sample_precisions)\n",
    "    avg_recall = np.mean(sample_recalls)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    if avg_precision + avg_recall > 0:\n",
    "        avg_f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
    "    else:\n",
    "        avg_f1 = 0\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "\n",
    "# Training and evaluation for H1, H2, and H3\n",
    "num_epochs = 27 # Adjusted to 27 epochs\n",
    "\n",
    "# Initialize lists to store training and validation accuracies\n",
    "train_accuracies_h1, val_accuracies_h1 = [], []\n",
    "train_accuracies_h2, val_accuracies_h2 = [], []\n",
    "train_accuracies_h3, val_accuracies_h3 = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training for H1\n",
    "    train_loss_h1 = train(model, train_dataloader_h1, optimizer, criterion, device)\n",
    "    # Training for H2\n",
    "    train_loss_h2 = train(model, train_dataloader_h2, optimizer, criterion, device)\n",
    "    # Training for H3\n",
    "    train_loss_h3 = train(model, train_dataloader_h3, optimizer, criterion, device)\n",
    "\n",
    "    # Validation for H1\n",
    "    val_loss_h1, val_preds_h1, _, _, val_labels_h1, _, _ = evaluate(model, val_dataloader_h1, criterion, device)\n",
    "    # Validation for H2\n",
    "    val_loss_h2, _, val_preds_h2, _, _, val_labels_h2, _ = evaluate(model, val_dataloader_h2, criterion, device)\n",
    "    # Validation for H3\n",
    "    val_loss_h3, _, _, val_preds_h3, _, _, val_labels_h3 = evaluate(model, val_dataloader_h3, criterion, device)\n",
    "\n",
    "    # Metrics calculation for H1\n",
    "    threshold_h1 = 0.5\n",
    "    val_preds_h1_binary = (np.array(val_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "    acc_h1 = accuracy_score(val_labels_h1, val_preds_h1_binary)\n",
    "    precision_h1 = precision_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    recall_h1 = recall_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    f1_h1 = f1_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "\n",
    "    # Store accuracies\n",
    "    train_accuracies_h1.append(acc_h1)\n",
    "    val_accuracies_h1.append(acc_h1)\n",
    "\n",
    "    # Metrics calculation for H2\n",
    "    threshold_h2 = 0.5\n",
    "    val_preds_h2_binary = (np.array(val_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "    acc_h2 = accuracy_score(val_labels_h2, val_preds_h2_binary)\n",
    "    precision_h2 = precision_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    recall_h2 = recall_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    f1_h2 = f1_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "\n",
    "    # Store accuracies\n",
    "    train_accuracies_h2.append(acc_h2)\n",
    "    val_accuracies_h2.append(acc_h2)\n",
    "\n",
    "    # Metrics calculation for H3\n",
    "    threshold_h3 = 0.5\n",
    "    val_preds_h3_binary = (np.array(val_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "    # Custom accuracy calculation for H3\n",
    "    acc_h3_custom = custom_accuracy(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "    precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "\n",
    "    # Store accuracies\n",
    "    train_accuracies_h3.append(acc_h3_custom)\n",
    "    val_accuracies_h3.append(acc_h3_custom)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"H1: Train Loss: {train_loss_h1:.4f}, Val Loss: {val_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "    print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "    print(f\"H2: Train Loss: {train_loss_h2:.4f}, Val Loss: {val_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "    print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "    print(f\"H3: Train Loss: {train_loss_h3:.4f}, Val Loss: {val_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "    print(f\"Precision H3: {precision_h3}, Recall H3: {recall_h3}, F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies_h1, label='Training Accuracy H1')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies_h1, label='Validation Accuracy H1')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy for H1')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies_h2, label='Training Accuracy H2')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies_h2, label='Validation Accuracy H2')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy for H2')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies_h3, label='Training Accuracy H3')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies_h3, label='Validation Accuracy H3')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy for H3')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Saving the model\n",
    "torch.save(model.state_dict(), 'model_Clinical-Longformer_V1.pth')\n",
    "\n",
    "# Loading the model\n",
    "#loaded_model = YourModelClass(*args, **kwargs)  # Instantiate your model\n",
    "#loaded_model.load_state_dict(torch.load('model.pth'))\n",
    "#loaded_model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Testing: 100%|██████████| 330/330 [02:21<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics for H1: Accuracy: 0.9958, Precision: 0.9958, Recall: 0.9958, F1: 0.9958\n",
      "Test Metrics for H2: Accuracy: 0.9890, Precision: 0.9890, Recall: 0.9890, F1: 0.9890\n",
      "Test Metrics for H3: Custom Accuracy: 0.9849, Precision: 0.9844, Recall: 0.9793, F1: 0.9819\n"
     ]
    }
   ],
   "source": [
    "#ORIGINAL TEST FINAL\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, LongformerModel, LongformerConfig\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the HierarchicalClassifier class (adjusted dropout for regularization)\n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        # Ensure proper loading of the pretrained model\n",
    "        self.longformer = AutoModel.from_pretrained(\"yikuan8/Clinical-Longformer\")\n",
    "        self.dropout = nn.Dropout(0.4)  # Moderated dropout rate for regularization\n",
    "        self.fc_h1 = nn.Linear(self.longformer.config.hidden_size, 1)\n",
    "        self.fc_h2 = nn.Linear(self.longformer.config.hidden_size, 1)\n",
    "        self.fc_h3 = nn.Linear(self.longformer.config.hidden_size, num_labels_h3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.longformer(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Using the [CLS] token's representation\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "# Define the TextDataset class (same as the one used for training)\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Load your test data\n",
    "test_data_h1 = pd.read_csv(\"model1_2636.csv\")\n",
    "texts_h1 = test_data_h1['text'].tolist()\n",
    "labels_h1 = test_data_h1.iloc[:, 1].values.tolist()\n",
    "\n",
    "test_data_h2 = pd.read_csv(\"model2_2636.csv\")\n",
    "texts_h2 = test_data_h2['text'].tolist()\n",
    "labels_h2 = test_data_h2.iloc[:, 1].values.tolist()\n",
    "\n",
    "test_data_h3 = pd.read_csv(\"model3_2636.csv\")\n",
    "texts_h3 = test_data_h3['text'].tolist()\n",
    "labels_h3 = test_data_h3.iloc[:, 1:].values.tolist()\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\")\n",
    "\n",
    "# Create test datasets and dataloaders\n",
    "test_dataset_h1 = TextDataset(texts_h1, labels_h1, labels_h2, labels_h3, tokenizer)\n",
    "test_dataset_h2 = TextDataset(texts_h2, labels_h1, labels_h2, labels_h3, tokenizer)\n",
    "test_dataset_h3 = TextDataset(texts_h3, labels_h1, labels_h2, labels_h3, tokenizer)\n",
    "\n",
    "test_dataloader_h1 = DataLoader(test_dataset_h1, batch_size=8, shuffle=False)\n",
    "test_dataloader_h2 = DataLoader(test_dataset_h2, batch_size=8, shuffle=False)\n",
    "test_dataloader_h3 = DataLoader(test_dataset_h3, batch_size=8, shuffle=False)\n",
    "\n",
    "# Initialize and load the model\n",
    "num_labels_h3 = len(labels_h3[0])\n",
    "model = HierarchicalClassifier(num_labels_h3=num_labels_h3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load('model_Clinical-Longformer_V1.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Testing\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels_h1 = batch['labels_h1'].to(device)\n",
    "            labels_h2 = batch['labels_h2'].to(device)\n",
    "            labels_h3 = batch['labels_h3'].to(device)\n",
    "\n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "# Run evaluation\n",
    "all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3 = evaluate(model, test_dataloader_h3, device)\n",
    "\n",
    "# Define threshold\n",
    "threshold_h1 = 0.9\n",
    "threshold_h2 = 0.8\n",
    "threshold_h3 = 0.5\n",
    "\n",
    "# Convert predictions to binary values based on threshold\n",
    "preds_h1_binary = (np.array(all_preds_h1) > threshold_h1).astype(int)\n",
    "preds_h2_binary = (np.array(all_preds_h2) > threshold_h2).astype(int)\n",
    "preds_h3_binary = (np.array(all_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_h1 = accuracy_score(all_labels_h1, preds_h1_binary)\n",
    "precision_h1 = precision_score(all_labels_h1, preds_h1_binary, average='micro')\n",
    "recall_h1 = recall_score(all_labels_h1, preds_h1_binary, average='micro')\n",
    "f1_h1 = f1_score(all_labels_h1, preds_h1_binary, average='micro')\n",
    "\n",
    "accuracy_h2 = accuracy_score(all_labels_h2, preds_h2_binary)\n",
    "precision_h2 = precision_score(all_labels_h2, preds_h2_binary, average='micro')\n",
    "recall_h2 = recall_score(all_labels_h2, preds_h2_binary, average='micro')\n",
    "f1_h2 = f1_score(all_labels_h2, preds_h2_binary, average='micro')\n",
    "\n",
    "# Custom accuracy function for H3\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_labels = np.sum(np.equal(y_true, y_pred), axis=1)\n",
    "    total_labels = y_true.shape[1]\n",
    "    sample_accuracy = np.mean(correct_labels / total_labels)\n",
    "    return sample_accuracy\n",
    "\n",
    "def custom_precision_recall_f1(y_true, y_pred):\n",
    "    # Calculate precision and recall for each sample\n",
    "    sample_precisions = []\n",
    "    sample_recalls = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_positive = np.sum((true == 1) & (pred == 1))\n",
    "        false_positive = np.sum((true == 0) & (pred == 1))\n",
    "        false_negative = np.sum((true == 1) & (pred == 0))\n",
    "        \n",
    "        sample_precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "        sample_recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "        \n",
    "        sample_precisions.append(sample_precision)\n",
    "        sample_recalls.append(sample_recall)\n",
    "    \n",
    "    # Calculate average precision and recall across all samples\n",
    "    avg_precision = np.mean(sample_precisions)\n",
    "    avg_recall = np.mean(sample_recalls)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    if avg_precision + avg_recall > 0:\n",
    "        avg_f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
    "    else:\n",
    "        avg_f1 = 0\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "accuracy_h3_custom = custom_accuracy(np.array(all_labels_h3), preds_h3_binary)\n",
    "precision_h3, recall_h3, f1_h3 = custom_precision_recall_f1(np.array(all_labels_h3), preds_h3_binary)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Test Metrics for H1: Accuracy: {accuracy_h1:.4f}, Precision: {precision_h1:.4f}, Recall: {recall_h1:.4f}, F1: {f1_h1:.4f}\")\n",
    "print(f\"Test Metrics for H2: Accuracy: {accuracy_h2:.4f}, Precision: {precision_h2:.4f}, Recall: {recall_h2:.4f}, F1: {f1_h2:.4f}\")\n",
    "print(f\"Test Metrics for H3: Custom Accuracy: {accuracy_h3_custom:.4f}, Precision: {precision_h3:.4f}, Recall: {recall_h3:.4f}, F1: {f1_h3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 16/16 [00:06<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Results:\n",
      "H1: Val Loss: 0.6143, Accuracy: 0.9844\n",
      "Precision H1: 0.9844, Recall H1: 0.9844, F1 H1: 0.9844\n",
      "H2: Val Loss: 0.6143, Accuracy: 0.9922\n",
      "Precision H2: 0.9922, Recall H2: 0.9922, F1 H2: 0.9922\n",
      "H3: Val Loss: 0.6143, Custom Accuracy: 0.8450\n",
      "Precision H3: 0.6844, Recall H3:0.8614, F1 H3: 0.7627\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 16/16 [00:06<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Results:\n",
      "H1: Val Loss: 0.5276, Accuracy: 0.9922\n",
      "Precision H1: 0.9922, Recall H1: 0.9922, F1 H1: 0.9922\n",
      "H2: Val Loss: 0.5276, Accuracy: 0.9609\n",
      "Precision H2: 0.9609, Recall H2: 0.9609, F1 H2: 0.9609\n",
      "H3: Val Loss: 0.5276, Custom Accuracy: 0.9501\n",
      "Precision H3: 0.9092, Recall H3:0.9303, F1 H3: 0.9196\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 16/16 [00:06<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Results:\n",
      "H1: Val Loss: 0.4983, Accuracy: 0.9844\n",
      "Precision H1: 0.9844, Recall H1: 0.9844, F1 H1: 0.9844\n",
      "H2: Val Loss: 0.4983, Accuracy: 0.9922\n",
      "Precision H2: 0.9922, Recall H2: 0.9922, F1 H2: 0.9922\n",
      "H3: Val Loss: 0.4983, Custom Accuracy: 0.8810\n",
      "Precision H3: 0.7759, Recall H3:0.9016, F1 H3: 0.8341\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 16/16 [00:06<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Results:\n",
      "H1: Val Loss: 0.7243, Accuracy: 0.9922\n",
      "Precision H1: 0.9922, Recall H1: 0.9922, F1 H1: 0.9922\n",
      "H2: Val Loss: 0.7243, Accuracy: 0.9609\n",
      "Precision H2: 0.9609, Recall H2: 0.9609, F1 H2: 0.9609\n",
      "H3: Val Loss: 0.7243, Custom Accuracy: 0.8942\n",
      "Precision H3: 0.7816, Recall H3:0.8806, F1 H3: 0.8281\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 16/16 [00:06<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Results:\n",
      "H1: Val Loss: 0.6087, Accuracy: 0.9766\n",
      "Precision H1: 0.9766, Recall H1: 0.9766, F1 H1: 0.9766\n",
      "H2: Val Loss: 0.6087, Accuracy: 0.9531\n",
      "Precision H2: 0.9531, Recall H2: 0.9531, F1 H2: 0.9531\n",
      "H3: Val Loss: 0.6087, Custom Accuracy: 0.9345\n",
      "Precision H3: 0.8939, Recall H3:0.9524, F1 H3: 0.9222\n",
      "Average Results across 5 folds:\n",
      "H1: Accuracy: 0.9859, Precision: 0.9859, Recall: 0.9859, F1: 0.9859\n",
      "H2: Accuracy: 0.9719, Precision: 0.9719, Recall: 0.9719, F1: 0.9719\n",
      "H3: Custom Accuracy: 0.9010, Precision: 0.8090, Recall: 0.9052, F1: 0.8534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#UNSEEN FINAL P2\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Function to load CSV with error handling for encoding issues and bad lines\n",
    "def load_csv_with_fallback(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'cp1252']\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=enc, on_bad_lines='skip')\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(f\"Failed to read the file {file_path} with available encodings.\")\n",
    "\n",
    "# Loading and preprocessing new_data_h1\n",
    "new_data_h1 = load_csv_with_fallback(\"113_H_100_O_NEWMODEL1.csv\")\n",
    "new_data_h1['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h1 = new_data_h1['text'].tolist()\n",
    "new_labels_h1 = new_data_h1.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h2\n",
    "new_data_h2 = load_csv_with_fallback(\"113_H_100_O_NEWMODEL2.csv\")\n",
    "new_data_h2['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h2 = new_data_h2['text'].tolist()\n",
    "new_labels_h2 = new_data_h2.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h3 for multi-label classification\n",
    "new_data_h3 = load_csv_with_fallback(\"113_H_100_O_NEWMODEL3.csv\")\n",
    "new_data_h3['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "\n",
    "# Replace NaN values in label columns with 0 for new_data_h3\n",
    "# Assuming all label columns are binary, fill NaN values with 0\n",
    "for label_col in new_data_h3.columns[1:]:  # Skip the text column, only fill NaN in label columns\n",
    "    new_data_h3[label_col].fillna(0, inplace=True)\n",
    "\n",
    "new_texts_h3 = new_data_h3['text'].tolist()\n",
    "new_labels_h3 = new_data_h3.iloc[:, 1:].values.tolist()  # Extract labels after filling NaN values\n",
    "\n",
    "# Initialize the Clinical-Longformer tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\")\n",
    "clinical_longformer_model = AutoModel.from_pretrained(\"yikuan8/Clinical-Longformer\")\n",
    "\n",
    "# Define the TextDataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Now expecting a list of binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Define the model architecture for H1, H2, and H3\n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.longformer = clinical_longformer_model\n",
    "        self.dropout = nn.Dropout(0.5)  # Increased dropout rate\n",
    "        self.fc_h1 = nn.Linear(self.longformer.config.hidden_size, 1)\n",
    "        self.fc_h2 = nn.Linear(self.longformer.config.hidden_size, 1)\n",
    "        self.fc_h3 = nn.Linear(self.longformer.config.hidden_size, num_labels_h3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.longformer(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Assuming using the [CLS] token's representation\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'model_Clinical-Longformer_V1.pth'  # Path to your saved model\n",
    "model = HierarchicalClassifier(num_labels_h3=len(new_labels_h3[0]))\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define the test function\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Testing\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            \n",
    "            # Ensuring labels are correctly shaped and moved to the device\n",
    "            labels_h1 = batch['labels_h1'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h2 = batch['labels_h2'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h3 = batch['labels_h3'].to(device)  # Shape: [batch_size, num_labels_h3]\n",
    "            \n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Compute loss for each hierarchy\n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert logits to probabilities for binary classification/multi-label classification\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            # Store predictions and labels for metric calculation\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Combine all data into a single dataset\n",
    "all_texts = new_texts_h1 + new_texts_h2 + new_texts_h3\n",
    "all_labels_h1 = new_labels_h1 + new_labels_h1 + new_labels_h1\n",
    "all_labels_h2 = new_labels_h2 + new_labels_h2 + new_labels_h2\n",
    "all_labels_h3 = new_labels_h3 + new_labels_h3 + new_labels_h3\n",
    "\n",
    "dataset = TextDataset(all_texts, all_labels_h1, all_labels_h2, all_labels_h3, tokenizer)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Subset the dataset for current fold\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    \n",
    "    # Create DataLoader for validation\n",
    "    val_dataloader = DataLoader(val_subset, batch_size=8, shuffle=False, drop_last=True)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_preds_h1, val_preds_h2, val_preds_h3, val_labels_h1, val_labels_h2, val_labels_h3 = test(model, val_dataloader, criterion, device)\n",
    "    \n",
    "    # Calculate metrics for H1\n",
    "    threshold_h1 = 0.5\n",
    "    val_preds_h1_binary = (np.array(val_preds_h1) > threshold_h1).astype(int)\n",
    "    acc_h1 = accuracy_score(val_labels_h1, val_preds_h1_binary)\n",
    "    precision_h1 = precision_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    recall_h1 = recall_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    f1_h1 = f1_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    \n",
    "    # Calculate metrics for H2\n",
    "    threshold_h2 = 0.9\n",
    "    val_preds_h2_binary = (np.array(val_preds_h2) > threshold_h2).astype(int)\n",
    "    acc_h2 = accuracy_score(val_labels_h2, val_preds_h2_binary)\n",
    "    precision_h2 = precision_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    recall_h2 = recall_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    f1_h2 = f1_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    \n",
    "    # Calculate metrics for H3\n",
    "    threshold_h3 = 0.5\n",
    "    val_preds_h3_binary = (np.array(val_preds_h3) > threshold_h3).astype(int)\n",
    "    acc_h3_custom = custom_accuracy(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "    precision_h3, recall_h3, f1_h3 = custom_precision_recall_f1(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Results:\")\n",
    "    print(f\"H1: Val Loss: {val_loss:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "    print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "    \n",
    "    print(f\"H2: Val Loss: {val_loss:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "    print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "    \n",
    "    print(f\"H3: Val Loss: {val_loss:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "    print(f\"Precision H3: {precision_h3:.4f}, Recall H3:{recall_h3:.4f}, F1 H3: {f1_h3:.4f}\")\n",
    "    \n",
    "    fold_results.append((acc_h1, precision_h1, recall_h1, f1_h1, acc_h2, precision_h2, recall_h2, f1_h2, acc_h3_custom, precision_h3, recall_h3, f1_h3))\n",
    "\n",
    "# Average results across folds\n",
    "avg_results = np.mean(fold_results, axis=0)\n",
    "print(f\"Average Results across {kf.n_splits} folds:\")\n",
    "print(f\"H1: Accuracy: {avg_results[0]:.4f}, Precision: {avg_results[1]:.4f}, Recall: {avg_results[2]:.4f}, F1: {avg_results[3]:.4f}\")\n",
    "print(f\"H2: Accuracy: {avg_results[4]:.4f}, Precision: {avg_results[5]:.4f}, Recall: {avg_results[6]:.4f}, F1: {avg_results[7]:.4f}\")\n",
    "print(f\"H3: Custom Accuracy: {avg_results[8]:.4f}, Precision: {avg_results[9]:.4f}, Recall: {avg_results[10]:.4f}, F1: {avg_results[11]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/mpagare/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: \n",
      "    Found GPU%d %s which is of cuda capability %d.%d.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is %d.%d.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn.format(d, name, major, minor, min_arch // 10, min_arch % 10))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:09<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Results:\n",
      "H1: Avg Loss: 0.9091, Accuracy: 0.8385\n",
      "Precision H1: 0.8385, Recall H1: 0.8385, F1 H1: 0.8385\n",
      "H2: Avg Loss: 1.7563, Accuracy: 0.5938\n",
      "Precision H2: 0.5938, Recall H2: 0.5938, F1 H2: 0.5938\n",
      "H3: Avg Loss: 0.7705, Custom Accuracy: 0.7071\n",
      "Precision H3: 0.6065, Recall H3:0.6651, F1 H3: 0.6344\n",
      "Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:09<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Results:\n",
      "H1: Avg Loss: 0.1382, Accuracy: 0.9688\n",
      "Precision H1: 0.9688, Recall H1: 0.9688, F1 H1: 0.9688\n",
      "H2: Avg Loss: 0.1095, Accuracy: 0.9427\n",
      "Precision H2: 0.9427, Recall H2: 0.9427, F1 H2: 0.9427\n",
      "H3: Avg Loss: 0.1763, Custom Accuracy: 0.9467\n",
      "Precision H3: 0.9398, Recall H3:0.9316, F1 H3: 0.9357\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:10<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Results:\n",
      "H1: Avg Loss: 0.0396, Accuracy: 0.9948\n",
      "Precision H1: 0.9948, Recall H1: 0.9948, F1 H1: 0.9948\n",
      "H2: Avg Loss: 0.0861, Accuracy: 0.9896\n",
      "Precision H2: 0.9896, Recall H2: 0.9896, F1 H2: 0.9896\n",
      "H3: Avg Loss: 0.0914, Custom Accuracy: 0.9856\n",
      "Precision H3: 0.9830, Recall H3:0.9833, F1 H3: 0.9831\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:09<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Results:\n",
      "H1: Avg Loss: 0.3017, Accuracy: 0.9479\n",
      "Precision H1: 0.9479, Recall H1: 0.9479, F1 H1: 0.9479\n",
      "H2: Avg Loss: 1.5395, Accuracy: 0.6667\n",
      "Precision H2: 0.6667, Recall H2: 0.6667, F1 H2: 0.6667\n",
      "H3: Avg Loss: 0.4848, Custom Accuracy: 0.8137\n",
      "Precision H3: 0.7377, Recall H3:0.7922, F1 H3: 0.7640\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:09<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Results:\n",
      "H1: Avg Loss: 0.7772, Accuracy: 0.8542\n",
      "Precision H1: 0.8542, Recall H1: 0.8542, F1 H1: 0.8542\n",
      "H2: Avg Loss: 0.3298, Accuracy: 0.8646\n",
      "Precision H2: 0.8646, Recall H2: 0.8646, F1 H2: 0.8646\n",
      "H3: Avg Loss: 0.4623, Custom Accuracy: 0.8421\n",
      "Precision H3: 0.8135, Recall H3:0.8064, F1 H3: 0.8100\n",
      "Fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:10<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 Results:\n",
      "H1: Avg Loss: 0.0041, Accuracy: 1.0000\n",
      "Precision H1: 1.0000, Recall H1: 1.0000, F1 H1: 1.0000\n",
      "H2: Avg Loss: 0.0858, Accuracy: 0.9896\n",
      "Precision H2: 0.9896, Recall H2: 0.9896, F1 H2: 0.9896\n",
      "H3: Avg Loss: 0.0937, Custom Accuracy: 0.9836\n",
      "Precision H3: 0.9790, Recall H3:0.9822, F1 H3: 0.9806\n",
      "Fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:09<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 Results:\n",
      "H1: Avg Loss: 0.0919, Accuracy: 0.9896\n",
      "Precision H1: 0.9896, Recall H1: 0.9896, F1 H1: 0.9896\n",
      "H2: Avg Loss: 1.0149, Accuracy: 0.7865\n",
      "Precision H2: 0.7865, Recall H2: 0.7865, F1 H2: 0.7865\n",
      "H3: Avg Loss: 0.2616, Custom Accuracy: 0.9099\n",
      "Precision H3: 0.8482, Recall H3:0.9095, F1 H3: 0.8778\n",
      "Fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:09<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 Results:\n",
      "H1: Avg Loss: 1.0243, Accuracy: 0.8073\n",
      "Precision H1: 0.8073, Recall H1: 0.8073, F1 H1: 0.8073\n",
      "H2: Avg Loss: 0.8207, Accuracy: 0.7552\n",
      "Precision H2: 0.7552, Recall H2: 0.7552, F1 H2: 0.7552\n",
      "H3: Avg Loss: 0.6843, Custom Accuracy: 0.7448\n",
      "Precision H3: 0.7006, Recall H3:0.6886, F1 H3: 0.6946\n",
      "Fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:10<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 Results:\n",
      "H1: Avg Loss: 0.0044, Accuracy: 1.0000\n",
      "Precision H1: 1.0000, Recall H1: 1.0000, F1 H1: 1.0000\n",
      "H2: Avg Loss: 0.0996, Accuracy: 0.9844\n",
      "Precision H2: 0.9844, Recall H2: 0.9844, F1 H2: 0.9844\n",
      "H3: Avg Loss: 0.0938, Custom Accuracy: 0.9832\n",
      "Precision H3: 0.9789, Recall H3:0.9807, F1 H3: 0.9798\n",
      "Fold 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 24/24 [00:10<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 Results:\n",
      "H1: Avg Loss: 0.0396, Accuracy: 0.9948\n",
      "Precision H1: 0.9948, Recall H1: 0.9948, F1 H1: 0.9948\n",
      "H2: Avg Loss: 0.0019, Accuracy: 1.0000\n",
      "Precision H2: 1.0000, Recall H2: 1.0000, F1 H2: 1.0000\n",
      "H3: Avg Loss: 0.0890, Custom Accuracy: 0.9872\n",
      "Precision H3: 0.9872, Recall H3:0.9840, F1 H3: 0.9856\n",
      "Average Results across 10 folds:\n",
      "H1: Avg Loss: 0.3330, Accuracy: 0.9396, Precision: 0.9396, Recall: 0.9396, F1: 0.9396\n",
      "H2: Avg Loss: 0.5844, Accuracy: 0.8573, Precision: 0.8573, Recall: 0.8573, F1: 0.8573\n",
      "H3: Avg Loss: 0.3208, Custom Accuracy: 0.8904, Precision: 0.8574, Recall: 0.8724, F1: 0.8646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#unseen chatgpt equivalent texts policy p3\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Function to load CSV with error handling for encoding issues and bad lines\n",
    "def load_csv_with_fallback(file_path):\n",
    "    encodings = ['utf-8', 'latin1', 'cp1252']\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=enc, on_bad_lines='skip')\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(f\"Failed to read the file {file_path} with available encodings.\")\n",
    "\n",
    "# Loading and preprocessing new_data_h1\n",
    "new_data_h1 = load_csv_with_fallback(\"P1_NEW2.csv\")\n",
    "new_data_h1['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h1 = new_data_h1['text'].tolist()\n",
    "new_labels_h1 = new_data_h1.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h2\n",
    "new_data_h2 = load_csv_with_fallback(\"P2_NEW2.csv\")\n",
    "new_data_h2['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h2 = new_data_h2['text'].tolist()\n",
    "new_labels_h2 = new_data_h2.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h3 for multi-label classification\n",
    "new_data_h3 = load_csv_with_fallback(\"P3_NEW2.csv\")\n",
    "new_data_h3['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "\n",
    "# Replace NaN values in label columns with 0 for new_data_h3\n",
    "for label_col in new_data_h3.columns[1:]:  # Skip the text column, only fill NaN in label columns\n",
    "    new_data_h3[label_col].fillna(0, inplace=True)\n",
    "\n",
    "new_texts_h3 = new_data_h3['text'].tolist()\n",
    "new_labels_h3 = new_data_h3.iloc[:, 1:].values.tolist()  # Extract labels after filling NaN values\n",
    "\n",
    "# Initialize the Clinical-Longformer tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-Longformer\")\n",
    "clinical_longformer_model = AutoModel.from_pretrained(\"yikuan8/Clinical-Longformer\")\n",
    "\n",
    "# Define the TextDataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Now expecting a list of binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Define the model architecture for H1, H2, and H3\n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.longformer = clinical_longformer_model\n",
    "        self.dropout = nn.Dropout(0.5)  # Increased dropout rate\n",
    "        self.fc_h1 = nn.Linear(self.longformer.config.hidden_size, 1)\n",
    "        self.fc_h2 = nn.Linear(self.longformer.config.hidden_size, 1)\n",
    "        self.fc_h3 = nn.Linear(self.longformer.config.hidden_size, num_labels_h3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.longformer(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Assuming using the [CLS] token's representation\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "# Custom accuracy function for H3\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_labels = np.sum(np.equal(y_true, y_pred), axis=1)\n",
    "    total_labels = y_true.shape[1]\n",
    "    sample_accuracy = np.mean(correct_labels / total_labels)\n",
    "    return sample_accuracy\n",
    "\n",
    "def custom_precision_recall_f1(y_true, y_pred):\n",
    "    # Calculate precision and recall for each sample\n",
    "    sample_precisions = []\n",
    "    sample_recalls = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_positive = np.sum((true == 1) & (pred == 1))\n",
    "        false_positive = np.sum((true == 0) & (pred == 1))\n",
    "        false_negative = np.sum((true == 1) & (pred == 0))\n",
    "        \n",
    "        sample_precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "        sample_recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "        \n",
    "        sample_precisions.append(sample_precision)\n",
    "        sample_recalls.append(sample_recall)\n",
    "    \n",
    "    # Calculate average precision and recall across all samples\n",
    "    avg_precision = np.mean(sample_precisions)\n",
    "    avg_recall = np.mean(sample_recalls)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    if avg_precision + avg_recall > 0:\n",
    "        avg_f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
    "    else:\n",
    "        avg_f1 = 0\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'model_Clinical-Longformer_V1.pth'  # Path to your saved model\n",
    "model = HierarchicalClassifier(num_labels_h3=len(new_labels_h3[0]))\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define the test function\n",
    "def test(model, dataloader, criterion_h1, criterion_h2, criterion_h3, device):\n",
    "    model.eval()\n",
    "    total_loss_h1 = 0.0\n",
    "    total_loss_h2 = 0.0\n",
    "    total_loss_h3 = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Testing\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            \n",
    "            labels_h1 = batch['labels_h1'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h2 = batch['labels_h2'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h3 = batch['labels_h3'].to(device)  # Shape: [batch_size, num_labels_h3]\n",
    "            \n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            \n",
    "            loss_h1 = criterion_h1(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion_h2(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion_h3(logits_h3, labels_h3)\n",
    "\n",
    "            total_loss_h1 += loss_h1.item()\n",
    "            total_loss_h2 += loss_h2.item()\n",
    "            total_loss_h3 += loss_h3.item()\n",
    "\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    avg_loss_h1 = total_loss_h1 / len(dataloader)\n",
    "    avg_loss_h2 = total_loss_h2 / len(dataloader)\n",
    "    avg_loss_h3 = total_loss_h3 / len(dataloader)\n",
    "\n",
    "    return avg_loss_h1, avg_loss_h2, avg_loss_h3, all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "all_texts = new_texts_h1 + new_texts_h2 + new_texts_h3\n",
    "all_labels_h1 = new_labels_h1 + new_labels_h1 + new_labels_h1\n",
    "all_labels_h2 = new_labels_h2 + new_labels_h2 + new_labels_h2\n",
    "all_labels_h3 = new_labels_h3 + new_labels_h3 + new_labels_h3\n",
    "\n",
    "dataset = TextDataset(all_texts, all_labels_h1, all_labels_h2, all_labels_h3, tokenizer)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "criterion_h1 = nn.BCEWithLogitsLoss()\n",
    "criterion_h2 = nn.BCEWithLogitsLoss()\n",
    "criterion_h3 = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    val_dataloader = DataLoader(val_subset, batch_size=8, shuffle=False, drop_last=True)\n",
    "    \n",
    "    avg_loss_h1, avg_loss_h2, avg_loss_h3, val_preds_h1, val_preds_h2, val_preds_h3, val_labels_h1, val_labels_h2, val_labels_h3 = test(model, val_dataloader, criterion_h1, criterion_h2, criterion_h3, device)\n",
    "    \n",
    "    threshold_h1 = 0.5\n",
    "    val_preds_h1_binary = (np.array(val_preds_h1) > threshold_h1).astype(int)\n",
    "    acc_h1 = accuracy_score(val_labels_h1, val_preds_h1_binary)\n",
    "    precision_h1 = precision_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    recall_h1 = recall_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    f1_h1 = f1_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    \n",
    "    threshold_h2 = 0.5\n",
    "    val_preds_h2_binary = (np.array(val_preds_h2) > threshold_h2).astype(int)\n",
    "    acc_h2 = accuracy_score(val_labels_h2, val_preds_h2_binary)\n",
    "    precision_h2 = precision_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    recall_h2 = recall_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    f1_h2 = f1_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    \n",
    "    threshold_h3 = 0.5\n",
    "    val_preds_h3_binary = (np.array(val_preds_h3) > threshold_h3).astype(int)\n",
    "    acc_h3_custom = custom_accuracy(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "    precision_h3, recall_h3, f1_h3 = custom_precision_recall_f1(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Results:\")\n",
    "    print(f\"H1: Avg Loss: {avg_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "    print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "    \n",
    "    print(f\"H2: Avg Loss: {avg_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "    print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "    \n",
    "    print(f\"H3: Avg Loss: {avg_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "    print(f\"Precision H3: {precision_h3:.4f}, Recall H3:{recall_h3:.4f}, F1 H3: {f1_h3:.4f}\")\n",
    "    \n",
    "    fold_results.append((avg_loss_h1, avg_loss_h2, avg_loss_h3, acc_h1, precision_h1, recall_h1, f1_h1, acc_h2, precision_h2, recall_h2, f1_h2, acc_h3_custom, precision_h3, recall_h3, f1_h3))\n",
    "\n",
    "# Average results across folds\n",
    "avg_results = np.mean(fold_results, axis=0)\n",
    "print(f\"Average Results across {kf.n_splits} folds:\")\n",
    "print(f\"H1: Avg Loss: {avg_results[0]:.4f}, Accuracy: {avg_results[3]:.4f}, Precision: {avg_results[4]:.4f}, Recall: {avg_results[5]:.4f}, F1: {avg_results[6]:.4f}\")\n",
    "print(f\"H2: Avg Loss: {avg_results[1]:.4f}, Accuracy: {avg_results[7]:.4f}, Precision: {avg_results[8]:.4f}, Recall: {avg_results[9]:.4f}, F1: {avg_results[10]:.4f}\")\n",
    "print(f\"H3: Avg Loss: {avg_results[2]:.4f}, Custom Accuracy: {avg_results[11]:.4f}, Precision: {avg_results[12]:.4f}, Recall: {avg_results[13]:.4f}, F1: {avg_results[14]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
