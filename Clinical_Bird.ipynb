{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Now import your GPU-related libraries, such as PyTorch\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpagare/.local/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/231 [00:00<?, ?it/s]Attention type 'block_sparse' is not possible if sequence_length: 512 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
      "Training: 100%|██████████| 231/231 [03:13<00:00,  1.19it/s]\n",
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:11<00:00,  1.21it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "H1: Train Loss: 1.7047, Val Loss: 1.3918, Accuracy: 0.9316\n",
      "Precision H1: 0.9316, Recall H1: 0.9316, F1 H1: 0.9316\n",
      "H2: Train Loss: 1.5215, Val Loss: 1.4247, Accuracy: 0.6578\n",
      "Precision H2: 0.6578, Recall H2: 0.6578, F1 H2: 0.6578\n",
      "H3: Train Loss: 1.4641, Val Loss: 1.4124, Custom Accuracy: 0.6727\n",
      "Precision H3: 0.6709487597320297,Recall H3:0.5243621714154034,F1 Score H3: 0.5886671649925109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/33\n",
      "H1: Train Loss: 1.4280, Val Loss: 1.3310, Accuracy: 0.9354\n",
      "Precision H1: 0.9354, Recall H1: 0.9354, F1 H1: 0.9354\n",
      "H2: Train Loss: 1.4019, Val Loss: 1.3621, Accuracy: 0.6768\n",
      "Precision H2: 0.6768, Recall H2: 0.6768, F1 H2: 0.6768\n",
      "H3: Train Loss: 1.3332, Val Loss: 1.3717, Custom Accuracy: 0.6748\n",
      "Precision H3: 0.6976552598225602,Recall H3:0.47852149962416124,F1 Score H3: 0.5676749493129188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:09<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/33\n",
      "H1: Train Loss: 1.2755, Val Loss: 1.1246, Accuracy: 0.9506\n",
      "Precision H1: 0.9506, Recall H1: 0.9506, F1 H1: 0.9506\n",
      "H2: Train Loss: 1.2329, Val Loss: 1.1284, Accuracy: 0.7795\n",
      "Precision H2: 0.7795, Recall H2: 0.7795, F1 H2: 0.7795\n",
      "H3: Train Loss: 1.1327, Val Loss: 1.1770, Custom Accuracy: 0.6868\n",
      "Precision H3: 0.6920876335325004,Recall H3:0.5183058175453613,F1 Score H3: 0.592721393843731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/33\n",
      "H1: Train Loss: 1.0595, Val Loss: 0.9583, Accuracy: 0.9658\n",
      "Precision H1: 0.9658, Recall H1: 0.9658, F1 H1: 0.9658\n",
      "H2: Train Loss: 1.0220, Val Loss: 1.0047, Accuracy: 0.8441\n",
      "Precision H2: 0.8441, Recall H2: 0.8441, F1 H2: 0.8441\n",
      "H3: Train Loss: 0.9619, Val Loss: 1.0143, Custom Accuracy: 0.6961\n",
      "Precision H3: 0.6760275212746697,Recall H3:0.560620188852128,F1 Score H3: 0.6129387917718001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/33\n",
      "H1: Train Loss: 0.8618, Val Loss: 0.8592, Accuracy: 0.9658\n",
      "Precision H1: 0.9658, Recall H1: 0.9658, F1 H1: 0.9658\n",
      "H2: Train Loss: 0.8370, Val Loss: 0.8992, Accuracy: 0.8935\n",
      "Precision H2: 0.8935, Recall H2: 0.8935, F1 H2: 0.8935\n",
      "H3: Train Loss: 0.7818, Val Loss: 0.9633, Custom Accuracy: 0.7031\n",
      "Precision H3: 0.6875475285171102,Recall H3:0.5650682545169237,F1 Score H3: 0.6203199530115331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/33\n",
      "H1: Train Loss: 0.7322, Val Loss: 0.8714, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.7300, Val Loss: 0.7878, Accuracy: 0.9354\n",
      "Precision H2: 0.9354, Recall H2: 0.9354, F1 H2: 0.9354\n",
      "H3: Train Loss: 0.7084, Val Loss: 0.8421, Custom Accuracy: 0.7008\n",
      "Precision H3: 0.6820115879051242,Recall H3:0.5752344191507689,F1 Score H3: 0.6240887422524247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/33\n",
      "H1: Train Loss: 0.6809, Val Loss: 0.8597, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.6791, Val Loss: 0.8372, Accuracy: 0.9316\n",
      "Precision H2: 0.9316, Recall H2: 0.9316, F1 H2: 0.9316\n",
      "H3: Train Loss: 0.6384, Val Loss: 0.8562, Custom Accuracy: 0.7014\n",
      "Precision H3: 0.7040467137425312,Recall H3:0.5394873504189094,F1 Score H3: 0.6108787963508304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/33\n",
      "H1: Train Loss: 0.6361, Val Loss: 0.8240, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.6231, Val Loss: 0.8161, Accuracy: 0.9354\n",
      "Precision H2: 0.9354, Recall H2: 0.9354, F1 H2: 0.9354\n",
      "H3: Train Loss: 0.5990, Val Loss: 0.7477, Custom Accuracy: 0.7043\n",
      "Precision H3: 0.6807004043696059,Recall H3:0.5788497413022128,F1 Score H3: 0.625657111513403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/33\n",
      "H1: Train Loss: 0.6012, Val Loss: 0.8417, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.6115, Val Loss: 0.7937, Accuracy: 0.9430\n",
      "Precision H2: 0.9430, Recall H2: 0.9430, F1 H2: 0.9430\n",
      "H3: Train Loss: 0.5804, Val Loss: 0.7931, Custom Accuracy: 0.7043\n",
      "Precision H3: 0.6811470215462611,Recall H3:0.5756692399277951,F1 Score H3: 0.6239820412774183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:09<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:09<00:00,  1.22it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.41it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/33\n",
      "H1: Train Loss: 0.5821, Val Loss: 0.7715, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.6224, Val Loss: 0.7219, Accuracy: 0.9620\n",
      "Precision H2: 0.9620, Recall H2: 0.9620, F1 H2: 0.9620\n",
      "H3: Train Loss: 0.5686, Val Loss: 0.7827, Custom Accuracy: 0.7075\n",
      "Precision H3: 0.6801270444806568,Recall H3:0.5975691186717803,F1 Score H3: 0.6361808546914451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:09<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.35it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/33\n",
      "H1: Train Loss: 0.5632, Val Loss: 0.7944, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.5716, Val Loss: 0.7718, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.5989, Val Loss: 0.8181, Custom Accuracy: 0.7093\n",
      "Precision H3: 0.6806231791022666,Recall H3:0.6055765421735003,F1 Score H3: 0.6409104659345741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:11<00:00,  1.21it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/33\n",
      "H1: Train Loss: 0.5770, Val Loss: 0.7487, Accuracy: 0.9734\n",
      "Precision H1: 0.9734, Recall H1: 0.9734, F1 H1: 0.9734\n",
      "H2: Train Loss: 0.5525, Val Loss: 0.7695, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.5352, Val Loss: 0.7995, Custom Accuracy: 0.7204\n",
      "Precision H3: 0.7085732391816042,Recall H3:0.587348087062916,F1 Score H3: 0.6422907442743367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/33\n",
      "H1: Train Loss: 0.5284, Val Loss: 0.7383, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.5319, Val Loss: 0.8173, Accuracy: 0.9430\n",
      "Precision H2: 0.9430, Recall H2: 0.9430, F1 H2: 0.9430\n",
      "H3: Train Loss: 0.5182, Val Loss: 0.7880, Custom Accuracy: 0.7286\n",
      "Precision H3: 0.7146608672274071,Recall H3:0.6054285385083864,F1 Score H3: 0.6555254250123451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/33\n",
      "H1: Train Loss: 0.5093, Val Loss: 0.7396, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.5154, Val Loss: 0.8589, Accuracy: 0.9278\n",
      "Precision H2: 0.9278, Recall H2: 0.9278, F1 H2: 0.9278\n",
      "H3: Train Loss: 0.5234, Val Loss: 0.7787, Custom Accuracy: 0.7295\n",
      "Precision H3: 0.7225371586588317,Recall H3:0.5896339824096478,F1 Score H3: 0.6493550253697048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.41it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/33\n",
      "H1: Train Loss: 0.5074, Val Loss: 0.7434, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.5070, Val Loss: 0.8332, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.4815, Val Loss: 0.8057, Custom Accuracy: 0.7438\n",
      "Precision H3: 0.7179062487997848,Recall H3:0.6252914808047888,F1 Score H3: 0.6684059263905713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/33\n",
      "H1: Train Loss: 0.4869, Val Loss: 0.7068, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.4840, Val Loss: 0.7674, Accuracy: 0.9354\n",
      "Precision H2: 0.9354, Recall H2: 0.9354, F1 H2: 0.9354\n",
      "H3: Train Loss: 0.4733, Val Loss: 0.7715, Custom Accuracy: 0.7444\n",
      "Precision H3: 0.7335445711871568,Recall H3:0.6078262253167195,F1 Score H3: 0.6647939987486863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/33\n",
      "H1: Train Loss: 0.4749, Val Loss: 0.6942, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.4655, Val Loss: 0.8172, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.4571, Val Loss: 0.7698, Custom Accuracy: 0.7567\n",
      "Precision H3: 0.7367411211517676,Recall H3:0.6462406520391312,F1 Score H3: 0.6885297720426848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/33\n",
      "H1: Train Loss: 0.4643, Val Loss: 0.6853, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.4586, Val Loss: 0.6901, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.4359, Val Loss: 0.6892, Custom Accuracy: 0.7625\n",
      "Precision H3: 0.7329786183398351,Recall H3:0.6806226304325163,F1 Score H3: 0.7058310619044885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/33\n",
      "H1: Train Loss: 0.4260, Val Loss: 0.6823, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.4128, Val Loss: 0.7125, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.4118, Val Loss: 0.6904, Custom Accuracy: 0.7780\n",
      "Precision H3: 0.758185741170532,Recall H3:0.6829293752297554,F1 Score H3: 0.7185925796393889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/33\n",
      "H1: Train Loss: 0.4074, Val Loss: 0.6610, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.3978, Val Loss: 0.6942, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.4039, Val Loss: 0.6716, Custom Accuracy: 0.7879\n",
      "Precision H3: 0.7821350385989169,Recall H3:0.6611127571203617,F1 Score H3: 0.7165497890829912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:10<00:00,  1.21it/s]\n",
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.35it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/33\n",
      "H1: Train Loss: 0.3847, Val Loss: 0.5822, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.4142, Val Loss: 0.6501, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.3699, Val Loss: 0.6699, Custom Accuracy: 0.8122\n",
      "Precision H3: 0.7953556477320736,Recall H3:0.7271979710192639,F1 Score H3: 0.7597512575534946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:11<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/33\n",
      "H1: Train Loss: 0.3539, Val Loss: 0.5819, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.3461, Val Loss: 0.6653, Accuracy: 0.9430\n",
      "Precision H2: 0.9430, Recall H2: 0.9430, F1 H2: 0.9430\n",
      "H3: Train Loss: 0.3339, Val Loss: 0.6433, Custom Accuracy: 0.8228\n",
      "Precision H3: 0.8161852089608743,Recall H3:0.7343120230002359,F1 Score H3: 0.7730869808479122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.36it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.35it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/33\n",
      "H1: Train Loss: 0.3277, Val Loss: 0.5842, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.3180, Val Loss: 0.6314, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.3077, Val Loss: 0.6002, Custom Accuracy: 0.8467\n",
      "Precision H3: 0.8490100203978532,Recall H3:0.7636530980637445,F1 Score H3: 0.8040726236518351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:11<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:11<00:00,  1.20it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.36it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.35it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/33\n",
      "H1: Train Loss: 0.3002, Val Loss: 0.6291, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.2911, Val Loss: 0.7100, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.2837, Val Loss: 0.6447, Custom Accuracy: 0.8502\n",
      "Precision H3: 0.857752429235319,Recall H3:0.7750127565716919,F1 Score H3: 0.8142861942627234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.36it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.35it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/33\n",
      "H1: Train Loss: 0.2938, Val Loss: 0.5511, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.2781, Val Loss: 0.5936, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.2741, Val Loss: 0.5592, Custom Accuracy: 0.8701\n",
      "Precision H3: 0.8675735755583664,Recall H3:0.8040826516111688,F1 Score H3: 0.8346223939642645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:11<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.36it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.35it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/33\n",
      "H1: Train Loss: 0.2529, Val Loss: 0.5272, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.2423, Val Loss: 0.5791, Accuracy: 0.9430\n",
      "Precision H2: 0.9430, Recall H2: 0.9430, F1 H2: 0.9430\n",
      "H3: Train Loss: 0.2295, Val Loss: 0.5456, Custom Accuracy: 0.8894\n",
      "Precision H3: 0.8810892740550536,Recall H3:0.8514124131044283,F1 Score H3: 0.8659966689135891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:11<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.35it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/33\n",
      "H1: Train Loss: 0.2276, Val Loss: 0.4883, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.2175, Val Loss: 0.5134, Accuracy: 0.9430\n",
      "Precision H2: 0.9430, Recall H2: 0.9430, F1 H2: 0.9430\n",
      "H3: Train Loss: 0.2079, Val Loss: 0.5144, Custom Accuracy: 0.9008\n",
      "Precision H3: 0.8963982574248734,Recall H3:0.8519527156409286,F1 Score H3: 0.8736105524278786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:11<00:00,  1.20it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.36it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/33\n",
      "H1: Train Loss: 0.2076, Val Loss: 0.4694, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.2145, Val Loss: 0.5394, Accuracy: 0.9354\n",
      "Precision H2: 0.9354, Recall H2: 0.9354, F1 H2: 0.9354\n",
      "H3: Train Loss: 0.1936, Val Loss: 0.5003, Custom Accuracy: 0.9131\n",
      "Precision H3: 0.9092640143970943,Recall H3:0.8683809853011375,F1 Score H3: 0.8883523772801146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:10<00:00,  1.21it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:09<00:00,  1.22it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.36it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.35it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/33\n",
      "H1: Train Loss: 0.1818, Val Loss: 0.4542, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.1744, Val Loss: 0.4950, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.1744, Val Loss: 0.5838, Custom Accuracy: 0.9175\n",
      "Precision H3: 0.9183909985240784,Recall H3:0.8762586484069373,F1 Score H3: 0.8968302603820033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:11<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:12<00:00,  1.20it/s]\n",
      "Training: 100%|██████████| 231/231 [03:11<00:00,  1.21it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/33\n",
      "H1: Train Loss: 0.1683, Val Loss: 0.4371, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.1510, Val Loss: 0.4782, Accuracy: 0.9392\n",
      "Precision H2: 0.9392, Recall H2: 0.9392, F1 H2: 0.9392\n",
      "H3: Train Loss: 0.1470, Val Loss: 0.4821, Custom Accuracy: 0.9339\n",
      "Precision H3: 0.9306256481161423,Recall H3:0.9090338474368893,F1 Score H3: 0.9197030379539373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/33\n",
      "H1: Train Loss: 0.1630, Val Loss: 0.4214, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.1339, Val Loss: 0.4496, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.1284, Val Loss: 0.4507, Custom Accuracy: 0.9409\n",
      "Precision H3: 0.9349930593276601,Recall H3:0.9187854920744655,F1 Score H3: 0.9268184244022202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.22it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.35it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.34it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/33\n",
      "H1: Train Loss: 0.1264, Val Loss: 0.4325, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.1146, Val Loss: 0.4492, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.1142, Val Loss: 0.4266, Custom Accuracy: 0.9476\n",
      "Precision H3: 0.9373181845615306,Recall H3:0.9348185823470995,F1 Score H3: 0.9360667147698095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [03:09<00:00,  1.22it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Training: 100%|██████████| 231/231 [03:08<00:00,  1.23it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.41it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:09<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/33\n",
      "H1: Train Loss: 0.1122, Val Loss: 0.3879, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.1023, Val Loss: 0.4647, Accuracy: 0.9468\n",
      "Precision H2: 0.9468, Recall H2: 0.9468, F1 H2: 0.9468\n",
      "H3: Train Loss: 0.1012, Val Loss: 0.4288, Custom Accuracy: 0.9468\n",
      "Precision H3: 0.9368437223950532,Recall H3:0.9341352141732369,F1 Score H3: 0.9354875078086302\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and set up CUDA\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "random_seed = 777  # You can change this value to any seed you prefer\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "\n",
    "# Load and preprocess your data for H1, H2, and H3\n",
    "model1_data = pd.read_csv(\"model1_2636.csv\")\n",
    "texts_h1 = model1_data['text'].tolist()\n",
    "labels_h1 = model1_data.iloc[:, 1].values.tolist()\n",
    "\n",
    "model2_data = pd.read_csv(\"model2_2636.csv\")\n",
    "texts_h2 = model2_data['text'].tolist()\n",
    "labels_h2 = model2_data.iloc[:, 1].values.tolist()\n",
    "\n",
    "model3_data = pd.read_csv(\"model3_2636.csv\")\n",
    "texts_h3 = model3_data['text'].tolist()\n",
    "labels_h3 = model3_data.iloc[:, 1:].values.tolist()\n",
    "\n",
    "#print(\"Total Records in H1:\", len(texts_h1),\"texts_h1\", \"with\", len(labels_h1), \"labels\")\n",
    "#print(\"Total Records in H2:\", len(texts_h2),\"texts_h2\",\"with\", len(labels_h2), \"labels\")\n",
    "#print(\"Total Records in H3:\", len(texts_h3),\"texts_h3\", \"with\", len(labels_h3), \"labels\")\n",
    "\n",
    "# Split the data for each hierarchy\n",
    "def split_data(texts, labels, train_ratio, val_ratio, test_ratio):\n",
    "    total_samples = len(texts)\n",
    "    train_size = int(total_samples * train_ratio)\n",
    "    val_size = int(total_samples * val_ratio)\n",
    "    test_size = total_samples - train_size - val_size  # Remaining samples for test\n",
    "\n",
    "    train_texts = texts[:train_size]\n",
    "    val_texts = texts[train_size:train_size + val_size]\n",
    "    test_texts = texts[train_size + val_size:]\n",
    "\n",
    "    train_labels = labels[:train_size]\n",
    "    val_labels = labels[train_size:train_size + val_size]\n",
    "    test_labels = labels[train_size + val_size:]\n",
    "\n",
    "    return train_texts, val_texts, test_texts, train_labels, val_labels, test_labels\n",
    "\n",
    "# Split the data for each hierarchy\n",
    "train_texts_h1, val_texts_h1, test_texts_h1, train_labels_h1, val_labels_h1, test_labels_h1 = split_data(texts_h1, labels_h1, 0.7, 0.1, 0.2)\n",
    "train_texts_h2, val_texts_h2, test_texts_h2, train_labels_h2, val_labels_h2, test_labels_h2 = split_data(texts_h2, labels_h2, 0.7, 0.1, 0.2)\n",
    "train_texts_h3, val_texts_h3, test_texts_h3, train_labels_h3, val_labels_h3, test_labels_h3 = split_data(texts_h3, labels_h3, 0.7, 0.1, 0.2)\n",
    "\n",
    "#print(\"Train Val Test Splitting:\")\n",
    "#print(\"H1:\", len(train_texts_h1), len(val_texts_h1), len(test_texts_h1))\n",
    "#print(\"H2:\", len(train_texts_h2), len(val_texts_h2), len(test_texts_h2))\n",
    "#print(\"H3:\", len(train_texts_h3), len(val_texts_h3), len(test_texts_h3))\n",
    "\n",
    "# Tokenizer\n",
    "# Tokenizer and Model setup for Clinical-BigBird\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-BigBird\")\n",
    "bigbird_model = AutoModel.from_pretrained(\"yikuan8/Clinical-BigBird\")\n",
    "\n",
    "# Define the TextDataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Now expecting a list of binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    # Rest of the code remains unchanged\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Create datasets and dataloaders for H1, H2, and H3\n",
    "dataset_h1 = TextDataset(train_texts_h1 + val_texts_h1 + test_texts_h1, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "dataset_h2 = TextDataset(train_texts_h2 + val_texts_h2 + test_texts_h2, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "dataset_h3 = TextDataset(train_texts_h3 + val_texts_h3 + test_texts_h3, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "\n",
    "# Split the datasets into train, val, and test for H1, H2, and H3\n",
    "train_size_h1 = len(train_texts_h1)\n",
    "val_size_h1 = len(val_texts_h1)\n",
    "train_size_h2 = len(train_texts_h2)\n",
    "val_size_h2 = len(val_texts_h2)\n",
    "train_size_h3 = len(train_texts_h3)\n",
    "val_size_h3 = len(val_texts_h3)\n",
    "\n",
    "train_dataset_h1, val_dataset_h1, test_dataset_h1 = random_split(dataset_h1, [train_size_h1, val_size_h1, len(test_texts_h1)])\n",
    "train_dataset_h2, val_dataset_h2, test_dataset_h2 = random_split(dataset_h2, [train_size_h2, val_size_h2, len(test_texts_h2)])\n",
    "train_dataset_h3, val_dataset_h3, test_dataset_h3 = random_split(dataset_h3, [train_size_h3, val_size_h3, len(test_texts_h3)])\n",
    "\n",
    "# Create dataloaders for H1, H2, and H3\n",
    "train_dataloader_h1 = DataLoader(train_dataset_h1, batch_size=8, shuffle=True)\n",
    "val_dataloader_h1 = DataLoader(val_dataset_h1,batch_size=8, shuffle=False)  # You can set shuffle to True if you want to shuffle the validation data.\n",
    "train_dataloader_h2 = DataLoader(train_dataset_h2, batch_size=8, shuffle=True)\n",
    "val_dataloader_h2 = DataLoader(val_dataset_h2, batch_size=8, shuffle=False)\n",
    "\n",
    "train_dataloader_h3 = DataLoader(train_dataset_h3, batch_size=8, shuffle=True)\n",
    "val_dataloader_h3 = DataLoader(val_dataset_h3, batch_size=8, shuffle=False)\n",
    "\n",
    "# Define the model architecture for H1, H2, and H3 using Clinical-BigBird\n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.bigbird = bigbird_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc_h1 = nn.Linear(self.bigbird.config.hidden_size, 1)\n",
    "        self.fc_h2 = nn.Linear(self.bigbird.config.hidden_size, 1)\n",
    "        self.fc_h3 = nn.Linear(self.bigbird.config.hidden_size, num_labels_h3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bigbird(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "        \n",
    "            \n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "model = HierarchicalClassifier(num_labels_h3=len(train_labels_h3[0]))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)  # You can adjust the learning rate as needed\n",
    "\n",
    "# Training loop for H1, H2, and H3\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader), desc=\"Training\"):\n",
    "        input_ids = batch['ids'].to(device)\n",
    "        attention_mask = batch['mask'].to(device)\n",
    "        labels_h1 = batch['labels_h1'].to(device)\n",
    "        labels_h2 = batch['labels_h2'].to(device)\n",
    "        labels_h3 = batch['labels_h3'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "        loss_h1 = criterion(logits_h1, labels_h1)\n",
    "        loss_h2 = criterion(logits_h2, labels_h2)\n",
    "        loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "        loss = loss_h1 + loss_h2 + loss_h3\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Validation loop for H1, H2, and H3\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Validation\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels_h1 = batch['labels_h1'].to(device)\n",
    "            labels_h2 = batch['labels_h2'].to(device)\n",
    "            labels_h3 = batch['labels_h3'].to(device)\n",
    "\n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "# Training and evaluation for H1, H2, and H3\n",
    "# Custom accuracy function\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_labels = np.sum(np.equal(y_true, y_pred), axis=1)\n",
    "    total_labels = y_true.shape[1]\n",
    "    sample_accuracy = np.mean(correct_labels / total_labels)\n",
    "    return sample_accuracy\n",
    "\n",
    "def custom_precision_recall_f1(y_true, y_pred):\n",
    "    # Calculate precision and recall for each sample\n",
    "    sample_precisions = []\n",
    "    sample_recalls = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_positive = np.sum((true == 1) & (pred == 1))\n",
    "        false_positive = np.sum((true == 0) & (pred == 1))\n",
    "        false_negative = np.sum((true == 1) & (pred == 0))\n",
    "        \n",
    "        sample_precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "        sample_recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "        \n",
    "        sample_precisions.append(sample_precision)\n",
    "        sample_recalls.append(sample_recall)\n",
    "    \n",
    "    # Calculate average precision and recall across all samples\n",
    "    avg_precision = np.mean(sample_precisions)\n",
    "    avg_recall = np.mean(sample_recalls)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    if avg_precision + avg_recall > 0:\n",
    "        avg_f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
    "    else:\n",
    "        avg_f1 = 0\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "\n",
    "# Training and evaluation for H1, H2, and H3\n",
    "num_epochs = 33 # You can adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training for H1\n",
    "    train_loss_h1 = train(model, train_dataloader_h1, optimizer, criterion, device)\n",
    "    # Training for H2\n",
    "    train_loss_h2 = train(model, train_dataloader_h2, optimizer, criterion, device)\n",
    "    # Training for H3\n",
    "    train_loss_h3 = train(model, train_dataloader_h3, optimizer, criterion, device)\n",
    "\n",
    "    # Validation for H1\n",
    "    val_loss_h1, val_preds_h1, _, _, val_labels_h1, _, _ = evaluate(model, val_dataloader_h1, criterion, device)\n",
    "    # Validation for H2\n",
    "    val_loss_h2, _, val_preds_h2, _, _, val_labels_h2, _ = evaluate(model, val_dataloader_h2, criterion, device)\n",
    "    # Validation for H3\n",
    "    val_loss_h3, _, _, val_preds_h3, _, _, val_labels_h3 = evaluate(model, val_dataloader_h3, criterion, device)\n",
    "\n",
    "    # Metrics calculation for H1\n",
    "    threshold_h1 = 0.5\n",
    "    val_preds_h1_binary = (np.array(val_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "    acc_h1 = accuracy_score(val_labels_h1, val_preds_h1_binary)\n",
    "    precision_h1 = precision_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    recall_h1 = recall_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    f1_h1 = f1_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "\n",
    "\n",
    "    # Metrics calculation for H2\n",
    "    threshold_h2 = 0.5\n",
    "    val_preds_h2_binary = (np.array(val_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "    acc_h2 = accuracy_score(val_labels_h2, val_preds_h2_binary)\n",
    "    precision_h2 = precision_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    recall_h2 = recall_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    f1_h2 = f1_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "\n",
    "# Convert predictions and labels to binary using the threshold\n",
    "\n",
    "    # Metrics calculation for H3\n",
    "    threshold_h3 = 0.5\n",
    "    val_preds_h3_binary = (np.array(val_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "\n",
    "    # Custom accuracy calculation for H3\n",
    "    acc_h3_custom = custom_accuracy(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "    # Calculate custom precision, recall, and F1 score for H3\n",
    "    precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"H1: Train Loss: {train_loss_h1:.4f}, Val Loss: {val_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "    print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "    print(f\"H2: Train Loss: {train_loss_h2:.4f}, Val Loss: {val_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "    print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "    print(f\"H3: Train Loss: {train_loss_h3:.4f}, Val Loss: {val_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "    print(f\"Precision H3: {precision_h3},Recall H3:{recall_h3},F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "# Saving the model\n",
    "torch.save(model.state_dict(), 'model_Clinical_Bird.pth')\n",
    "\n",
    "# Loading the model\n",
    "#loaded_model = YourModelClass(*args, **kwargs)  # Instantiate your model\n",
    "#loaded_model.load_state_dict(torch.load('model.pth'))\n",
    "#loaded_model.eval()  # Set the model to evaluation mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   2%|▏         | 1/66 [00:00<00:19,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   3%|▎         | 2/66 [00:00<00:18,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   5%|▍         | 3/66 [00:00<00:18,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   6%|▌         | 4/66 [00:01<00:17,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   8%|▊         | 5/66 [00:01<00:17,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   9%|▉         | 6/66 [00:01<00:17,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  11%|█         | 7/66 [00:02<00:17,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  12%|█▏        | 8/66 [00:02<00:17,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  14%|█▎        | 9/66 [00:02<00:16,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  15%|█▌        | 10/66 [00:02<00:16,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  17%|█▋        | 11/66 [00:03<00:16,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  18%|█▊        | 12/66 [00:03<00:15,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  20%|█▉        | 13/66 [00:03<00:15,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  21%|██        | 14/66 [00:04<00:15,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  23%|██▎       | 15/66 [00:04<00:14,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  24%|██▍       | 16/66 [00:04<00:14,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  26%|██▌       | 17/66 [00:04<00:14,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  27%|██▋       | 18/66 [00:05<00:14,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  29%|██▉       | 19/66 [00:05<00:13,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  30%|███       | 20/66 [00:05<00:13,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  32%|███▏      | 21/66 [00:06<00:13,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  33%|███▎      | 22/66 [00:06<00:12,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  35%|███▍      | 23/66 [00:06<00:12,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  36%|███▋      | 24/66 [00:07<00:12,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  38%|███▊      | 25/66 [00:07<00:11,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  39%|███▉      | 26/66 [00:07<00:11,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  41%|████      | 27/66 [00:07<00:11,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  42%|████▏     | 28/66 [00:08<00:11,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  44%|████▍     | 29/66 [00:08<00:10,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  45%|████▌     | 30/66 [00:08<00:10,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  47%|████▋     | 31/66 [00:09<00:10,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  48%|████▊     | 32/66 [00:09<00:10,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  50%|█████     | 33/66 [00:09<00:09,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  52%|█████▏    | 34/66 [00:09<00:09,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  53%|█████▎    | 35/66 [00:10<00:09,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  55%|█████▍    | 36/66 [00:10<00:08,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  56%|█████▌    | 37/66 [00:10<00:08,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  58%|█████▊    | 38/66 [00:11<00:08,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  59%|█████▉    | 39/66 [00:11<00:07,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  61%|██████    | 40/66 [00:11<00:07,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  62%|██████▏   | 41/66 [00:12<00:07,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  64%|██████▎   | 42/66 [00:12<00:07,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  65%|██████▌   | 43/66 [00:12<00:06,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  67%|██████▋   | 44/66 [00:12<00:06,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  68%|██████▊   | 45/66 [00:13<00:06,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  70%|██████▉   | 46/66 [00:13<00:05,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  71%|███████   | 47/66 [00:13<00:05,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  73%|███████▎  | 48/66 [00:14<00:05,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  74%|███████▍  | 49/66 [00:14<00:05,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  76%|███████▌  | 50/66 [00:14<00:04,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  77%|███████▋  | 51/66 [00:14<00:04,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  79%|███████▉  | 52/66 [00:15<00:04,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  80%|████████  | 53/66 [00:15<00:03,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  82%|████████▏ | 54/66 [00:15<00:03,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  83%|████████▎ | 55/66 [00:16<00:03,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  85%|████████▍ | 56/66 [00:16<00:02,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  86%|████████▋ | 57/66 [00:16<00:02,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  88%|████████▊ | 58/66 [00:16<00:02,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  89%|████████▉ | 59/66 [00:17<00:02,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  91%|█████████ | 60/66 [00:17<00:01,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  92%|█████████▏| 61/66 [00:17<00:01,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  94%|█████████▍| 62/66 [00:18<00:01,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  95%|█████████▌| 63/66 [00:18<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  97%|█████████▋| 64/66 [00:18<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  98%|█████████▊| 65/66 [00:19<00:00,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 66/66 [00:19<00:00,  3.42it/s]\n",
      "Testing:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   2%|▏         | 1/66 [00:00<00:19,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   3%|▎         | 2/66 [00:00<00:18,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   5%|▍         | 3/66 [00:00<00:18,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   6%|▌         | 4/66 [00:01<00:17,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   8%|▊         | 5/66 [00:01<00:17,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   9%|▉         | 6/66 [00:01<00:17,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  11%|█         | 7/66 [00:02<00:17,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  12%|█▏        | 8/66 [00:02<00:16,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  14%|█▎        | 9/66 [00:02<00:16,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  15%|█▌        | 10/66 [00:02<00:16,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  17%|█▋        | 11/66 [00:03<00:16,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  18%|█▊        | 12/66 [00:03<00:15,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  20%|█▉        | 13/66 [00:03<00:15,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  21%|██        | 14/66 [00:04<00:15,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  23%|██▎       | 15/66 [00:04<00:14,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  24%|██▍       | 16/66 [00:04<00:14,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  26%|██▌       | 17/66 [00:04<00:14,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  27%|██▋       | 18/66 [00:05<00:13,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  29%|██▉       | 19/66 [00:05<00:13,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  30%|███       | 20/66 [00:05<00:13,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  32%|███▏      | 21/66 [00:06<00:13,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  33%|███▎      | 22/66 [00:06<00:12,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  35%|███▍      | 23/66 [00:06<00:12,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  36%|███▋      | 24/66 [00:07<00:12,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  38%|███▊      | 25/66 [00:07<00:11,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  39%|███▉      | 26/66 [00:07<00:11,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  41%|████      | 27/66 [00:07<00:11,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  42%|████▏     | 28/66 [00:08<00:11,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  44%|████▍     | 29/66 [00:08<00:10,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  45%|████▌     | 30/66 [00:08<00:10,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  47%|████▋     | 31/66 [00:09<00:10,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  48%|████▊     | 32/66 [00:09<00:09,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  50%|█████     | 33/66 [00:09<00:09,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  52%|█████▏    | 34/66 [00:09<00:09,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  53%|█████▎    | 35/66 [00:10<00:09,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  55%|█████▍    | 36/66 [00:10<00:08,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  56%|█████▌    | 37/66 [00:10<00:08,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  58%|█████▊    | 38/66 [00:11<00:08,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  59%|█████▉    | 39/66 [00:11<00:07,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  61%|██████    | 40/66 [00:11<00:07,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  62%|██████▏   | 41/66 [00:11<00:07,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  64%|██████▎   | 42/66 [00:12<00:07,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  65%|██████▌   | 43/66 [00:12<00:06,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  67%|██████▋   | 44/66 [00:12<00:06,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  68%|██████▊   | 45/66 [00:13<00:06,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  70%|██████▉   | 46/66 [00:13<00:05,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  71%|███████   | 47/66 [00:13<00:05,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  73%|███████▎  | 48/66 [00:14<00:05,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  74%|███████▍  | 49/66 [00:14<00:04,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  76%|███████▌  | 50/66 [00:14<00:04,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  77%|███████▋  | 51/66 [00:14<00:04,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  79%|███████▉  | 52/66 [00:15<00:04,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  80%|████████  | 53/66 [00:15<00:03,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  82%|████████▏ | 54/66 [00:15<00:03,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  83%|████████▎ | 55/66 [00:16<00:03,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  85%|████████▍ | 56/66 [00:16<00:02,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  86%|████████▋ | 57/66 [00:16<00:02,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  88%|████████▊ | 58/66 [00:16<00:02,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  89%|████████▉ | 59/66 [00:17<00:02,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  91%|█████████ | 60/66 [00:17<00:01,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  92%|█████████▏| 61/66 [00:17<00:01,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  94%|█████████▍| 62/66 [00:18<00:01,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  95%|█████████▌| 63/66 [00:18<00:00,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  97%|█████████▋| 64/66 [00:18<00:00,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  98%|█████████▊| 65/66 [00:19<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 66/66 [00:19<00:00,  3.42it/s]\n",
      "Testing:   0%|          | 0/66 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   2%|▏         | 1/66 [00:00<00:19,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   3%|▎         | 2/66 [00:00<00:18,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   5%|▍         | 3/66 [00:00<00:18,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   6%|▌         | 4/66 [00:01<00:17,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   8%|▊         | 5/66 [00:01<00:17,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   9%|▉         | 6/66 [00:01<00:17,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  11%|█         | 7/66 [00:02<00:17,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  12%|█▏        | 8/66 [00:02<00:17,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  14%|█▎        | 9/66 [00:02<00:16,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  15%|█▌        | 10/66 [00:02<00:16,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  17%|█▋        | 11/66 [00:03<00:16,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  18%|█▊        | 12/66 [00:03<00:15,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  20%|█▉        | 13/66 [00:03<00:15,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  21%|██        | 14/66 [00:04<00:15,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  23%|██▎       | 15/66 [00:04<00:14,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  24%|██▍       | 16/66 [00:04<00:14,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  26%|██▌       | 17/66 [00:04<00:14,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  27%|██▋       | 18/66 [00:05<00:14,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  29%|██▉       | 19/66 [00:05<00:13,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  30%|███       | 20/66 [00:05<00:13,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  32%|███▏      | 21/66 [00:06<00:13,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  33%|███▎      | 22/66 [00:06<00:12,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  35%|███▍      | 23/66 [00:06<00:12,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  36%|███▋      | 24/66 [00:07<00:12,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  38%|███▊      | 25/66 [00:07<00:11,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  39%|███▉      | 26/66 [00:07<00:11,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  41%|████      | 27/66 [00:07<00:11,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  42%|████▏     | 28/66 [00:08<00:11,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  44%|████▍     | 29/66 [00:08<00:10,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  45%|████▌     | 30/66 [00:08<00:10,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  47%|████▋     | 31/66 [00:09<00:10,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  48%|████▊     | 32/66 [00:09<00:10,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  50%|█████     | 33/66 [00:09<00:09,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  52%|█████▏    | 34/66 [00:09<00:09,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  53%|█████▎    | 35/66 [00:10<00:09,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  55%|█████▍    | 36/66 [00:10<00:08,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  56%|█████▌    | 37/66 [00:10<00:08,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  58%|█████▊    | 38/66 [00:11<00:08,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  59%|█████▉    | 39/66 [00:11<00:07,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  61%|██████    | 40/66 [00:11<00:07,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  62%|██████▏   | 41/66 [00:12<00:07,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  64%|██████▎   | 42/66 [00:12<00:07,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  65%|██████▌   | 43/66 [00:12<00:06,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  67%|██████▋   | 44/66 [00:12<00:06,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  68%|██████▊   | 45/66 [00:13<00:06,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  70%|██████▉   | 46/66 [00:13<00:05,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  71%|███████   | 47/66 [00:13<00:05,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  73%|███████▎  | 48/66 [00:14<00:05,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  74%|███████▍  | 49/66 [00:14<00:04,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  76%|███████▌  | 50/66 [00:14<00:04,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  77%|███████▋  | 51/66 [00:14<00:04,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  79%|███████▉  | 52/66 [00:15<00:04,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  80%|████████  | 53/66 [00:15<00:03,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  82%|████████▏ | 54/66 [00:15<00:03,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  83%|████████▎ | 55/66 [00:16<00:03,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  85%|████████▍ | 56/66 [00:16<00:02,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  86%|████████▋ | 57/66 [00:16<00:02,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  88%|████████▊ | 58/66 [00:16<00:02,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  89%|████████▉ | 59/66 [00:17<00:02,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  91%|█████████ | 60/66 [00:17<00:01,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  92%|█████████▏| 61/66 [00:17<00:01,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  94%|█████████▍| 62/66 [00:18<00:01,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  95%|█████████▌| 63/66 [00:18<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  97%|█████████▋| 64/66 [00:18<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  98%|█████████▊| 65/66 [00:19<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 66/66 [00:19<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Results:\n",
      "H1: Test Loss: 0.0985, Accuracy: 0.9981\n",
      "Precision H1: 0.9981, Recall H1: 0.9981, F1 H1: 0.9981\n",
      "H2: Test Loss: 0.0985, Accuracy: 0.9962\n",
      "Precision H2: 0.9962, Recall H2: 0.9962, F1 H2: 0.9962\n",
      "H3: Test Loss: 0.0985, Custom Accuracy: 0.9869\n",
      "Precision H3: 0.9875943553500371, Recall H3:0.9856872294372295, F1 Score H3: 0.9866398707995548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create test datasets for H1, H2, and H3\n",
    "test_dataset_h1 = TextDataset(test_texts_h1, test_labels_h1, test_labels_h2, test_labels_h3, tokenizer)\n",
    "test_dataset_h2 = TextDataset(test_texts_h2, test_labels_h1, test_labels_h2, test_labels_h3, tokenizer)\n",
    "test_dataset_h3 = TextDataset(test_texts_h3, test_labels_h1, test_labels_h2, test_labels_h3, tokenizer)\n",
    "\n",
    "# Create test dataloaders for H1, H2, and H3\n",
    "test_dataloader_h1 = DataLoader(test_dataset_h1, batch_size=8, shuffle=False)\n",
    "test_dataloader_h2 = DataLoader(test_dataset_h2, batch_size=8, shuffle=False)\n",
    "test_dataloader_h3 = DataLoader(test_dataset_h3, batch_size=8, shuffle=False)\n",
    "# Testing loop for H1, H2, and H3\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Testing\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels_h1 = batch['labels_h1'].to(device)  # No need to reshape labels_h1\n",
    "            labels_h2 = batch['labels_h2'].to(device)  # No need to reshape labels_h2\n",
    "\n",
    "            #labels_h1 = batch['labels_h1'].unsqueeze(1).to(device)  # Reshape labels_h1\n",
    "            #labels_h2 = batch['labels_h2'].unsqueeze(1).to(device)  # Reshape labels_h2\n",
    "            #labels_h3 = batch['labels_h3'].unsqueeze(1).to(device)  # Reshape labels_h3\n",
    "            labels_h3 = batch['labels_h3'].to(device)  # No need to reshape labels_h3\n",
    "            print(\"Labels H1 shape:\", labels_h1.shape)\n",
    "            print(\"Labels H2 shape:\", labels_h2.shape)\n",
    "            print(\"Labels H3 shape:\", labels_h3.shape)\n",
    "\n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            \n",
    "            print(\"Logits H1 shape:\", logits_h1.shape)\n",
    "            print(\"Logits H2 shape:\", logits_h2.shape)\n",
    "            print(\"Logits H3 shape:\", logits_h3.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "# Testing for H1\n",
    "test_loss_h1, test_preds_h1, _, _, test_labels_h1, _, _ = test(model, test_dataloader_h1, criterion, device)\n",
    "# Testing for H2\n",
    "test_loss_h2, _, test_preds_h2, _, _, test_labels_h2, _ = test(model, test_dataloader_h2, criterion, device)\n",
    "# Testing for H3\n",
    "test_loss_h3, _, _, test_preds_h3, _, _, test_labels_h3 = test(model, test_dataloader_h3, criterion, device)\n",
    "\n",
    "# Metrics calculation for H1\n",
    "threshold_h1 = 0.5\n",
    "test_preds_h1_binary = (np.array(test_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "acc_h1 = accuracy_score(test_labels_h1, test_preds_h1_binary)\n",
    "precision_h1 = precision_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "recall_h1 = recall_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "f1_h1 = f1_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H2\n",
    "threshold_h2 = 0.5\n",
    "test_preds_h2_binary = (np.array(test_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "acc_h2 = accuracy_score(test_labels_h2, test_preds_h2_binary)\n",
    "precision_h2 = precision_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "recall_h2 = recall_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "f1_h2 = f1_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H3\n",
    "threshold_h3 = 0.5\n",
    "test_preds_h3_binary = (np.array(test_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "# Custom accuracy calculation for H3\n",
    "acc_h3_custom = custom_accuracy(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "# Calculate custom precision, recall, and F1 score for H3\n",
    "precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "\n",
    "print(\"Testing Results:\")\n",
    "print(f\"H1: Test Loss: {test_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "print(f\"H2: Test Loss: {test_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "print(f\"H3: Test Loss: {test_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "print(f\"Precision H3: {precision_h3}, Recall H3:{recall_h3}, F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNSEEN DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpagare/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: \n",
      "    Found GPU%d %s which is of cuda capability %d.%d.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is %d.%d.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn.format(d, name, major, minor, min_arch // 10, min_arch % 10))\n",
      "Testing:   0%|          | 0/26 [00:00<?, ?it/s]Attention type 'block_sparse' is not possible if sequence_length: 512 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
      "Testing: 100%|██████████| 26/26 [00:07<00:00,  3.31it/s]\n",
      "Testing: 100%|██████████| 26/26 [00:07<00:00,  3.49it/s]\n",
      "Testing: 100%|██████████| 26/26 [00:07<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Results:\n",
      "H1: Test Loss: 0.5334, Accuracy: 0.9760\n",
      "Precision H1: 0.9760, Recall H1: 0.9760, F1 H1: 0.9760\n",
      "H2: Test Loss: 0.5334, Accuracy: 0.9808\n",
      "Precision H2: 0.9808, Recall H2: 0.9808, F1 H2: 0.9808\n",
      "H3: Test Loss: 0.5334, Custom Accuracy: 0.8920\n",
      "Precision H3: 0.7907528215355902, Recall H3:0.8971799006601666, F1 Score H3: 0.8406111503616124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming the new unseen datasets are similar to 'model1_2636.csv', 'model2_2636.csv', 'model3_2636.csv'\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "#from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Loading and preprocessing new_data_h1\n",
    "new_data_h1 = pd.read_csv(\"112_H_100_O_NEWMODEL1.CSV\")\n",
    "new_data_h1['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h1 = new_data_h1['text'].tolist()\n",
    "new_labels_h1 = new_data_h1.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h2\n",
    "new_data_h2 = pd.read_csv(\"112_H_100_O_NEWMODEL2.CSV\")\n",
    "new_data_h2['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h2 = new_data_h2['text'].tolist()\n",
    "new_labels_h2 = new_data_h2.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h3 for multi-label classification\n",
    "new_data_h3 = pd.read_csv(\"112_H_100_O_NEWMODEL3.CSV\")\n",
    "new_data_h3['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "\n",
    "# Replace NaN values in label columns with 0 for new_data_h3\n",
    "# Assuming all label columns are binary, fill NaN values with 0\n",
    "for label_col in new_data_h3.columns[1:]:  # Skip the text column, only fill NaN in label columns\n",
    "    new_data_h3[label_col].fillna(0, inplace=True)\n",
    "\n",
    "new_texts_h3 = new_data_h3['text'].tolist()\n",
    "new_labels_h3 = new_data_h3.iloc[:, 1:].values.tolist()  # Extract labels after filling NaN values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Now expecting a list of binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    # Rest of the code remains unchanged\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "        \n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.bigbird = bigbird_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc_h1 = nn.Linear(self.bigbird.config.hidden_size, 1)\n",
    "        self.fc_h2 = nn.Linear(self.bigbird.config.hidden_size, 1)\n",
    "        self.fc_h3 = nn.Linear(self.bigbird.config.hidden_size, num_labels_h3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bigbird(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "#model = HierarchicalClassifier(num_labels_h3=len(train_labels_h3[0]))\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Tokenizer and Model setup for Clinical-BigBird\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-BigBird\")\n",
    "bigbird_model = AutoModel.from_pretrained(\"yikuan8/Clinical-BigBird\")\n",
    "\n",
    "\n",
    "#from transformers import RobertaTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Preprocess the texts and labels in the same way as the original datasets\n",
    "# Assuming the preprocessing steps are included in the TextDataset class\n",
    "# Create TextDataset instances for the new data\n",
    "new_dataset_h1 = TextDataset(new_texts_h1, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "new_dataset_h2 = TextDataset(new_texts_h2, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "new_dataset_h3 = TextDataset(new_texts_h3, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "\n",
    "# Create DataLoader instances for the new datasets\n",
    "#new_dataloader_h1 = DataLoader(new_dataset_h1, batch_size=8, shuffle=False)\n",
    "#new_dataloader_h2 = DataLoader(new_dataset_h2, batch_size=8, shuffle=False)\n",
    "#new_dataloader_h3 = DataLoader(new_dataset_h3, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "new_dataloader_h1 = DataLoader(new_dataset_h1, batch_size=8, shuffle=False, drop_last=True)\n",
    "new_dataloader_h2 = DataLoader(new_dataset_h2, batch_size=8, shuffle=False, drop_last=True)\n",
    "new_dataloader_h3 = DataLoader(new_dataset_h3, batch_size=8, shuffle=False, drop_last=True)\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'model_Clinical_Bird.pth'  # Path to your saved model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = HierarchicalClassifier(num_labels_h3=len(new_labels_h3[0]))  # Make sure to provide the correct number of labels for H3\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Testing\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            \n",
    "            # Ensuring labels are correctly shaped and moved to the device\n",
    "            labels_h1 = batch['labels_h1'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h2 = batch['labels_h2'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h3 = batch['labels_h3'].to(device)  # Shape: [batch_size, num_labels_h3]\n",
    "            \n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Compute loss for each hierarchy\n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert logits to probabilities for binary classification/multi-label classification\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            # Store predictions and labels for metric calculation\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Testing the model on the new unseen data\n",
    "test_loss_h1, test_preds_h1, _, _, test_labels_h1, _, _ = test(model, new_dataloader_h1, criterion, device)\n",
    "test_loss_h2, _, test_preds_h2, _, _, test_labels_h2, _ = test(model, new_dataloader_h2, criterion, device)\n",
    "test_loss_h3, _, _, test_preds_h3, _, _, test_labels_h3 = test(model, new_dataloader_h3, criterion, device)\n",
    "\n",
    "# Calculate and print the metrics for H1, H2, and H3 using the same approach as before\n",
    "# Use the appropriate threshold and custom functions for metrics calculation\n",
    "\n",
    "# Metrics calculation for H1\n",
    "threshold_h1 = 0.5\n",
    "test_preds_h1_binary = (np.array(test_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "acc_h1 = accuracy_score(test_labels_h1, test_preds_h1_binary)\n",
    "precision_h1 = precision_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "recall_h1 = recall_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "f1_h1 = f1_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H2\n",
    "threshold_h2 = 0.5\n",
    "test_preds_h2_binary = (np.array(test_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "acc_h2 = accuracy_score(test_labels_h2, test_preds_h2_binary)\n",
    "precision_h2 = precision_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "recall_h2 = recall_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "f1_h2 = f1_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H3\n",
    "threshold_h3 = 0.5\n",
    "test_preds_h3_binary = (np.array(test_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_predictions = np.equal(y_true, y_pred)\n",
    "    sample_accuracy = np.sum(correct_predictions, axis=1) / y_true.shape[1]\n",
    "    return np.mean(sample_accuracy)\n",
    "\n",
    "def custom_precision_recall_f1(y_true, y_pred):\n",
    "    true_positives = np.sum((y_true == 1) & (y_pred == 1), axis=1)\n",
    "    false_positives = np.sum((y_true == 0) & (y_pred == 1), axis=1)\n",
    "    false_negatives = np.sum((y_true == 1) & (y_pred == 0), axis=1)\n",
    "\n",
    "    precision = np.mean(true_positives / (true_positives + false_positives + 1e-8))\n",
    "    recall = np.mean(true_positives / (true_positives + false_negatives + 1e-8))\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom accuracy calculation for H3\n",
    "acc_h3_custom = custom_accuracy(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "# Calculate custom precision, recall, and F1 score for H3\n",
    "precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "\n",
    "print(\"Testing Results:\")\n",
    "print(f\"H1: Test Loss: {test_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "print(f\"H2: Test Loss: {test_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "print(f\"H3: Test Loss: {test_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "print(f\"Precision H3: {precision_h3}, Recall H3:{recall_h3}, F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing_ChatgptEq_Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpagare/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: \n",
      "    Found GPU%d %s which is of cuda capability %d.%d.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is %d.%d.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn.format(d, name, major, minor, min_arch // 10, min_arch % 10))\n",
      "Testing:   0%|          | 0/63 [00:00<?, ?it/s]Attention type 'block_sparse' is not possible if sequence_length: 512 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
      "Testing: 100%|██████████| 63/63 [00:32<00:00,  1.91it/s]\n",
      "Testing: 100%|██████████| 63/63 [00:32<00:00,  1.92it/s]\n",
      "Testing: 100%|██████████| 63/63 [00:32<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Results:\n",
      "H1: Test Loss: 3.7800, Accuracy: 0.8472\n",
      "Precision H1: 0.8472, Recall H1: 0.8472, F1 H1: 0.8472\n",
      "H2: Test Loss: 3.7020, Accuracy: 0.5159\n",
      "Precision H2: 0.5159, Recall H2: 0.5159, F1 H2: 0.5159\n",
      "H3: Test Loss: 3.7020, Custom Accuracy: 0.6810\n",
      "Precision H3: 0.5680531923039022, Recall H3:0.6326776822343488, F1 Score H3: 0.598626356197814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "#from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Loading and preprocessing new_data_h1\n",
    "new_data_h1 = pd.read_csv(\"P3_Chatgpt_Eq_Model1_508.csv\")\n",
    "new_data_h1['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h1 = new_data_h1['text'].tolist()\n",
    "new_labels_h1 = new_data_h1.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h2\n",
    "new_data_h2 = pd.read_csv(\"P3_Chatgpt_Eq_Model2_508.csv\")\n",
    "new_data_h2['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h2 = new_data_h2['text'].tolist()\n",
    "new_labels_h2 = new_data_h2.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h3 for multi-label classification\n",
    "new_data_h3 = pd.read_csv(\"P3_Chatgpt_Eq_Model3_508.csv\")\n",
    "new_data_h3['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "\n",
    "# Replace NaN values in label columns with 0 for new_data_h3\n",
    "# Assuming all label columns are binary, fill NaN values with 0\n",
    "for label_col in new_data_h3.columns[1:]:  # Skip the text column, only fill NaN in label columns\n",
    "    new_data_h3[label_col].fillna(0, inplace=True)\n",
    "\n",
    "new_texts_h3 = new_data_h3['text'].tolist()\n",
    "new_labels_h3 = new_data_h3.iloc[:, 1:].values.tolist()  # Extract labels after filling NaN values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Now expecting a list of binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    # Rest of the code remains unchanged\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "        \n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.bigbird = bigbird_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc_h1 = nn.Linear(self.bigbird.config.hidden_size, 1)\n",
    "        self.fc_h2 = nn.Linear(self.bigbird.config.hidden_size, 1)\n",
    "        self.fc_h3 = nn.Linear(self.bigbird.config.hidden_size, num_labels_h3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bigbird(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "#model = HierarchicalClassifier(num_labels_h3=len(train_labels_h3[0]))\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Tokenizer and Model setup for Clinical-BigBird\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yikuan8/Clinical-BigBird\")\n",
    "bigbird_model = AutoModel.from_pretrained(\"yikuan8/Clinical-BigBird\")\n",
    "\n",
    "\n",
    "#from transformers import RobertaTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Preprocess the texts and labels in the same way as the original datasets\n",
    "# Assuming the preprocessing steps are included in the TextDataset class\n",
    "# Create TextDataset instances for the new data\n",
    "new_dataset_h1 = TextDataset(new_texts_h1, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "new_dataset_h2 = TextDataset(new_texts_h2, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "new_dataset_h3 = TextDataset(new_texts_h3, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "\n",
    "# Create DataLoader instances for the new datasets\n",
    "#new_dataloader_h1 = DataLoader(new_dataset_h1, batch_size=8, shuffle=False)\n",
    "#new_dataloader_h2 = DataLoader(new_dataset_h2, batch_size=8, shuffle=False)\n",
    "#new_dataloader_h3 = DataLoader(new_dataset_h3, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "new_dataloader_h1 = DataLoader(new_dataset_h1, batch_size=8, shuffle=False, drop_last=True)\n",
    "new_dataloader_h2 = DataLoader(new_dataset_h2, batch_size=8, shuffle=False, drop_last=True)\n",
    "new_dataloader_h3 = DataLoader(new_dataset_h3, batch_size=8, shuffle=False, drop_last=True)\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'model_Clinical_Bird.pth'  # Path to your saved model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = HierarchicalClassifier(num_labels_h3=len(new_labels_h3[0]))  # Make sure to provide the correct number of labels for H3\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Testing\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            \n",
    "            # Ensuring labels are correctly shaped and moved to the device\n",
    "            labels_h1 = batch['labels_h1'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h2 = batch['labels_h2'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h3 = batch['labels_h3'].to(device)  # Shape: [batch_size, num_labels_h3]\n",
    "            \n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Compute loss for each hierarchy\n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert logits to probabilities for binary classification/multi-label classification\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            # Store predictions and labels for metric calculation\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Testing the model on the new unseen data\n",
    "test_loss_h1, test_preds_h1, _, _, test_labels_h1, _, _ = test(model, new_dataloader_h1, criterion, device)\n",
    "test_loss_h2, _, test_preds_h2, _, _, test_labels_h2, _ = test(model, new_dataloader_h2, criterion, device)\n",
    "test_loss_h3, _, _, test_preds_h3, _, _, test_labels_h3 = test(model, new_dataloader_h3, criterion, device)\n",
    "\n",
    "# Calculate and print the metrics for H1, H2, and H3 using the same approach as before\n",
    "# Use the appropriate threshold and custom functions for metrics calculation\n",
    "\n",
    "# Metrics calculation for H1\n",
    "threshold_h1 = 0.5\n",
    "test_preds_h1_binary = (np.array(test_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "acc_h1 = accuracy_score(test_labels_h1, test_preds_h1_binary)\n",
    "precision_h1 = precision_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "recall_h1 = recall_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "f1_h1 = f1_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H2\n",
    "threshold_h2 = 0.5\n",
    "test_preds_h2_binary = (np.array(test_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "acc_h2 = accuracy_score(test_labels_h2, test_preds_h2_binary)\n",
    "precision_h2 = precision_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "recall_h2 = recall_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "f1_h2 = f1_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H3\n",
    "threshold_h3 = 0.5\n",
    "test_preds_h3_binary = (np.array(test_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_predictions = np.equal(y_true, y_pred)\n",
    "    sample_accuracy = np.sum(correct_predictions, axis=1) / y_true.shape[1]\n",
    "    return np.mean(sample_accuracy)\n",
    "\n",
    "def custom_precision_recall_f1(y_true, y_pred):\n",
    "    true_positives = np.sum((y_true == 1) & (y_pred == 1), axis=1)\n",
    "    false_positives = np.sum((y_true == 0) & (y_pred == 1), axis=1)\n",
    "    false_negatives = np.sum((y_true == 1) & (y_pred == 0), axis=1)\n",
    "\n",
    "    precision = np.mean(true_positives / (true_positives + false_positives + 1e-8))\n",
    "    recall = np.mean(true_positives / (true_positives + false_negatives + 1e-8))\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom accuracy calculation for H3\n",
    "acc_h3_custom = custom_accuracy(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "# Calculate custom precision, recall, and F1 score for H3\n",
    "precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "\n",
    "print(\"Testing Results:\")\n",
    "print(f\"H1: Test Loss: {test_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "print(f\"H2: Test Loss: {test_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "print(f\"H3: Test Loss: {test_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "print(f\"Precision H3: {precision_h3}, Recall H3:{recall_h3}, F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
