{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Now import your GPU-related libraries, such as PyTorch\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/users/mpagare/Data/.venv/lib/python3.8/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████| 231/231 [01:32<00:00,  2.49it/s]\n",
      "Training: 100%|██████████| 231/231 [01:35<00:00,  2.43it/s]\n",
      "Training: 100%|██████████| 231/231 [01:34<00:00,  2.44it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "H1: Train Loss: 1.7098, Val Loss: 1.4100, Accuracy: 0.9125\n",
      "Precision H1: 0.9125, Recall H1: 0.9125, F1 H1: 0.9125\n",
      "H2: Train Loss: 1.5122, Val Loss: 1.4480, Accuracy: 0.6578\n",
      "Precision H2: 0.6578, Recall H2: 0.6578, F1 H2: 0.6578\n",
      "H3: Train Loss: 1.4465, Val Loss: 1.3906, Custom Accuracy: 0.6739\n",
      "Precision H3: 0.6899420604743798,Recall H3:0.48436510679856687,F1 Score H3: 0.5691591929606629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:34<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.40it/s]\n",
      "Training: 100%|██████████| 231/231 [01:37<00:00,  2.38it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.82it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.81it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/33\n",
      "H1: Train Loss: 1.3957, Val Loss: 1.2153, Accuracy: 0.9544\n",
      "Precision H1: 0.9544, Recall H1: 0.9544, F1 H1: 0.9544\n",
      "H2: Train Loss: 1.3274, Val Loss: 1.2787, Accuracy: 0.7490\n",
      "Precision H2: 0.7490, Recall H2: 0.7490, F1 H2: 0.7490\n",
      "H3: Train Loss: 1.2335, Val Loss: 1.2514, Custom Accuracy: 0.6844\n",
      "Precision H3: 0.6844287524895889,Recall H3:0.5280422365973697,F1 Score H3: 0.5961499986540789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.38it/s]\n",
      "Training: 100%|██████████| 231/231 [01:37<00:00,  2.38it/s]\n",
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.38it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.82it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.78it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/33\n",
      "H1: Train Loss: 1.1388, Val Loss: 0.9718, Accuracy: 0.9620\n",
      "Precision H1: 0.9620, Recall H1: 0.9620, F1 H1: 0.9620\n",
      "H2: Train Loss: 1.0500, Val Loss: 1.0602, Accuracy: 0.8441\n",
      "Precision H2: 0.8441, Recall H2: 0.8441, F1 H2: 0.8441\n",
      "H3: Train Loss: 0.9434, Val Loss: 1.0137, Custom Accuracy: 0.6976\n",
      "Precision H3: 0.6745156617780192,Recall H3:0.5900221662579077,F1 Score H3: 0.6294460839582667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.38it/s]\n",
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.38it/s]\n",
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.38it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.82it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.77it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/33\n",
      "H1: Train Loss: 0.8536, Val Loss: 0.9379, Accuracy: 0.9696\n",
      "Precision H1: 0.9696, Recall H1: 0.9696, F1 H1: 0.9696\n",
      "H2: Train Loss: 0.7989, Val Loss: 0.9991, Accuracy: 0.8669\n",
      "Precision H2: 0.8669, Recall H2: 0.8669, F1 H2: 0.8669\n",
      "H3: Train Loss: 0.7480, Val Loss: 0.9886, Custom Accuracy: 0.6996\n",
      "Precision H3: 0.701548071700163,Recall H3:0.548928036475565,F1 Score H3: 0.6159244514529689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:37<00:00,  2.38it/s]\n",
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.38it/s]\n",
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.38it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.83it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.80it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/33\n",
      "H1: Train Loss: 0.7147, Val Loss: 0.8472, Accuracy: 0.9734\n",
      "Precision H1: 0.9734, Recall H1: 0.9734, F1 H1: 0.9734\n",
      "H2: Train Loss: 0.6790, Val Loss: 0.8545, Accuracy: 0.9240\n",
      "Precision H2: 0.9240, Recall H2: 0.9240, F1 H2: 0.9240\n",
      "H3: Train Loss: 0.6715, Val Loss: 0.7981, Custom Accuracy: 0.7055\n",
      "Precision H3: 0.6748415716096325,Recall H3:0.5985596047383119,F1 Score H3: 0.6344157864249877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.38it/s]\n",
      "Training: 100%|██████████| 231/231 [01:37<00:00,  2.38it/s]\n",
      "Training: 100%|██████████| 231/231 [01:34<00:00,  2.44it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.06it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.15it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/33\n",
      "H1: Train Loss: 0.6459, Val Loss: 0.8339, Accuracy: 0.9734\n",
      "Precision H1: 0.9734, Recall H1: 0.9734, F1 H1: 0.9734\n",
      "H2: Train Loss: 0.6221, Val Loss: 0.8297, Accuracy: 0.9430\n",
      "Precision H2: 0.9430, Recall H2: 0.9430, F1 H2: 0.9430\n",
      "H3: Train Loss: 0.6145, Val Loss: 0.8111, Custom Accuracy: 0.7025\n",
      "Precision H3: 0.6815951475647292,Recall H3:0.5880096456142083,F1 Score H3: 0.6313531948290527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/33\n",
      "H1: Train Loss: 0.5990, Val Loss: 0.8551, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.5980, Val Loss: 0.9273, Accuracy: 0.8973\n",
      "Precision H2: 0.8973, Recall H2: 0.8973, F1 H2: 0.8973\n",
      "H3: Train Loss: 0.5739, Val Loss: 0.8421, Custom Accuracy: 0.7101\n",
      "Precision H3: 0.7033733587916097,Recall H3:0.567860434875644,F1 Score H3: 0.6283940898882266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:34<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.16it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/33\n",
      "H1: Train Loss: 0.5837, Val Loss: 0.7239, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.5667, Val Loss: 0.7746, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.5602, Val Loss: 0.7176, Custom Accuracy: 0.7178\n",
      "Precision H3: 0.6890684410646387,Recall H3:0.6086121947338676,F1 Score H3: 0.6463461728087492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.17it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.11it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/33\n",
      "H1: Train Loss: 0.5416, Val Loss: 0.7290, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.5450, Val Loss: 0.7429, Accuracy: 0.9658\n",
      "Precision H2: 0.9658, Recall H2: 0.9658, F1 H2: 0.9658\n",
      "H3: Train Loss: 0.5532, Val Loss: 0.7346, Custom Accuracy: 0.7224\n",
      "Precision H3: 0.6814800640846268,Recall H3:0.6508419337316675,F1 Score H3: 0.6658087210680067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.17it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.15it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/33\n",
      "H1: Train Loss: 0.5450, Val Loss: 0.7120, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.5343, Val Loss: 0.7428, Accuracy: 0.9620\n",
      "Precision H2: 0.9620, Recall H2: 0.9620, F1 H2: 0.9620\n",
      "H3: Train Loss: 0.5185, Val Loss: 0.6710, Custom Accuracy: 0.7330\n",
      "Precision H3: 0.6950460608255286,Recall H3:0.6428088599191261,F1 Score H3: 0.6679076468199665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:35<00:00,  2.41it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.79it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.72it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/33\n",
      "H1: Train Loss: 0.5009, Val Loss: 0.6970, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.4975, Val Loss: 0.6735, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.4916, Val Loss: 0.6370, Custom Accuracy: 0.7450\n",
      "Precision H3: 0.713765986864846,Recall H3:0.6493813748566599,F1 Score H3: 0.6800531635711881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:37<00:00,  2.37it/s]\n",
      "Training: 100%|██████████| 231/231 [01:37<00:00,  2.38it/s]\n",
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.38it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.81it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.76it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/33\n",
      "H1: Train Loss: 0.4866, Val Loss: 0.6644, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.4858, Val Loss: 0.6791, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.4688, Val Loss: 0.6382, Custom Accuracy: 0.7572\n",
      "Precision H3: 0.7239733017299557,Recall H3:0.6774064655243361,F1 Score H3: 0.699916192481865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.38it/s]\n",
      "Training: 100%|██████████| 231/231 [01:37<00:00,  2.38it/s]\n",
      "Training: 100%|██████████| 231/231 [01:37<00:00,  2.38it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.79it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.78it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/33\n",
      "H1: Train Loss: 0.4598, Val Loss: 0.6291, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.4471, Val Loss: 0.7097, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.4334, Val Loss: 0.6651, Custom Accuracy: 0.7754\n",
      "Precision H3: 0.756277742114244,Recall H3:0.6752639101498417,F1 Score H3: 0.713478457985026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:36<00:00,  2.40it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.16it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.18it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/33\n",
      "H1: Train Loss: 0.4311, Val Loss: 0.6086, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.4230, Val Loss: 0.6621, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.4049, Val Loss: 0.6373, Custom Accuracy: 0.7994\n",
      "Precision H3: 0.7882549009925436,Recall H3:0.715995780729621,F1 Score H3: 0.7503897988651187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.17it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/33\n",
      "H1: Train Loss: 0.3945, Val Loss: 0.5826, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.3823, Val Loss: 0.5702, Accuracy: 0.9734\n",
      "Precision H2: 0.9734, Recall H2: 0.9734, F1 H2: 0.9734\n",
      "H3: Train Loss: 0.3731, Val Loss: 0.5486, Custom Accuracy: 0.8105\n",
      "Precision H3: 0.7880011412330804,Recall H3:0.752443500732474,F1 Score H3: 0.769811937589721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.16it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/33\n",
      "H1: Train Loss: 0.3682, Val Loss: 0.6002, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.3488, Val Loss: 0.6548, Accuracy: 0.9506\n",
      "Precision H2: 0.9506, Recall H2: 0.9506, F1 H2: 0.9506\n",
      "H3: Train Loss: 0.3367, Val Loss: 0.5915, Custom Accuracy: 0.8274\n",
      "Precision H3: 0.8499894381073088,Recall H3:0.722141019099194,F1 Score H3: 0.7808667992464668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.15it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/33\n",
      "H1: Train Loss: 0.3456, Val Loss: 0.5746, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.3575, Val Loss: 0.5814, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.3135, Val Loss: 0.5332, Custom Accuracy: 0.8435\n",
      "Precision H3: 0.8358867051832831,Recall H3:0.7887500754420906,F1 Score H3: 0.811634587665272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:34<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.15it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.15it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/33\n",
      "H1: Train Loss: 0.3048, Val Loss: 0.5470, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.2829, Val Loss: 0.5313, Accuracy: 0.9620\n",
      "Precision H2: 0.9620, Recall H2: 0.9620, F1 H2: 0.9620\n",
      "H3: Train Loss: 0.2712, Val Loss: 0.4644, Custom Accuracy: 0.8681\n",
      "Precision H3: 0.8749740753543035,Recall H3:0.7975903796246001,F1 Score H3: 0.8344920912866403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.15it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/33\n",
      "H1: Train Loss: 0.2639, Val Loss: 0.5041, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.2531, Val Loss: 0.5102, Accuracy: 0.9620\n",
      "Precision H2: 0.9620, Recall H2: 0.9620, F1 H2: 0.9620\n",
      "H3: Train Loss: 0.2401, Val Loss: 0.4605, Custom Accuracy: 0.8842\n",
      "Precision H3: 0.8900020026445882,Recall H3:0.8229177982980265,F1 Score H3: 0.8551462690711873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:34<00:00,  2.45it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.15it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/33\n",
      "H1: Train Loss: 0.2363, Val Loss: 0.4948, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.2244, Val Loss: 0.4442, Accuracy: 0.9658\n",
      "Precision H2: 0.9658, Recall H2: 0.9658, F1 H2: 0.9658\n",
      "H3: Train Loss: 0.2075, Val Loss: 0.4094, Custom Accuracy: 0.9047\n",
      "Precision H3: 0.8989966201943388,Recall H3:0.8682587691142825,F1 Score H3: 0.8833603831228999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.17it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.16it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/33\n",
      "H1: Train Loss: 0.2023, Val Loss: 0.4849, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.2009, Val Loss: 0.4694, Accuracy: 0.9620\n",
      "Precision H2: 0.9620, Recall H2: 0.9620, F1 H2: 0.9620\n",
      "H3: Train Loss: 0.1955, Val Loss: 0.4055, Custom Accuracy: 0.9184\n",
      "Precision H3: 0.9201324763111836,Recall H3:0.8816498773723108,F1 Score H3: 0.900480219764145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.16it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.16it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/33\n",
      "H1: Train Loss: 0.1775, Val Loss: 0.4901, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.1682, Val Loss: 0.4681, Accuracy: 0.9544\n",
      "Precision H2: 0.9544, Recall H2: 0.9544, F1 H2: 0.9544\n",
      "H3: Train Loss: 0.1697, Val Loss: 0.3952, Custom Accuracy: 0.9254\n",
      "Precision H3: 0.9211237853823405,Recall H3:0.9018746673689638,F1 Score H3: 0.9113976002487255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/33\n",
      "H1: Train Loss: 0.1545, Val Loss: 0.4438, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.1456, Val Loss: 0.3811, Accuracy: 0.9658\n",
      "Precision H2: 0.9658, Recall H2: 0.9658, F1 H2: 0.9658\n",
      "H3: Train Loss: 0.1373, Val Loss: 0.3420, Custom Accuracy: 0.9427\n",
      "Precision H3: 0.941969806703647,Recall H3:0.9209932019817951,F1 Score H3: 0.9313634080778984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.18it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/33\n",
      "H1: Train Loss: 0.1317, Val Loss: 0.4453, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.1249, Val Loss: 0.3933, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.1204, Val Loss: 0.3485, Custom Accuracy: 0.9468\n",
      "Precision H3: 0.9455715492787736,Recall H3:0.9223346995210113,F1 Score H3: 0.9338085905971357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.10it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/33\n",
      "H1: Train Loss: 0.1143, Val Loss: 0.4983, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.1127, Val Loss: 0.4123, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.1082, Val Loss: 0.3537, Custom Accuracy: 0.9476\n",
      "Precision H3: 0.9437669744703966,Recall H3:0.9315323248783325,F1 Score H3: 0.9376097396048912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.15it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.16it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/33\n",
      "H1: Train Loss: 0.1161, Val Loss: 0.4621, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.1148, Val Loss: 0.3948, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.0989, Val Loss: 0.3304, Custom Accuracy: 0.9526\n",
      "Precision H3: 0.9488532802221015,Recall H3:0.937917880598489,F1 Score H3: 0.9433538905669768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.13it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/33\n",
      "H1: Train Loss: 0.0951, Val Loss: 0.4282, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.0883, Val Loss: 0.3759, Accuracy: 0.9696\n",
      "Precision H2: 0.9696, Recall H2: 0.9696, F1 H2: 0.9696\n",
      "H3: Train Loss: 0.0862, Val Loss: 0.3224, Custom Accuracy: 0.9564\n",
      "Precision H3: 0.9490901683867463,Recall H3:0.9438505094398632,F1 Score H3: 0.9464630872264979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.18it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.16it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/33\n",
      "H1: Train Loss: 0.0909, Val Loss: 0.4380, Accuracy: 0.9886\n",
      "Precision H1: 0.9886, Recall H1: 0.9886, F1 H1: 0.9886\n",
      "H2: Train Loss: 0.0820, Val Loss: 0.3499, Accuracy: 0.9696\n",
      "Precision H2: 0.9696, Recall H2: 0.9696, F1 H2: 0.9696\n",
      "H3: Train Loss: 0.0741, Val Loss: 0.2997, Custom Accuracy: 0.9585\n",
      "Precision H3: 0.9558693946526646,Recall H3:0.9439245798561388,F1 Score H3: 0.9498594361824335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.47it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.17it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/33\n",
      "H1: Train Loss: 0.0707, Val Loss: 0.4640, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.0650, Val Loss: 0.4057, Accuracy: 0.9620\n",
      "Precision H2: 0.9620, Recall H2: 0.9620, F1 H2: 0.9620\n",
      "H3: Train Loss: 0.0636, Val Loss: 0.3675, Custom Accuracy: 0.9608\n",
      "Precision H3: 0.9561470215462611,Recall H3:0.9476259059909249,F1 Score H3: 0.9518673938970613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:34<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:34<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.16it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.15it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/33\n",
      "H1: Train Loss: 0.0618, Val Loss: 0.4703, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.0592, Val Loss: 0.4050, Accuracy: 0.9658\n",
      "Precision H2: 0.9658, Recall H2: 0.9658, F1 H2: 0.9658\n",
      "H3: Train Loss: 0.0571, Val Loss: 0.3194, Custom Accuracy: 0.9629\n",
      "Precision H3: 0.96103566902046,Recall H3:0.9473316818373853,F1 Score H3: 0.9541344712585019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.15it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.12it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/33\n",
      "H1: Train Loss: 0.0525, Val Loss: 0.4832, Accuracy: 0.9772\n",
      "Precision H1: 0.9772, Recall H1: 0.9772, F1 H1: 0.9772\n",
      "H2: Train Loss: 0.0513, Val Loss: 0.3806, Accuracy: 0.9620\n",
      "Precision H2: 0.9620, Recall H2: 0.9620, F1 H2: 0.9620\n",
      "H3: Train Loss: 0.0499, Val Loss: 0.3131, Custom Accuracy: 0.9608\n",
      "Precision H3: 0.9587180879956546,Recall H3:0.9450032645850135,F1 Score H3: 0.9518112740023023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:34<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:34<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.15it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/33\n",
      "H1: Train Loss: 0.0480, Val Loss: 0.5237, Accuracy: 0.9848\n",
      "Precision H1: 0.9848, Recall H1: 0.9848, F1 H1: 0.9848\n",
      "H2: Train Loss: 0.0468, Val Loss: 0.4249, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.0478, Val Loss: 0.3338, Custom Accuracy: 0.9643\n",
      "Precision H3: 0.9630635524171647,Recall H3:0.9500640571933348,F1 Score H3: 0.9565196397231022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Training: 100%|██████████| 231/231 [01:33<00:00,  2.46it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.14it/s]\n",
      "Validation: 100%|██████████| 33/33 [00:05<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/33\n",
      "H1: Train Loss: 0.0441, Val Loss: 0.5424, Accuracy: 0.9810\n",
      "Precision H1: 0.9810, Recall H1: 0.9810, F1 H1: 0.9810\n",
      "H2: Train Loss: 0.0926, Val Loss: 0.4741, Accuracy: 0.9582\n",
      "Precision H2: 0.9582, Recall H2: 0.9582, F1 H2: 0.9582\n",
      "H3: Train Loss: 0.0681, Val Loss: 0.3710, Custom Accuracy: 0.9585\n",
      "Precision H3: 0.9559116422234293,Recall H3:0.9409640950515475,F1 Score H3: 0.9483789746461571\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and set up CUDA\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "random_seed = 777  # You can change this value to any seed you prefer\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "\n",
    "# Load and preprocess your data for H1, H2, and H3\n",
    "model1_data = pd.read_csv(\"model1_2636.csv\")\n",
    "texts_h1 = model1_data['text'].tolist()\n",
    "labels_h1 = model1_data.iloc[:, 1].values.tolist()\n",
    "\n",
    "model2_data = pd.read_csv(\"model2_2636.csv\")\n",
    "texts_h2 = model2_data['text'].tolist()\n",
    "labels_h2 = model2_data.iloc[:, 1].values.tolist()\n",
    "\n",
    "model3_data = pd.read_csv(\"model3_2636.csv\")\n",
    "texts_h3 = model3_data['text'].tolist()\n",
    "labels_h3 = model3_data.iloc[:, 1:].values.tolist()\n",
    "\n",
    "#print(\"Total Records in H1:\", len(texts_h1),\"texts_h1\", \"with\", len(labels_h1), \"labels\")\n",
    "#print(\"Total Records in H2:\", len(texts_h2),\"texts_h2\",\"with\", len(labels_h2), \"labels\")\n",
    "#print(\"Total Records in H3:\", len(texts_h3),\"texts_h3\", \"with\", len(labels_h3), \"labels\")\n",
    "\n",
    "# Split the data for each hierarchy\n",
    "def split_data(texts, labels, train_ratio, val_ratio, test_ratio):\n",
    "    total_samples = len(texts)\n",
    "    train_size = int(total_samples * train_ratio)\n",
    "    val_size = int(total_samples * val_ratio)\n",
    "    test_size = total_samples - train_size - val_size  # Remaining samples for test\n",
    "\n",
    "    train_texts = texts[:train_size]\n",
    "    val_texts = texts[train_size:train_size + val_size]\n",
    "    test_texts = texts[train_size + val_size:]\n",
    "\n",
    "    train_labels = labels[:train_size]\n",
    "    val_labels = labels[train_size:train_size + val_size]\n",
    "    test_labels = labels[train_size + val_size:]\n",
    "\n",
    "    return train_texts, val_texts, test_texts, train_labels, val_labels, test_labels\n",
    "\n",
    "# Split the data for each hierarchy\n",
    "train_texts_h1, val_texts_h1, test_texts_h1, train_labels_h1, val_labels_h1, test_labels_h1 = split_data(texts_h1, labels_h1, 0.7, 0.1, 0.2)\n",
    "train_texts_h2, val_texts_h2, test_texts_h2, train_labels_h2, val_labels_h2, test_labels_h2 = split_data(texts_h2, labels_h2, 0.7, 0.1, 0.2)\n",
    "train_texts_h3, val_texts_h3, test_texts_h3, train_labels_h3, val_labels_h3, test_labels_h3 = split_data(texts_h3, labels_h3, 0.7, 0.1, 0.2)\n",
    "\n",
    "#print(\"Train Val Test Splitting:\")\n",
    "#print(\"H1:\", len(train_texts_h1), len(val_texts_h1), len(test_texts_h1))\n",
    "#print(\"H2:\", len(train_texts_h2), len(val_texts_h2), len(test_texts_h2))\n",
    "#print(\"H3:\", len(train_texts_h3), len(val_texts_h3), len(test_texts_h3))\n",
    "\n",
    "# Tokenizer\n",
    "\n",
    "# Import and initialize the ClinicalBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "clinical_bert_model = AutoModel.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "\n",
    "\n",
    "# Define the TextDataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Now expecting a list of binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    # Rest of the code remains unchanged\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Create datasets and dataloaders for H1, H2, and H3\n",
    "dataset_h1 = TextDataset(train_texts_h1 + val_texts_h1 + test_texts_h1, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "dataset_h2 = TextDataset(train_texts_h2 + val_texts_h2 + test_texts_h2, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "dataset_h3 = TextDataset(train_texts_h3 + val_texts_h3 + test_texts_h3, train_labels_h1 + val_labels_h1 + test_labels_h1, train_labels_h2 + val_labels_h2 + test_labels_h2, train_labels_h3 + val_labels_h3 + test_labels_h3, tokenizer)\n",
    "\n",
    "# Split the datasets into train, val, and test for H1, H2, and H3\n",
    "train_size_h1 = len(train_texts_h1)\n",
    "val_size_h1 = len(val_texts_h1)\n",
    "train_size_h2 = len(train_texts_h2)\n",
    "val_size_h2 = len(val_texts_h2)\n",
    "train_size_h3 = len(train_texts_h3)\n",
    "val_size_h3 = len(val_texts_h3)\n",
    "\n",
    "train_dataset_h1, val_dataset_h1, test_dataset_h1 = random_split(dataset_h1, [train_size_h1, val_size_h1, len(test_texts_h1)])\n",
    "train_dataset_h2, val_dataset_h2, test_dataset_h2 = random_split(dataset_h2, [train_size_h2, val_size_h2, len(test_texts_h2)])\n",
    "train_dataset_h3, val_dataset_h3, test_dataset_h3 = random_split(dataset_h3, [train_size_h3, val_size_h3, len(test_texts_h3)])\n",
    "\n",
    "# Create dataloaders for H1, H2, and H3\n",
    "train_dataloader_h1 = DataLoader(train_dataset_h1, batch_size=8, shuffle=True)\n",
    "val_dataloader_h1 = DataLoader(val_dataset_h1,batch_size=8, shuffle=False)  # You can set shuffle to True if you want to shuffle the validation data.\n",
    "train_dataloader_h2 = DataLoader(train_dataset_h2, batch_size=8, shuffle=True)\n",
    "val_dataloader_h2 = DataLoader(val_dataset_h2, batch_size=8, shuffle=False)\n",
    "\n",
    "train_dataloader_h3 = DataLoader(train_dataset_h3, batch_size=8, shuffle=True)\n",
    "val_dataloader_h3 = DataLoader(val_dataset_h3, batch_size=8, shuffle=False)\n",
    "\n",
    "# Define the model architecture for H1, H2, and H3\n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.bert = clinical_bert_model  # Use the ClinicalBERT model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc_h1 = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.fc_h2 = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.fc_h3 = nn.Linear(self.bert.config.hidden_size, num_labels_h3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "model = HierarchicalClassifier(num_labels_h3=len(train_labels_h3[0]))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)  # You can adjust the learning rate as needed\n",
    "\n",
    "# Training loop for H1, H2, and H3\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, total=len(dataloader), desc=\"Training\"):\n",
    "        input_ids = batch['ids'].to(device)\n",
    "        attention_mask = batch['mask'].to(device)\n",
    "        labels_h1 = batch['labels_h1'].to(device)\n",
    "        labels_h2 = batch['labels_h2'].to(device)\n",
    "        labels_h3 = batch['labels_h3'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "        loss_h1 = criterion(logits_h1, labels_h1)\n",
    "        loss_h2 = criterion(logits_h2, labels_h2)\n",
    "        loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "        loss = loss_h1 + loss_h2 + loss_h3\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Validation loop for H1, H2, and H3\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Validation\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels_h1 = batch['labels_h1'].to(device)\n",
    "            labels_h2 = batch['labels_h2'].to(device)\n",
    "            labels_h3 = batch['labels_h3'].to(device)\n",
    "\n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "# Training and evaluation for H1, H2, and H3\n",
    "# Custom accuracy function\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_labels = np.sum(np.equal(y_true, y_pred), axis=1)\n",
    "    total_labels = y_true.shape[1]\n",
    "    sample_accuracy = np.mean(correct_labels / total_labels)\n",
    "    return sample_accuracy\n",
    "\n",
    "def custom_precision_recall_f1(y_true, y_pred):\n",
    "    # Calculate precision and recall for each sample\n",
    "    sample_precisions = []\n",
    "    sample_recalls = []\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_positive = np.sum((true == 1) & (pred == 1))\n",
    "        false_positive = np.sum((true == 0) & (pred == 1))\n",
    "        false_negative = np.sum((true == 1) & (pred == 0))\n",
    "        \n",
    "        sample_precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "        sample_recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "        \n",
    "        sample_precisions.append(sample_precision)\n",
    "        sample_recalls.append(sample_recall)\n",
    "    \n",
    "    # Calculate average precision and recall across all samples\n",
    "    avg_precision = np.mean(sample_precisions)\n",
    "    avg_recall = np.mean(sample_recalls)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    if avg_precision + avg_recall > 0:\n",
    "        avg_f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
    "    else:\n",
    "        avg_f1 = 0\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "\n",
    "# Training and evaluation for H1, H2, and H3\n",
    "num_epochs = 33 # You can adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training for H1\n",
    "    train_loss_h1 = train(model, train_dataloader_h1, optimizer, criterion, device)\n",
    "    # Training for H2\n",
    "    train_loss_h2 = train(model, train_dataloader_h2, optimizer, criterion, device)\n",
    "    # Training for H3\n",
    "    train_loss_h3 = train(model, train_dataloader_h3, optimizer, criterion, device)\n",
    "\n",
    "    # Validation for H1\n",
    "    val_loss_h1, val_preds_h1, _, _, val_labels_h1, _, _ = evaluate(model, val_dataloader_h1, criterion, device)\n",
    "    # Validation for H2\n",
    "    val_loss_h2, _, val_preds_h2, _, _, val_labels_h2, _ = evaluate(model, val_dataloader_h2, criterion, device)\n",
    "    # Validation for H3\n",
    "    val_loss_h3, _, _, val_preds_h3, _, _, val_labels_h3 = evaluate(model, val_dataloader_h3, criterion, device)\n",
    "\n",
    "    # Metrics calculation for H1\n",
    "    threshold_h1 = 0.5\n",
    "    val_preds_h1_binary = (np.array(val_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "    acc_h1 = accuracy_score(val_labels_h1, val_preds_h1_binary)\n",
    "    precision_h1 = precision_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    recall_h1 = recall_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "    f1_h1 = f1_score(val_labels_h1, val_preds_h1_binary, average='micro')\n",
    "\n",
    "\n",
    "    # Metrics calculation for H2\n",
    "    threshold_h2 = 0.5\n",
    "    val_preds_h2_binary = (np.array(val_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "    acc_h2 = accuracy_score(val_labels_h2, val_preds_h2_binary)\n",
    "    precision_h2 = precision_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    recall_h2 = recall_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "    f1_h2 = f1_score(val_labels_h2, val_preds_h2_binary, average='micro')\n",
    "\n",
    "# Convert predictions and labels to binary using the threshold\n",
    "\n",
    "    # Metrics calculation for H3\n",
    "    threshold_h3 = 0.5\n",
    "    val_preds_h3_binary = (np.array(val_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "\n",
    "    # Custom accuracy calculation for H3\n",
    "    acc_h3_custom = custom_accuracy(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "    # Calculate custom precision, recall, and F1 score for H3\n",
    "    precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(val_labels_h3), val_preds_h3_binary)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"H1: Train Loss: {train_loss_h1:.4f}, Val Loss: {val_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "    print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "    print(f\"H2: Train Loss: {train_loss_h2:.4f}, Val Loss: {val_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "    print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "    print(f\"H3: Train Loss: {train_loss_h3:.4f}, Val Loss: {val_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "    print(f\"Precision H3: {precision_h3},Recall H3:{recall_h3},F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "# Saving the model\n",
    "torch.save(model.state_dict(), 'model_clinicalBert.pth')\n",
    "\n",
    "# Loading the model\n",
    "#loaded_model = YourModelClass(*args, **kwargs)  # Instantiate your model\n",
    "#loaded_model.load_state_dict(torch.load('model.pth'))\n",
    "#loaded_model.eval()  # Set the model to evaluation mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   2%|▏         | 1/66 [00:00<00:11,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   5%|▍         | 3/66 [00:00<00:10,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   8%|▊         | 5/66 [00:00<00:09,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  11%|█         | 7/66 [00:01<00:09,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  14%|█▎        | 9/66 [00:01<00:09,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  17%|█▋        | 11/66 [00:01<00:08,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  20%|█▉        | 13/66 [00:02<00:08,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  23%|██▎       | 15/66 [00:02<00:08,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  26%|██▌       | 17/66 [00:02<00:07,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  29%|██▉       | 19/66 [00:03<00:07,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  32%|███▏      | 21/66 [00:03<00:07,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  35%|███▍      | 23/66 [00:03<00:06,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  38%|███▊      | 25/66 [00:03<00:06,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  41%|████      | 27/66 [00:04<00:06,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  44%|████▍     | 29/66 [00:04<00:06,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  47%|████▋     | 31/66 [00:04<00:05,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  50%|█████     | 33/66 [00:05<00:05,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  53%|█████▎    | 35/66 [00:05<00:05,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  56%|█████▌    | 37/66 [00:05<00:04,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  59%|█████▉    | 39/66 [00:06<00:04,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  62%|██████▏   | 41/66 [00:06<00:04,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  65%|██████▌   | 43/66 [00:06<00:03,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  68%|██████▊   | 45/66 [00:07<00:03,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  71%|███████   | 47/66 [00:07<00:03,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  74%|███████▍  | 49/66 [00:07<00:02,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  77%|███████▋  | 51/66 [00:08<00:02,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  80%|████████  | 53/66 [00:08<00:02,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  83%|████████▎ | 55/66 [00:08<00:01,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  86%|████████▋ | 57/66 [00:09<00:01,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  89%|████████▉ | 59/66 [00:09<00:01,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  92%|█████████▏| 61/66 [00:09<00:00,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  95%|█████████▌| 63/66 [00:10<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  98%|█████████▊| 65/66 [00:10<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 66/66 [00:10<00:00,  6.23it/s]\n",
      "Testing:   2%|▏         | 1/66 [00:00<00:10,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   5%|▍         | 3/66 [00:00<00:09,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   8%|▊         | 5/66 [00:00<00:09,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  11%|█         | 7/66 [00:01<00:09,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  14%|█▎        | 9/66 [00:01<00:09,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  17%|█▋        | 11/66 [00:01<00:08,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  20%|█▉        | 13/66 [00:02<00:08,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  23%|██▎       | 15/66 [00:02<00:08,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  26%|██▌       | 17/66 [00:02<00:07,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  29%|██▉       | 19/66 [00:03<00:07,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  32%|███▏      | 21/66 [00:03<00:07,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  35%|███▍      | 23/66 [00:03<00:06,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  38%|███▊      | 25/66 [00:03<00:06,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  41%|████      | 27/66 [00:04<00:06,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  44%|████▍     | 29/66 [00:04<00:06,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  47%|████▋     | 31/66 [00:04<00:05,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  50%|█████     | 33/66 [00:05<00:05,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  53%|█████▎    | 35/66 [00:05<00:05,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  56%|█████▌    | 37/66 [00:05<00:04,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  59%|█████▉    | 39/66 [00:06<00:04,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  62%|██████▏   | 41/66 [00:06<00:04,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  65%|██████▌   | 43/66 [00:06<00:03,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  68%|██████▊   | 45/66 [00:07<00:03,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  71%|███████   | 47/66 [00:07<00:03,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  74%|███████▍  | 49/66 [00:07<00:02,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  77%|███████▋  | 51/66 [00:08<00:02,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  80%|████████  | 53/66 [00:08<00:02,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  83%|████████▎ | 55/66 [00:08<00:01,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  86%|████████▋ | 57/66 [00:09<00:01,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  89%|████████▉ | 59/66 [00:09<00:01,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  92%|█████████▏| 61/66 [00:09<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  95%|█████████▌| 63/66 [00:10<00:00,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  98%|█████████▊| 65/66 [00:10<00:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 66/66 [00:10<00:00,  6.23it/s]\n",
      "Testing:   2%|▏         | 1/66 [00:00<00:10,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   5%|▍         | 3/66 [00:00<00:09,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   8%|▊         | 5/66 [00:00<00:09,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   9%|▉         | 6/66 [00:00<00:09,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  12%|█▏        | 8/66 [00:01<00:09,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  15%|█▌        | 10/66 [00:01<00:08,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  18%|█▊        | 12/66 [00:01<00:08,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  21%|██        | 14/66 [00:02<00:08,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  24%|██▍       | 16/66 [00:02<00:07,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  27%|██▋       | 18/66 [00:02<00:07,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  30%|███       | 20/66 [00:03<00:07,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  33%|███▎      | 22/66 [00:03<00:07,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  36%|███▋      | 24/66 [00:03<00:06,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  39%|███▉      | 26/66 [00:04<00:06,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  42%|████▏     | 28/66 [00:04<00:06,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  45%|████▌     | 30/66 [00:04<00:05,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  48%|████▊     | 32/66 [00:05<00:05,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  52%|█████▏    | 34/66 [00:05<00:05,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  55%|█████▍    | 36/66 [00:05<00:04,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  58%|█████▊    | 38/66 [00:06<00:04,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  61%|██████    | 40/66 [00:06<00:04,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  64%|██████▎   | 42/66 [00:06<00:03,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  67%|██████▋   | 44/66 [00:07<00:03,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  70%|██████▉   | 46/66 [00:07<00:03,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  73%|███████▎  | 48/66 [00:07<00:02,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  76%|███████▌  | 50/66 [00:08<00:02,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  79%|███████▉  | 52/66 [00:08<00:02,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  82%|████████▏ | 54/66 [00:08<00:01,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  85%|████████▍ | 56/66 [00:09<00:01,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  88%|████████▊ | 58/66 [00:09<00:01,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  91%|█████████ | 60/66 [00:09<00:00,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  94%|█████████▍| 62/66 [00:09<00:00,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  97%|█████████▋| 64/66 [00:10<00:00,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 66/66 [00:10<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels H1 shape: torch.Size([8, 1])\n",
      "Labels H2 shape: torch.Size([8, 1])\n",
      "Labels H3 shape: torch.Size([8, 13])\n",
      "Logits H1 shape: torch.Size([8, 1])\n",
      "Logits H2 shape: torch.Size([8, 1])\n",
      "Logits H3 shape: torch.Size([8, 13])\n",
      "Testing Results:\n",
      "H1: Test Loss: 0.0991, Accuracy: 0.9981\n",
      "Precision H1: 0.9981, Recall H1: 0.9981, F1 H1: 0.9981\n",
      "H2: Test Loss: 0.0991, Accuracy: 0.9905\n",
      "Precision H2: 0.9905, Recall H2: 0.9905, F1 H2: 0.9905\n",
      "H3: Test Loss: 0.0991, Custom Accuracy: 0.9904\n",
      "Precision H3: 0.9919890873015872, Recall H3:0.9869055134680135, F1 Score H3: 0.9894407707993158\n"
     ]
    }
   ],
   "source": [
    "# Create test datasets for H1, H2, and H3\n",
    "test_dataset_h1 = TextDataset(test_texts_h1, test_labels_h1, test_labels_h2, test_labels_h3, tokenizer)\n",
    "test_dataset_h2 = TextDataset(test_texts_h2, test_labels_h1, test_labels_h2, test_labels_h3, tokenizer)\n",
    "test_dataset_h3 = TextDataset(test_texts_h3, test_labels_h1, test_labels_h2, test_labels_h3, tokenizer)\n",
    "\n",
    "# Create test dataloaders for H1, H2, and H3\n",
    "test_dataloader_h1 = DataLoader(test_dataset_h1, batch_size=8, shuffle=False)\n",
    "test_dataloader_h2 = DataLoader(test_dataset_h2, batch_size=8, shuffle=False)\n",
    "test_dataloader_h3 = DataLoader(test_dataset_h3, batch_size=8, shuffle=False)\n",
    "# Testing loop for H1, H2, and H3\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Testing\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            labels_h1 = batch['labels_h1'].to(device)  # No need to reshape labels_h1\n",
    "            labels_h2 = batch['labels_h2'].to(device)  # No need to reshape labels_h2\n",
    "\n",
    "            #labels_h1 = batch['labels_h1'].unsqueeze(1).to(device)  # Reshape labels_h1\n",
    "            #labels_h2 = batch['labels_h2'].unsqueeze(1).to(device)  # Reshape labels_h2\n",
    "            #labels_h3 = batch['labels_h3'].unsqueeze(1).to(device)  # Reshape labels_h3\n",
    "            labels_h3 = batch['labels_h3'].to(device)  # No need to reshape labels_h3\n",
    "            print(\"Labels H1 shape:\", labels_h1.shape)\n",
    "            print(\"Labels H2 shape:\", labels_h2.shape)\n",
    "            print(\"Labels H3 shape:\", labels_h3.shape)\n",
    "\n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            \n",
    "            print(\"Logits H1 shape:\", logits_h1.shape)\n",
    "            print(\"Logits H2 shape:\", logits_h2.shape)\n",
    "            print(\"Logits H3 shape:\", logits_h3.shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "# Testing for H1\n",
    "test_loss_h1, test_preds_h1, _, _, test_labels_h1, _, _ = test(model, test_dataloader_h1, criterion, device)\n",
    "# Testing for H2\n",
    "test_loss_h2, _, test_preds_h2, _, _, test_labels_h2, _ = test(model, test_dataloader_h2, criterion, device)\n",
    "# Testing for H3\n",
    "test_loss_h3, _, _, test_preds_h3, _, _, test_labels_h3 = test(model, test_dataloader_h3, criterion, device)\n",
    "\n",
    "# Metrics calculation for H1\n",
    "threshold_h1 = 0.5\n",
    "test_preds_h1_binary = (np.array(test_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "acc_h1 = accuracy_score(test_labels_h1, test_preds_h1_binary)\n",
    "precision_h1 = precision_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "recall_h1 = recall_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "f1_h1 = f1_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H2\n",
    "threshold_h2 = 0.5\n",
    "test_preds_h2_binary = (np.array(test_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "acc_h2 = accuracy_score(test_labels_h2, test_preds_h2_binary)\n",
    "precision_h2 = precision_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "recall_h2 = recall_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "f1_h2 = f1_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H3\n",
    "threshold_h3 = 0.5\n",
    "test_preds_h3_binary = (np.array(test_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "# Custom accuracy calculation for H3\n",
    "acc_h3_custom = custom_accuracy(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "# Calculate custom precision, recall, and F1 score for H3\n",
    "precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "\n",
    "print(\"Testing Results:\")\n",
    "print(f\"H1: Test Loss: {test_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "print(f\"H2: Test Loss: {test_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "print(f\"H3: Test Loss: {test_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "print(f\"Precision H3: {precision_h3}, Recall H3:{recall_h3}, F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 26/26 [00:04<00:00,  5.22it/s]\n",
      "Testing: 100%|██████████| 26/26 [00:04<00:00,  5.96it/s]\n",
      "Testing: 100%|██████████| 26/26 [00:04<00:00,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Results:\n",
      "H1: Test Loss: 0.5658, Accuracy: 0.9712\n",
      "Precision H1: 0.9712, Recall H1: 0.9712, F1 H1: 0.9712\n",
      "H2: Test Loss: 0.5658, Accuracy: 0.9856\n",
      "Precision H2: 0.9856, Recall H2: 0.9856, F1 H2: 0.9856\n",
      "H3: Test Loss: 0.5658, Custom Accuracy: 0.8961\n",
      "Precision H3: 0.7919204039683364, Recall H3:0.9029647408127635, F1 Score H3: 0.8438049035906062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming the new unseen datasets are similar to 'model1_2636.csv', 'model2_2636.csv', 'model3_2636.csv'\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "#from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Loading and preprocessing new_data_h1\n",
    "new_data_h1 = pd.read_csv(\"112_H_100_O_NEWMODEL1.CSV\")\n",
    "new_data_h1['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h1 = new_data_h1['text'].tolist()\n",
    "new_labels_h1 = new_data_h1.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h2\n",
    "new_data_h2 = pd.read_csv(\"112_H_100_O_NEWMODEL2.CSV\")\n",
    "new_data_h2['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h2 = new_data_h2['text'].tolist()\n",
    "new_labels_h2 = new_data_h2.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h3 for multi-label classification\n",
    "new_data_h3 = pd.read_csv(\"112_H_100_O_NEWMODEL3.CSV\")\n",
    "new_data_h3['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "\n",
    "# Replace NaN values in label columns with 0 for new_data_h3\n",
    "# Assuming all label columns are binary, fill NaN values with 0\n",
    "for label_col in new_data_h3.columns[1:]:  # Skip the text column, only fill NaN in label columns\n",
    "    new_data_h3[label_col].fillna(0, inplace=True)\n",
    "\n",
    "new_texts_h3 = new_data_h3['text'].tolist()\n",
    "new_labels_h3 = new_data_h3.iloc[:, 1:].values.tolist()  # Extract labels after filling NaN values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tokenizer\n",
    "\n",
    "# Import and initialize the ClinicalBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "clinical_bert_model = AutoModel.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "\n",
    "\n",
    "# Define the TextDataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Now expecting a list of binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    # Rest of the code remains unchanged\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "        \n",
    "# Define the model architecture for H1, H2, and H3\n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.bert = clinical_bert_model  # Use the ClinicalBERT model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc_h1 = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.fc_h2 = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.fc_h3 = nn.Linear(self.bert.config.hidden_size, num_labels_h3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "\n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "#model = HierarchicalClassifier(num_labels_h3=len(train_labels_h3[0]))\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#from transformers import RobertaTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Preprocess the texts and labels in the same way as the original datasets\n",
    "# Assuming the preprocessing steps are included in the TextDataset class\n",
    "# Create TextDataset instances for the new data\n",
    "new_dataset_h1 = TextDataset(new_texts_h1, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "new_dataset_h2 = TextDataset(new_texts_h2, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "new_dataset_h3 = TextDataset(new_texts_h3, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "\n",
    "# Create DataLoader instances for the new datasets\n",
    "#new_dataloader_h1 = DataLoader(new_dataset_h1, batch_size=8, shuffle=False)\n",
    "#new_dataloader_h2 = DataLoader(new_dataset_h2, batch_size=8, shuffle=False)\n",
    "#new_dataloader_h3 = DataLoader(new_dataset_h3, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "new_dataloader_h1 = DataLoader(new_dataset_h1, batch_size=8, shuffle=False, drop_last=True)\n",
    "new_dataloader_h2 = DataLoader(new_dataset_h2, batch_size=8, shuffle=False, drop_last=True)\n",
    "new_dataloader_h3 = DataLoader(new_dataset_h3, batch_size=8, shuffle=False, drop_last=True)\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'model_clinicalBert.pth'  # Path to your saved model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = HierarchicalClassifier(num_labels_h3=len(new_labels_h3[0]))  # Make sure to provide the correct number of labels for H3\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Testing\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            \n",
    "            # Ensuring labels are correctly shaped and moved to the device\n",
    "            labels_h1 = batch['labels_h1'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h2 = batch['labels_h2'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h3 = batch['labels_h3'].to(device)  # Shape: [batch_size, num_labels_h3]\n",
    "            \n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Compute loss for each hierarchy\n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert logits to probabilities for binary classification/multi-label classification\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            # Store predictions and labels for metric calculation\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Testing the model on the new unseen data\n",
    "test_loss_h1, test_preds_h1, _, _, test_labels_h1, _, _ = test(model, new_dataloader_h1, criterion, device)\n",
    "test_loss_h2, _, test_preds_h2, _, _, test_labels_h2, _ = test(model, new_dataloader_h2, criterion, device)\n",
    "test_loss_h3, _, _, test_preds_h3, _, _, test_labels_h3 = test(model, new_dataloader_h3, criterion, device)\n",
    "\n",
    "# Calculate and print the metrics for H1, H2, and H3 using the same approach as before\n",
    "# Use the appropriate threshold and custom functions for metrics calculation\n",
    "\n",
    "# Metrics calculation for H1\n",
    "threshold_h1 = 0.5\n",
    "test_preds_h1_binary = (np.array(test_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "acc_h1 = accuracy_score(test_labels_h1, test_preds_h1_binary)\n",
    "precision_h1 = precision_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "recall_h1 = recall_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "f1_h1 = f1_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H2\n",
    "threshold_h2 = 0.5\n",
    "test_preds_h2_binary = (np.array(test_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "acc_h2 = accuracy_score(test_labels_h2, test_preds_h2_binary)\n",
    "precision_h2 = precision_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "recall_h2 = recall_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "f1_h2 = f1_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H3\n",
    "threshold_h3 = 0.5\n",
    "test_preds_h3_binary = (np.array(test_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_predictions = np.equal(y_true, y_pred)\n",
    "    sample_accuracy = np.sum(correct_predictions, axis=1) / y_true.shape[1]\n",
    "    return np.mean(sample_accuracy)\n",
    "\n",
    "def custom_precision_recall_f1(y_true, y_pred):\n",
    "    true_positives = np.sum((y_true == 1) & (y_pred == 1), axis=1)\n",
    "    false_positives = np.sum((y_true == 0) & (y_pred == 1), axis=1)\n",
    "    false_negatives = np.sum((y_true == 1) & (y_pred == 0), axis=1)\n",
    "\n",
    "    precision = np.mean(true_positives / (true_positives + false_positives + 1e-8))\n",
    "    recall = np.mean(true_positives / (true_positives + false_negatives + 1e-8))\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom accuracy calculation for H3\n",
    "acc_h3_custom = custom_accuracy(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "# Calculate custom precision, recall, and F1 score for H3\n",
    "precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "\n",
    "print(\"Testing Results:\")\n",
    "print(f\"H1: Test Loss: {test_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "print(f\"H2: Test Loss: {test_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "print(f\"H3: Test Loss: {test_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "print(f\"Precision H3: {precision_h3}, Recall H3:{recall_h3}, F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING_Chatgpt_Eq_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 63/63 [00:17<00:00,  3.65it/s]\n",
      "Testing: 100%|██████████| 63/63 [00:16<00:00,  3.79it/s]\n",
      "Testing: 100%|██████████| 63/63 [00:16<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Results:\n",
      "H1: Test Loss: 4.4273, Accuracy: 0.8472\n",
      "Precision H1: 0.8472, Recall H1: 0.8472, F1 H1: 0.8472\n",
      "H2: Test Loss: 4.3395, Accuracy: 0.5258\n",
      "Precision H2: 0.5258, Recall H2: 0.5258, F1 H2: 0.5258\n",
      "H3: Test Loss: 4.3395, Custom Accuracy: 0.7060\n",
      "Precision H3: 0.6222686741955771, Recall H3:0.5491439322256687, F1 Score H3: 0.583423913757354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming the new unseen datasets are similar to 'model1_2636.csv', 'model2_2636.csv', 'model3_2636.csv'\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "#from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Loading and preprocessing new_data_h1\n",
    "new_data_h1 = pd.read_csv(\"P3_Chatgpt_Eq_Model1_508.csv\")\n",
    "new_data_h1['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h1 = new_data_h1['text'].tolist()\n",
    "new_labels_h1 = new_data_h1.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h2\n",
    "new_data_h2 = pd.read_csv(\"P3_Chatgpt_Eq_Model2_508.csv\")\n",
    "new_data_h2['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "new_texts_h2 = new_data_h2['text'].tolist()\n",
    "new_labels_h2 = new_data_h2.iloc[:, 1].values.tolist()\n",
    "\n",
    "# Loading and preprocessing new_data_h3 for multi-label classification\n",
    "new_data_h3 = pd.read_csv(\"P3_Chatgpt_Eq_Model3_508.csv\")\n",
    "new_data_h3['text'].fillna(\"\", inplace=True)  # Replace NaN values with empty strings\n",
    "\n",
    "# Replace NaN values in label columns with 0 for new_data_h3\n",
    "# Assuming all label columns are binary, fill NaN values with 0\n",
    "for label_col in new_data_h3.columns[1:]:  # Skip the text column, only fill NaN in label columns\n",
    "    new_data_h3[label_col].fillna(0, inplace=True)\n",
    "\n",
    "new_texts_h3 = new_data_h3['text'].tolist()\n",
    "new_labels_h3 = new_data_h3.iloc[:, 1:].values.tolist()  # Extract labels after filling NaN values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tokenizer\n",
    "\n",
    "# Import and initialize the ClinicalBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "clinical_bert_model = AutoModel.from_pretrained(\"medicalai/ClinicalBERT\")\n",
    "\n",
    "\n",
    "# Define the TextDataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels_h1, labels_h2, labels_h3, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels_h1 = labels_h1  # Now expecting a list of binary values for H1\n",
    "        self.labels_h2 = np.array(labels_h2).reshape(-1, 1)  # Reshape labels_h2 to [batch_size, 1]\n",
    "        self.labels_h3 = labels_h3  # Multi-label but binary values for H3\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    # Rest of the code remains unchanged\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text, None, add_special_tokens=True, max_length=self.max_length,\n",
    "            padding='max_length', return_token_type_ids=True, truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'labels_h1': torch.tensor(self.labels_h1[idx], dtype=torch.float).unsqueeze(-1),\n",
    "            'labels_h2': torch.tensor(self.labels_h2[idx], dtype=torch.float),\n",
    "            'labels_h3': torch.tensor(self.labels_h3[idx], dtype=torch.float)\n",
    "        }\n",
    "        \n",
    "# Define the model architecture for H1, H2, and H3\n",
    "class HierarchicalClassifier(nn.Module):\n",
    "    def __init__(self, num_labels_h3):\n",
    "        super(HierarchicalClassifier, self).__init__()\n",
    "        self.bert = clinical_bert_model  # Use the ClinicalBERT model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc_h1 = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.fc_h2 = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        self.fc_h3 = nn.Linear(self.bert.config.hidden_size, num_labels_h3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        logits_h1 = self.fc_h1(self.dropout(pooled_output))\n",
    "        logits_h2 = self.fc_h2(self.dropout(pooled_output))\n",
    "        logits_h3 = self.fc_h3(self.dropout(pooled_output))\n",
    "        return logits_h1, logits_h2, logits_h3\n",
    "\n",
    "\n",
    "# Initialize and move the model to the appropriate device (CPU/GPU)\n",
    "#model = HierarchicalClassifier(num_labels_h3=len(train_labels_h3[0]))\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#from transformers import RobertaTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Preprocess the texts and labels in the same way as the original datasets\n",
    "# Assuming the preprocessing steps are included in the TextDataset class\n",
    "# Create TextDataset instances for the new data\n",
    "new_dataset_h1 = TextDataset(new_texts_h1, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "new_dataset_h2 = TextDataset(new_texts_h2, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "new_dataset_h3 = TextDataset(new_texts_h3, new_labels_h1, new_labels_h2, new_labels_h3, tokenizer)\n",
    "\n",
    "# Create DataLoader instances for the new datasets\n",
    "#new_dataloader_h1 = DataLoader(new_dataset_h1, batch_size=8, shuffle=False)\n",
    "#new_dataloader_h2 = DataLoader(new_dataset_h2, batch_size=8, shuffle=False)\n",
    "#new_dataloader_h3 = DataLoader(new_dataset_h3, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "new_dataloader_h1 = DataLoader(new_dataset_h1, batch_size=8, shuffle=False, drop_last=True)\n",
    "new_dataloader_h2 = DataLoader(new_dataset_h2, batch_size=8, shuffle=False, drop_last=True)\n",
    "new_dataloader_h3 = DataLoader(new_dataset_h3, batch_size=8, shuffle=False, drop_last=True)\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'model_clinicalBert.pth'  # Path to your saved model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = HierarchicalClassifier(num_labels_h3=len(new_labels_h3[0]))  # Make sure to provide the correct number of labels for H3\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "model.to(device)  # Move the model to the appropriate device\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_h1, all_preds_h2, all_preds_h3 = [], [], []\n",
    "    all_labels_h1, all_labels_h2, all_labels_h3 = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, total=len(dataloader), desc=\"Testing\"):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            attention_mask = batch['mask'].to(device)\n",
    "            \n",
    "            # Ensuring labels are correctly shaped and moved to the device\n",
    "            labels_h1 = batch['labels_h1'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h2 = batch['labels_h2'].to(device)  # Shape: [batch_size, 1]\n",
    "            labels_h3 = batch['labels_h3'].to(device)  # Shape: [batch_size, num_labels_h3]\n",
    "            \n",
    "            logits_h1, logits_h2, logits_h3 = model(input_ids, attention_mask)\n",
    "            \n",
    "            # Compute loss for each hierarchy\n",
    "            loss_h1 = criterion(logits_h1, labels_h1)\n",
    "            loss_h2 = criterion(logits_h2, labels_h2)\n",
    "            loss_h3 = criterion(logits_h3, labels_h3)\n",
    "\n",
    "            loss = loss_h1 + loss_h2 + loss_h3\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert logits to probabilities for binary classification/multi-label classification\n",
    "            preds_h1 = torch.sigmoid(logits_h1)\n",
    "            preds_h2 = torch.sigmoid(logits_h2)\n",
    "            preds_h3 = torch.sigmoid(logits_h3)\n",
    "\n",
    "            # Store predictions and labels for metric calculation\n",
    "            all_preds_h1.extend(preds_h1.cpu().numpy())\n",
    "            all_preds_h2.extend(preds_h2.cpu().numpy())\n",
    "            all_preds_h3.extend(preds_h3.cpu().numpy())\n",
    "\n",
    "            all_labels_h1.extend(labels_h1.cpu().numpy())\n",
    "            all_labels_h2.extend(labels_h2.cpu().numpy())\n",
    "            all_labels_h3.extend(labels_h3.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds_h1, all_preds_h2, all_preds_h3, all_labels_h1, all_labels_h2, all_labels_h3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Testing the model on the new unseen data\n",
    "test_loss_h1, test_preds_h1, _, _, test_labels_h1, _, _ = test(model, new_dataloader_h1, criterion, device)\n",
    "test_loss_h2, _, test_preds_h2, _, _, test_labels_h2, _ = test(model, new_dataloader_h2, criterion, device)\n",
    "test_loss_h3, _, _, test_preds_h3, _, _, test_labels_h3 = test(model, new_dataloader_h3, criterion, device)\n",
    "\n",
    "# Calculate and print the metrics for H1, H2, and H3 using the same approach as before\n",
    "# Use the appropriate threshold and custom functions for metrics calculation\n",
    "\n",
    "# Metrics calculation for H1\n",
    "threshold_h1 = 0.5\n",
    "test_preds_h1_binary = (np.array(test_preds_h1) > threshold_h1).astype(int)\n",
    "\n",
    "acc_h1 = accuracy_score(test_labels_h1, test_preds_h1_binary)\n",
    "precision_h1 = precision_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "recall_h1 = recall_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "f1_h1 = f1_score(test_labels_h1, test_preds_h1_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H2\n",
    "threshold_h2 = 0.5\n",
    "test_preds_h2_binary = (np.array(test_preds_h2) > threshold_h2).astype(int)\n",
    "\n",
    "acc_h2 = accuracy_score(test_labels_h2, test_preds_h2_binary)\n",
    "precision_h2 = precision_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "recall_h2 = recall_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "f1_h2 = f1_score(test_labels_h2, test_preds_h2_binary, average='micro')\n",
    "\n",
    "# Metrics calculation for H3\n",
    "threshold_h3 = 0.5\n",
    "test_preds_h3_binary = (np.array(test_preds_h3) > threshold_h3).astype(int)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    correct_predictions = np.equal(y_true, y_pred)\n",
    "    sample_accuracy = np.sum(correct_predictions, axis=1) / y_true.shape[1]\n",
    "    return np.mean(sample_accuracy)\n",
    "\n",
    "def custom_precision_recall_f1(y_true, y_pred):\n",
    "    true_positives = np.sum((y_true == 1) & (y_pred == 1), axis=1)\n",
    "    false_positives = np.sum((y_true == 0) & (y_pred == 1), axis=1)\n",
    "    false_negatives = np.sum((y_true == 1) & (y_pred == 0), axis=1)\n",
    "\n",
    "    precision = np.mean(true_positives / (true_positives + false_positives + 1e-8))\n",
    "    recall = np.mean(true_positives / (true_positives + false_negatives + 1e-8))\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom accuracy calculation for H3\n",
    "acc_h3_custom = custom_accuracy(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "# Calculate custom precision, recall, and F1 score for H3\n",
    "precision_h3, recall_h3, f1_score_h3 = custom_precision_recall_f1(np.array(test_labels_h3), test_preds_h3_binary)\n",
    "\n",
    "print(\"Testing Results:\")\n",
    "print(f\"H1: Test Loss: {test_loss_h1:.4f}, Accuracy: {acc_h1:.4f}\")\n",
    "print(f\"Precision H1: {precision_h1:.4f}, Recall H1: {recall_h1:.4f}, F1 H1: {f1_h1:.4f}\")\n",
    "\n",
    "print(f\"H2: Test Loss: {test_loss_h2:.4f}, Accuracy: {acc_h2:.4f}\")\n",
    "print(f\"Precision H2: {precision_h2:.4f}, Recall H2: {recall_h2:.4f}, F1 H2: {f1_h2:.4f}\")\n",
    "\n",
    "print(f\"H3: Test Loss: {test_loss_h3:.4f}, Custom Accuracy: {acc_h3_custom:.4f}\")\n",
    "print(f\"Precision H3: {precision_h3}, Recall H3:{recall_h3}, F1 Score H3: {f1_score_h3}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
